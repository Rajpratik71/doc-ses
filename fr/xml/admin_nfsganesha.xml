<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_nfsganesha.xml" version="5.0" xml:id="cha-ceph-nfsganesha">

 <title>NFS Ganesha : exportation de données Ceph via NFS</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>modification</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>oui</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    
 <para>
  NFS Ganesha est un serveur NFS (voir <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_nfs.html">Partage de systèmes de fichiers avec NFS</link>) qui s'exécute dans un espace d'adressage utilisateur et non pas dans le kernel du système d'exploitation. Avec NFS Ganesha, vous pouvez brancher votre propre mécanisme de stockage, tel que Ceph, et y accéder depuis n'importe quel client NFS.
 </para>
 <para>
  Les compartiments S3 sont exportés vers NFS suivant l'utilisateur, par exemple via le chemin <filename><replaceable>NOEUD_GANESHA:</replaceable>/<replaceable>NOM_UTILISATEUR</replaceable>/<replaceable>NOM_COMPARTIMENT</replaceable></filename>.
 </para>
 <para>
  Un CephFS est exporté par défaut via le chemin <filename><replaceable>NOEUD_GANESHA:</replaceable>/cephfs</filename>.
 </para>
 <sect1 xml:id="ceph-nfsganesha-install">
  <title>Installation</title>

  <para>
   Pour connaître la procédure d'installation, reportez-vous au <xref linkend="cha-as-ganesha"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-config">
  <title>Configuration</title>

  <para>
   Pour obtenir la liste de tous les paramètres disponibles dans le fichier de configuration, reportez-vous à :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>man ganesha-config</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-ceph-config</command> pour les options de la couche FSAL (couche d'abstraction du système de fichiers) de CephFS.
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-rgw-config</command> pour les options FSAL d'Object Gateway.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Cette section vous aide à configurer le serveur NFS Ganesha pour exporter les données de grappe accessibles via Object Gateway et CephFS.
  </para>

  <para>
   La configuration de NFS Ganesha est contrôlée par <filename>/etc/ganesha/ganesha.conf</filename>. Notez que les modifications apportées à ce fichier sont remplacées lors de la phase 4 de DeepSea. Pour modifier les paramètres durablement, modifiez le fichier <filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename> situé sur Salt Master.
  </para>

  <sect2 xml:id="ceph-nfsganesha-config-general">
   <title>Section EXPORT</title>
   <para>
    Cette section décrit la manière de configurer les sections <literal>EXPORT</literal> du fichier <filename>ganesha.conf</filename>.
   </para>
<screen>EXPORT
{
  Export_Id = 1;
  Path = "/";
  Pseudo = "/";
  Access_Type = RW;
  Squash = No_Root_Squash;
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
   <sect3 xml:id="ceph-nfsganesha-config-general-export">
    <title>Section EXPORT principale</title>
    <variablelist>
     <varlistentry>
      <term>Export_Id</term>
      <listitem>
       <para>
        Chaque exportation doit disposer d'un « Export_Id » unique (obligatoire).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Path</term>
      <listitem>
       <para>
        Chemin d'exportation dans la réserve CephFS associée (obligatoire). Cela permet l'exportation des sous-répertoires depuis CephFS.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Pseudo</term>
      <listitem>
       <para>
        Chemin d'exportation NFS cible (obligatoire pour NFSv4). Il définit le chemin d'exportation NFS sous lequel les données exportées sont disponibles.
       </para>
       <para>
        Exemple : avec la valeur <literal>/cephfs/</literal> et après exécution
       </para>
<screen>
<prompt>root # </prompt>mount <replaceable>GANESHA_IP</replaceable>:/cephfs/ /mnt/
</screen>
       <para>
        Les données CephFS sont disponibles dans le répertoire <filename>/mnt/cephfs/</filename> du client.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Access_Type</term>
      <listitem>
       <para>
        « RO » pour un accès en lecture seule ; « None » (« Aucun »).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Squash</term>
      <listitem>
       <para>
        Option squash de NFS.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>FSAL</term>
      <listitem>
       <para>
        Exportation de la couche d'abstraction du système de fichiers (File System Abstraction Layer, FSAL). Reportez-vous à la <xref linkend="ceph-nfsganesha-config-general-fsal"/>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-nfsganesha-config-general-fsal">
    <title>Sous-section FSAL</title>
<screen>EXPORT
{
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
    <variablelist>
     <varlistentry>
      <term>Name</term>
      <listitem>
       <para>
        Indique le nom du système dorsal utilisé par NFS Ganesha. Les valeurs autorisées sont <literal>CEPH</literal> pour CephFS ou <literal>RGW</literal> pour Object Gateway. Selon le choix, il est nécessaire de définir <literal>role-mds</literal> ou <literal>role-rgw</literal> dans le fichier <filename>policy.cfg</filename>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-config-rgw">
   <title>Section RGW</title>
<screen>RGW {
  ceph_conf = "/etc/ceph/ceph.conf";
  name = "name";
  cluster = "ceph";
}</screen>
   <variablelist>
    <varlistentry>
     <term>ceph_conf</term>
     <listitem>
      <para>
       Pointe vers le fichier <filename>ceph.conf</filename>. Lors du déploiement réalisé avec DeepSea, il n'est pas nécessaire de modifier cette valeur.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>name</term>
     <listitem>
      <para>
       Nom de l'utilisateur client Ceph employé par NFS Ganesha.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cluster</term>
     <listitem>
      <para>
       Nom de la grappe Ceph. SUSE Enterprise Storage 5 ne prend actuellement en charge qu'un nom de grappe, <literal>ceph</literal> par défaut.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ganesha-nfsport">
   <title>Changement des ports NFS Ganesha par défaut</title>
   <para>
    Par défaut, NFS Ganesha utilise le port 2049 pour NFS et le port 875 pour la prise en charge de rquota. Pour changer les numéros de port par défaut, utilisez les options <option>NFS_Port</option> et <option>RQUOTA_Port</option> de la section <literal>NFS_CORE_PARAM</literal>, par exemple :
   </para>
<screen>
NFS_CORE_PARAM
{
 NFS_Port = 2060;
 RQUOTA_Port = 876;
}
</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-customrole">
  <title>Rôles NFS Ganesha personnalisés</title>

  <para>
   Il est possible de définir des rôles NFS Ganesha pour les noeuds de grappe. Ces rôles sont ensuite assignés aux noeuds via le fichier <filename>policy.cfg</filename>. Les rôles permettent :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     de séparer les noeuds NFS Ganesha pour l'accès à Object Gateway et CephFS ;
    </para>
   </listitem>
   <listitem>
    <para>
     d'assigner des utilisateurs Object Gateway différents aux noeuds NFS Ganesha.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Les noeuds NFS Ganesha disposent d'utilisateurs Object Gateway différents pour pouvoir accéder à des compartiments S3 différents. Les compartiments S3 peuvent être utilisés pour le contrôle d'accès. Remarque : les compartiments S3 ne doivent pas être confondus avec les compartiments Ceph utilisés dans l'assignation CRUSH.
  </para>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-multiusers">
   <title>Utilisateurs Object Gateway pour NFS Ganesha</title>
   <para>
    Cet exemple de procédure pour Salt Master montre comment créer deux rôles NFS Ganesha avec des utilisateurs Object Gateway différents. Il utilise les rôles <literal>gold</literal> et <literal>silver</literal> pour lesquels DeepSea fournit déjà des exemples de fichier de configuration.
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-rgw-multiusers">
    <step>
     <para>
      Ouvrez le fichier <filename>/srv/pillar/ceph/stack/global.yml</filename> dans l'éditeur de votre choix. Créez le fichier s'il n'existe pas.
     </para>
    </step>
    <step>
     <para>
      Le fichier doit contenir les lignes suivantes :
     </para>
<screen>rgw_configurations:
  - rgw
  - silver
  - gold
ganesha_configurations:
  - silver
  - gold</screen>
     <para>
      Ces rôles peuvent être assignés ultérieurement dans le fichier <filename>policy.cfg</filename>.
     </para>
    </step>
    <step>
     <para>
      Créez le fichier <filename>/srv/salt/ceph/rgw/users/users.d/gold.yml</filename> et ajoutez-lui le contenu suivant :
     </para>
<screen>- { uid: "gold1", name: "gold1", email: "gold1@demo.nil" }</screen>
     <para>
      Créez un fichier <filename>/srv/salt/ceph/rgw/users/users.d/silver.yml</filename> et ajoutez-lui les lignes suivantes :
     </para>
<screen>- { uid: "silver1", name: "silver1", email: "silver1@demo.nil" }</screen>
    </step>
    <step>
     <para>
      À présent, les modèles de <filename>ganesha.conf</filename> doivent être créés pour chaque rôle. Le modèle original de DeepSea est une bonne base pour commencer. Créez deux copies :
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 silver.conf.j2
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 gold.conf.j2</screen>
    </step>
    <step>
     <para>
      Les nouveaux rôles requièrent des trousseaux pour pouvoir accéder à la grappe. Pour accorder l'accès, copiez le fichier <filename>ganesha.j2</filename> :
     </para>
<screen><prompt>root # </prompt><command>cp</command> ganesha.j2 silver.j2
<prompt>root # </prompt><command>cp</command> ganesha.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Copiez le trousseau de clés pour Object Gateway :
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/rgw/files/
<prompt>root # </prompt><command>cp</command> rgw.j2 silver.j2
<prompt>root # </prompt><command>cp</command> rgw.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Object Gateway a également besoin de la configuration des différents rôles :
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/configuration/files/
<prompt>root # </prompt><command>cp</command> ceph.conf.rgw silver.conf
<prompt>root # </prompt><command>cp</command> ceph.conf.rgw gold.conf</screen>
    </step>
    <step>
     <para>
      Assignez les rôles nouvellement créés aux noeuds de grappe dans le fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> :
     </para>
<screen>role-silver/cluster/<replaceable>NODE1</replaceable>.sls
role-gold/cluster/<replaceable>NODE2</replaceable>.sls
 </screen>
     <para>
      Remplacez <replaceable>NODE1</replaceable> et <replaceable>NODE2</replaceable> par les noms des noeuds auxquels vous voulez assigner les rôles.
     </para>
    </step>
    <step>
     <para>
      Exécutez les phases 0 à 4 de DeepSea.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-cephfs">
   <title>Séparation de la couche FSAL de CephFS et d'Object Gateway</title>
   <para>
    Cet exemple de procédure pour Salt Master montre comment créer deux rôles différents utilisant CephFS et Object Gateway :
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-customrole">
    <step>
     <para>
      Ouvrez le fichier <filename>/srv/pillar/ceph/rgw.sls</filename> avec l'éditeur de votre choix. Créez le fichier s'il n'existe pas.
     </para>
    </step>
    <step>
     <para>
      Le fichier doit contenir les lignes suivantes :
     </para>
<screen>rgw_configurations:
  ganesha_cfs:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }
  ganesha_rgw:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }

ganesha_configurations:
  - ganesha_cfs
  - ganesha_rgw</screen>
     <para>
      Ces rôles peuvent être assignés ultérieurement dans le fichier <filename>policy.cfg</filename>.
     </para>
    </step>
    <step>
     <para>
      À présent, les modèles de <filename>ganesha.conf</filename> doivent être créés pour chaque rôle. Le modèle original de DeepSea est une bonne base pour commencer. Créez deux copies :
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 ganesha_rgw.conf.j2
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 ganesha_cfs.conf.j2</screen>
    </step>
    <step>
     <para>
      Ouvrez le fichier <filename>ganesha_rgw.conf.j2</filename> pour supprimer la section suivante :
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles='mds') != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      Ouvrez le fichier <filename>ganesha_cfs.conf.j2</filename> pour supprimer la section suivante :
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles=role) != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      Les nouveaux rôles requièrent des trousseaux pour pouvoir accéder à la grappe. Pour accorder l'accès, copiez le fichier <filename>ganesha.j2</filename> :
     </para>
<screen><prompt>root # </prompt><command>cp</command> ganesha.j2 ganesha_rgw.j2
<prompt>root # </prompt><command>cp</command> ganesha.j2 ganesha_cfs.j2</screen>
     <para>
      Vous pouvez supprimer la ligne <literal>caps mds = "allow *"</literal> du fichier <filename>ganesha_rgw.j2</filename>.
     </para>
    </step>
    <step>
     <para>
      Copiez le trousseau de clés pour Object Gateway :
     </para>
<screen><prompt>root # </prompt><command>cp</command> /srv/salt/ceph/rgw/files/rgw.j2 \
/srv/salt/ceph/rgw/files/ganesha_rgw.j2</screen>
    </step>
    <step>
     <para>
      Object Gateway a besoin de la configuration du nouveau rôle :
     </para>
<screen><prompt>root # </prompt><command>cp</command> /srv/salt/ceph/configuration/files/ceph.conf.rgw \
/srv/salt/ceph/configuration/files/ceph.conf.ganesha_rgw</screen>
    </step>
    <step>
     <para>
      Assignez les rôles nouvellement créés aux noeuds de grappe dans le fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> :
     </para>
<screen>role-ganesha_rgw/cluster/<replaceable>NODE1</replaceable>.sls
role-ganesha_cfs/cluster/<replaceable>NODE1</replaceable>.sls
 </screen>
     <para>
      Remplacez <replaceable>NODE1</replaceable> et <replaceable>NODE2</replaceable> par les noms des noeuds auxquels vous voulez assigner les rôles.
     </para>
    </step>
    <step>
     <para>
      Exécutez les phases 0 à 4 de DeepSea.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-services">
  <title>Démarrage ou redémarrage de NFS Ganesha</title>

  <para>
   Pour activer et démarrer le service NFS Ganesha, exécutez :
  </para>

<screen><prompt>root # </prompt><command>systemctl</command> enable nfs-ganesha
<prompt>root # </prompt><command>systemctl</command> start nfs-ganesha</screen>

  <para>
   Redémarrez NFS Ganesha avec :
  </para>

<screen><prompt>root # </prompt><command>systemctl</command> restart nfs-ganesha</screen>

  <para>
   Lorsque NFS Ganesha est démarré ou redémarré, le délai de grâce est de 90 secondes pour NFS v4. Au cours de cette période bonus, les nouvelles requêtes provenant des clients sont activement rejetées. Par conséquent, les clients peuvent être confrontés au ralentissement des demandes lorsque NFS est en état de grâce.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-loglevel">
  <title>Définition du niveau de journalisation</title>

  <para>
   Changez le niveau de débogage par défaut <literal>NIV_EVENT</literal> dans le fichier <filename>/etc/sysconfig/nfs-ganesha</filename>. Remplacez <literal>NIV_EVENT</literal> par <literal>NIV_DEBUG</literal> ou <literal>NIV_FULL_DEBUG</literal>. L'augmentation du niveau de détail de journalisation peut engendrer de grandes quantités de données dans les fichiers journaux.
  </para>

<screen>OPTIONS="-L /var/log/ganesha/ganesha.log -f /etc/ganesha/ganesha.conf -N NIV_EVENT"</screen>

  <para>
   Le redémarrage du service est requis à l'issue de la modification du niveau de journalisation.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-verify">
  <title>Vérification du partage NFS exporté</title>

  <para>
   Lors de l'utilisation NFS v3, vous pouvez vérifier si les partages NFS sont exportés sur le noeud du serveur NFS Ganesha :
  </para>

<screen><prompt>root # </prompt><command>showmount</command> -e
/ (everything)</screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-mount">
  <title>Montage du partage NFS exporté</title>

  <para>
   Pour monter le partage NFS exporté (tel que configuré à la <xref linkend="ceph-nfsganesha-config"/>) sur un hôte client, exécutez :
  </para>

<screen><prompt>root # </prompt><command>mount</command> -t nfs -o rw,noatime,sync \
 <replaceable>nfs_ganesha_server_hostname:/ /path/to/local/mountpoint</replaceable></screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-more">
  <title>Ressources supplémentaires</title>

  <para>
   La documentation originale de NFS Ganesha est disponible à l'adresse <link xlink:href="https://github.com/nfs-ganesha/nfs-ganesha/wiki/Docs"/>.
  </para>
 </sect1>
</chapter>
