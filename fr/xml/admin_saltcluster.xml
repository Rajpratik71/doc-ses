<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_saltcluster.xml" version="5.0" xml:id="storage-salt-cluster">
 <title>Administration de grappe Salt</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>oui</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Après avoir déployé la grappe, vous devrez probablement effectuer plusieurs modifications de manière occasionnelle. Citons notamment l'ajout ou la suppression de nouveaux noeuds, disques ou services. Ce chapitre décrit la manière dont vous pouvez réaliser ces tâches d'administration.
 </para>
 <sect1 xml:id="salt-adding-nodes">
  <title>Ajout de nouveaux noeuds à la grappe</title>

  <para>
   La procédure d'ajout de nouveaux noeuds à la grappe est presque identique au déploiement initial du noeud de grappe décrit dans le <xref linkend="ceph-install-saltstack"/> :
  </para>

  <procedure>
   <step>
    <para>
     Installez SUSE Linux Enterprise Server 12 SP3 sur le nouveau noeud, configurez son paramètre réseau de sorte qu'il résolve correctement le nom d'hôte Salt Master et installez le paquetage <systemitem>salt-minion</systemitem> :
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper in salt-minion</screen>
    <para>
     Si le nom d'hôte de Salt Master est différent de <literal>salt</literal>, modifiez <filename>etc/salt/minion</filename> pour lui ajouter ce qui suit :
    </para>
<screen>master: <replaceable>DNS_name_of_your_salt_master</replaceable></screen>
    <para>
     Si vous avez apporté des modifications aux fichiers de configuration mentionnés ci-dessus, redémarrez le service <systemitem>salt.minion</systemitem> :
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <para>
     Acceptez toutes les clés salt sur Salt Master :
    </para>
<screen><prompt>root@master # </prompt>salt-key --accept-all</screen>
   </step>
   <step>
    <para>
     Vérifiez que <filename>/srv/pillar/ceph/deepsea_minions.sls</filename> cible également le nouveau minion Salt. Reportez-vous au <xref linkend="ds-minion-targeting-name"/> du <xref linkend="ds-depl-stages"/> pour plus de détails.
    </para>
   </step>
   <step>
    <para>
     Exécutez la phase de préparation. Les modules et les données sont synchronisés afin que la nouveau minion puisse fournir toutes les informations attendues par DeepSea :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
   </step>
   <step>
    <para>
     Exécutez la phase de découverte. Elle va écrire de nouvelles entrées de fichier dans le répertoire <filename>/srv/pillar/ceph/proposals</filename> dans lequel vous pouvez modifier les fichiers .yml pertinents :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Éventuellement, modifiez le fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> si le nouvel hôte ajouté ne correspond pas au schéma de dénomination existant. Pour plus d'informations, reportez-vous au <xref linkend="policy-configuration"/>.
    </para>
   </step>
   <step>
    <para>
     Exécutez la phase de configuration. Elle lit tous les éléments sous <filename>/srv/pillar/ceph</filename> et met à jour Pillar en conséquence :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
    <para>
     Pillar stocke les données auxquelles vous pouvez accéder à l'aide de la commande suivante :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.items</screen>
   </step>
   <step>
    <para>
     Les phases de configuration et de déploiement incluent les noeuds que vous venez d'ajouter :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-adding-services">
  <title>Ajout de nouveaux rôles à des noeuds</title>

  <para>
   Vous pouvez déployer tous les types de rôles pris en charge avec DeepSea. Reportez-vous au <xref linkend="policy-role-assignment"/> pour plus d'informations sur les types de rôles pris en charge et des exemples sur leur mise en correspondance.
  </para>

  <tip>
   <title>rôles et phases obligatoires et facultatifs</title>
   <para>
    En règle générale, il est recommandé d'exécuter toutes les phases de déploiement 0 à 5 lors de l'ajout d'un nouveau rôle à un noeud de grappe. Pour gagner du temps, vous pouvez ignorer la phase 3 ou 4 selon le type de rôle que vous souhaitez déployer. Alors que les rôles OSD et MON incluent des services de base et sont requis par Ceph, d'autres rôles, tels qu'Object Gateway, sont facultatifs. Les phases de déploiement DeepSea sont hiérarchiques : alors que la phase 3 déploie les services centraux, la phase 4 déploie les services facultatifs.
   </para>
   <para>
    Par conséquent, vous devez exécuter la phase 3 lors du déploiement de rôles principaux, tels que MON sur un noeud OSD existant, et vous pouvez ignorer la phase 4.
   </para>
   <para>
    De même, vous pouvez ignorer la phase 3 lors du déploiement de services facultatifs, tels qu'Object Gateway, mais vous devez exécuter la phase 4 dans ce cas.
   </para>
  </tip>

  <para>
   Pour ajouter un nouveau service à un noeud existant, procédez comme suit :
  </para>

  <procedure>
   <step>
    <para>
     Adaptez <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> pour faire correspondre l'hôte existant à un nouveau rôle. Pour plus d'informations, reportez-vous au <xref linkend="policy-configuration"/>. Par exemple, si vous devez exécuter une passerelle Object Gateway sur un noeud MON, la ligne est similaire à ceci :
    </para>
<screen>role-rgw/xx/x/example.mon-1.sls</screen>
   </step>
   <step>
    <para>
     Exécutez la phase 2 pour mettre à jour Pillar :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Exécutez la phase 3 pour déployer les services de base ou la phase 4 pour déployer les services facultatifs. L'exécution des deux phases est sans risque.
    </para>
   </step>
  </procedure>

  <tip>
   <para>
    Lorsque vous ajoutez un OSD à la grappe existante, gardez à l'esprit que le rééquilibrage de celle-ci dure un certain temps après cette opération. Pour minimiser les périodes de rééquilibrage, nous vous recommandons d'ajouter tous les OSD que vous avez l'intention d'ajouter en même temps.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="salt-node-removing">
  <title>Suppression et réinstallation de noeuds de grappe</title>

  <para>
   Pour supprimer un rôle d'une grappe, modifiez <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> et supprimez la ou les lignes correspondantes. Exécutez ensuite les phases 2 et 5 comme décrit dans le <xref linkend="ceph-install-stack"/>.
  </para>

  <note>
   <title>suppression d'OSD de votre grappe</title>
   <para>
    Si vous devez supprimer un noeud OSD particulier de votre grappe, assurez-vous que celle-ci dispose de plus d'espace disque libre que le disque que vous souhaitez supprimer. Gardez à l'esprit que la suppression d'un OSD entraîne un rééquilibrage de l'ensemble de la grappe.
   </para>
  </note>

  <para>
   Lorsqu'un rôle est supprimé d'un minion, l'objectif est d'annuler toutes les modifications liées à ce rôle. Pour la plupart des rôles, la tâche est simple, mais des dépendances de paquetages peuvent être problématiques. Si un paquetage est désinstallé, ses dépendances ne le sont pas pour autant.
  </para>

  <para>
   Les OSD supprimés apparaissent comme des unités vides. Les tâches associées remplacent le début des systèmes de fichiers et suppriment les partitions de sauvegarde, en plus de supprimer les tables de partition.
  </para>

  <note>
   <title>préservation des partitions créées par d'autres méthodes</title>
   <para>
    Les unités de disque précédemment configurées à l'aide d'autres méthodes, telles que <command>ceph-deploy</command>, peuvent toujours contenir des partitions. DeepSea ne les détruira pas automatiquement. L'administrateur doit récupérer ces unités. 
   </para>
  </note>

  <example xml:id="ex-ds-rmnode">
   <title>Suppression d'un minion Salt de la grappe</title>
   <para>
    Si vos minions de stockage sont nommés, par exemple, « data1.ceph », « data2.ceph » ... « data6.ceph », et les lignes associées dans votre fichier <filename>policy.cfg</filename> sont similaires à ce qui suit :
   </para>
<screen>[...]
# Hardware Profile
profile-default/cluster/data*.sls
profile-default/stack/default/ceph/minions/data*.yml
[...]</screen>
   <para>
    Ensuite, pour supprimer le minion Salt « data2.ceph », modifiez les lignes comme suit :
   </para>
<screen>
[...]
# Hardware Profile
profile-default/cluster/data[1,3-6]*.sls
profile-default/stack/default/ceph/minions/data[1,3-6]*.yml
[...]</screen>
   <para>
    Exécutez ensuite les phases 2 et 5 :
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5</screen>
  </example>

  <example xml:id="ex-ds-mignode">
   <title>Migration des noeuds</title>
   <para>
    Imaginons la situation suivante : lors de l'installation de la nouvelle grappe, vous (l'administrateur) avez alloué l'un des noeuds de stockage en tant que passerelle Object Gateway autonome en attendant la livraison du matériel de la passerelle. Le matériel permanent est à présent arrivé pour la passerelle et vous pouvez enfin attribuer le rôle prévu au noeud de stockage de sauvegarde et supprimer le rôle de passerelle.
   </para>
   <para>
    Après avoir exécuté les phases 0 et 1 (reportez-vous au <xref linkend="ds-depl-stages"/>) pour le nouveau matériel, vous avez nommé la nouvelle passerelle <literal>rgw1</literal>. Si le noeud <literal>data8</literal> requiert la suppression du rôle Object Gateway et l'ajout du rôle de stockage, le fichier <filename>policy.cfg</filename> se présente comme suit :
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-7]*.sls
profile-default/stack/default/ceph/minions/data[1-7]*.sls

# Roles
role-rgw/cluster/data8*.sls</screen>
   <para>
    Modifiez-le de sorte qu'il contienne les informations suivantes :
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-8]*.sls
profile-default/stack/default/ceph/minions/data[1-8]*.sls

# Roles
role-rgw/cluster/rgw1*.sls</screen>
   <para>
    Exécutez les phase 2 à 5. La phase 3 ajoute <literal>data8</literal> en tant que noeud de stockage. Pour quelques instants, <literal>data8</literal> a deux rôles. La phase 4 ajoute le rôle Object Gateway à <literal>rgw1</literal> et la phase 5 supprime le rôle Object Gateway de <literal>data8</literal>.
   </para>
  </example>
 </sect1>
 <sect1 xml:id="ds-mon">
  <title>Redéploiement des noeuds de moniteur</title>

  <para>
   Lorsqu'un ou plusieurs de vos noeuds de moniteur échouent et ne répondent pas, vous devez supprimer de la grappe les moniteurs ayant échoué et éventuellement les rajouter dans la grappe.
  </para>

  <important>
   <title>le minimum est de trois noeuds de moniteur</title>
   <para>
    Le nombre de noeuds de moniteur ne doit pas être inférieur à trois. Si un noeud de moniteur échoue et que votre grappe ne possède qu'un ou deux noeuds de moniteur, vous devez assigner temporairement le rôle de moniteur aux autres noeuds de la grappe avant de redéployer les noeuds de moniteur ayant échoué. Après avoir redéployé les noeuds de moniteur ayant échoué, vous pouvez désinstaller les rôles de moniteur temporaires.
   </para>
   <para>
    Pour plus d'informations sur l'ajout de nouveaux noeuds/rôles à la grappe Ceph, reportez-vous à la <xref linkend="salt-adding-nodes"/> et à la <xref linkend="salt-adding-services"/>.
   </para>
   <para>
    Pour plus d'informations sur la suppression de noeuds de grappe, reportez-vous à la <xref linkend="salt-node-removing"/>.
   </para>
  </important>

  <para>
   On distingue deux degrés de base lors d'un échec de noeud Ceph :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     L'hôte minion Salt est endommagé physiquement ou au niveau du système d'exploitation et ne répond pas à l'appel <command>salt '<replaceable>nom_minion</replaceable>' test.ping</command>. Dans ce cas, vous devez redéployer le serveur complètement en suivant les instructions appropriées dans le <xref linkend="ceph-install-stack"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Les services liés au moniteur ont échoué et ne permettent pas de récupérer les ressources, mais l'hôte répond à l'appel <command>salt '<replaceable>nom_minion</replaceable>' test.ping</command>. Dans ce cas, procédez comme suit :
    </para>
   </listitem>
  </itemizedlist>

  <procedure>
   <step>
    <para>
     Modifiez le fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> sur Salt Master et supprimez ou mettez à jour les lignes qui correspondent aux noeuds de moniteur ayant échoué afin qu'elles pointent sur les noeuds de moniteur opérationnels.
    </para>
   </step>
   <step>
    <para>
     Exécutez les phases 2 à 5 de DeepSea pour appliquer les modifications :
    </para>
<screen>
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.4
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.5
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-node-add-disk">
  <title>Ajout d'un OSD à un noeud</title>

  <para>
   Pour ajouter un disque à un noeud OSD existant, vérifiez que toutes les partitions du disque ont été supprimées et effacées. Reportez-vous à l'<xref linkend="deploy-wiping-disk"/> du <xref linkend="ceph-install-stack"/> pour plus de détails. Une fois que le disque est vide, ajoutez-le au fichier YAML du noeud. Le fichier se situe dans le chemin d'accès <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/<replaceable>nom_noeud</replaceable>.yml</filename>. Après avoir enregistré le fichier, exécutez les phases 2 et 3 de DeepSea :
  </para>

<screen><prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>

  <tip>
   <title>profils mis à jour automatiquement</title>
   <para>
    Au lieu de modifier manuellement le fichier YAML, DeepSea peut créer de nouveaux profils. Pour permettre à DeepSea de créer de nouveaux profils, les profils existants doivent être déplacés :
   </para>
<screen><prompt>root@master # </prompt><command>old</command> /srv/pillar/ceph/proposals/profile-default/
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.1
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>
  </tip>
 </sect1>
 <sect1 xml:id="salt-removing-osd">
  <title>Suppression d'un OSD</title>

  <para>
   Vous pouvez supprimer Ceph OSD de la grappe en exécutant la commande suivante :
  </para>

<screen><prompt>root@master # </prompt><command>salt-run</command> disengage.safety
<prompt>root@master # </prompt><command>salt-run</command> remove.osd <replaceable>OSD_ID</replaceable></screen>

  <para>
   <replaceable>OSD_ID</replaceable> doit être le numéro de l'affichage à l'écran sans le terme <literal>osd</literal>. Par exemple, à partir de <literal>osd.3</literal>, utilisez uniquement le chiffre <literal>3</literal>.
  </para>

  <tip>
   <title>suppression de plusieurs OSD</title>
   <para>
    Il n'y a aucun moyen de supprimer plusieurs OSD en parallèle avec la commande <command>salt-run remove.osd</command>. Pour automatiser la suppression de plusieurs OSD, vous pouvez utiliser la boucle suivante (5, 21, 33, 19 sont les numéros d'identification des OSD à supprimer) :
   </para>
<screen>
for i in 5 21 33 19
do
 echo $i
 salt-run disengage.safety
 salt-run remove.osd $i
done
</screen>
  </tip>

  <sect2 xml:id="osd-forced-removal">
   <title>Suppression forcée des OSD rompus</title>
   <para>
    La suppression normale d'un OSD peut parfois conduire à un échec (reportez-vous à la <xref linkend="salt-removing-osd"/>). Cela peut se produire, par exemple, si l'OSD ou son cache est endommagé, si un blocage d'opérations d'E/S se produit ou si le démontage du disque OSD échoue. Dans ce cas, vous devez forcer la suppression de l'OSD :
   </para>
<screen><prompt>root@master # </prompt><replaceable>target</replaceable> osd.remove <replaceable>OSD_ID</replaceable> force=True</screen>
   <para>
    Cette commande supprime à la fois la partition de données et le journal ou les partitions WAL/DB.
   </para>
   <para>
    Pour identifier les périphériques de journal/WAL/DB potentiellement orphelins, procédez comme suit :
   </para>
   <procedure>
    <step>
     <para>
      Choisissez le périphérique qui peut contenir des partitions orphelines et enregistrez la liste de ses partitions dans un fichier :
     </para>
<screen>
<prompt>root@minion &gt; </prompt>ls /dev/sdd?* &gt; /tmp/partitions
</screen>
    </step>
    <step>
     <para>
      Exécutez <command>readlink</command> sur tous les périphériques block.wal, block.db et de journal, et comparez la sortie à la liste de partitions précédemment enregistrée :
     </para>
<screen>
<prompt>root@minion &gt; </prompt>readlink -f /var/lib/ceph/osd/ceph-*/{block.wal,block.db,journal} \
 | sort | comm -23 /tmp/partitions -
</screen>
     <para>
      La sortie est la liste des partitions qui ne sont <emphasis>pas</emphasis> utilisées par Ceph.
     </para>
    </step>
    <step>
     <para>
      Supprimez les partitions orphelines qui n'appartiennent pas à Ceph à l'aide de votre commande préférée (par exemple <command>fdisk</command>, <command>parted</command> ou <command>sgdisk</command>).
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ds-osd-recover">
  <title>Récupération d'un noeud OSD réinstallé</title>

  <para>
   Si le système d'exploitation subit des dommages et n'est pas récupérable sur l'un de vos noeuds OSD, procédez comme suit pour le récupérer et redéployer son rôle OSD avec les données de grappe intactes :
  </para>

  <procedure>
   <step>
    <para>
     Réinstallez le système d'exploitation sur le noeud.
    </para>
   </step>
   <step>
    <para>
     Installez les paquetages <package>salt minion</package> sur le noeud OSD, supprimez l'ancienne clé du minion Salt sur Salt Master et enregistrez la nouvelle clé du minion Salt auprès de Salt Master. Pour plus d'informations sur le déploiement de minion Salt, reportez-vous au <xref linkend="ceph-install-stack"/>.
    </para>
   </step>
   <step>
    <para>
     Au lieu d'exécuter l'ensemble de la phase 0, exécutez les parties suivantes :
    </para>
<screen>
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.sync
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.packages.common
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.mines
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.updates
</screen>
   </step>
   <step>
    <para>
     Exécutez les phases 1 à 5 de DeepSea :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5
</screen>
   </step>
   <step>
    <para>
     Exécutez la phase 0 de DeepSea :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
</screen>
   </step>
   <step>
    <para>
     Redémarrez le noeud OSD correspondant. Tous les disques OSD seront redécouverts et réutilisés.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-automated-installation">
  <title>Installation automatisée via Salt</title>

  <para>
   L'installation peut être automatisée à l'aide du réacteur Salt. Pour les environnements virtuels ou les environnements matériels cohérents, cette configuration permettra la création d'une grappe Ceph avec le comportement indiqué.
  </para>

  <warning>
   <para>
    Salt ne peut pas effectuer de contrôles de dépendance basés sur les événements du réacteur. Il existe un risque réel de mettre en danger Salt Master de façon irréversible.
   </para>
  </warning>

  <para>
   L'installation automatisée nécessite les éléments suivants :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Un fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> correctement créé.
    </para>
   </listitem>
   <listitem>
    <para>
     Une configuration personnalisée préparée et placée dans le répertoire <filename>/srv/pillar/ceph/stack</filename>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   La configuration du réacteur par défaut n'exécutera que les phases 0 et 1. Cela permet de tester le réacteur sans attendre la fin des phases suivantes.
  </para>

  <para>
   Lorsque le premier salt-minion démarre, la phase 0 commence. Un verrouillage empêche la présence de plusieurs instances. Lorsque tous les minions terminent la phase 0, la phase 1 commence.
  </para>

  <para>
   Si l'opération est effectuée correctement, modifiez la dernière ligne dans le fichier <filename>/etc/salt/master.d/reactor.conf</filename> :
  </para>

<screen>- /srv/salt/ceph/reactor/discovery.sls</screen>

  <para>
   par
  </para>

<screen>- /srv/salt/ceph/reactor/all_stages.sls</screen>
 </sect1>
 <sect1 xml:id="deepsea-rolling-updates">
  <title>Mise à jour des noeuds de grappe</title>

  <para>
   Il est judicieux d'appliquer régulièrement les mises à jour progressives aux noeuds de la grappe. Pour appliquer les mises à jour, exécutez la phase 0 :
  </para>

<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>

  <para>
   Si DeepSea détecte une grappe Ceph en cours d'exécution, il applique les mises à jour et redémarre les noeuds de manière séquentielle. DeepSea suit la recommandation officielle de Ceph de mettre d'abord à jour les moniteurs, puis les OSD et enfin des services supplémentaires, tels que MDS, Object Gateway, iSCSI Gateway ou NFS Ganesha. DeepSea arrête le processus de mise à jour s'il détecte un problème dans la grappe. Pour ce faire, un déclencheur peut se présenter ainsi :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Ceph indique « HEALTH_ERR » pendant plus de 300 secondes.
    </para>
   </listitem>
   <listitem>
    <para>
     Une requête est envoyée aux minions Salt afin que les services qui leur sont assignés soient toujours opérationnels après une mise à jour. La mise à jour échoue si les services sont arrêtés pendant plus de 900 secondes.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Grâce à cette approche, même si les mises à jour ne se sont pas déroulées correctement, la grappe Ceph reste opérationnelle.
  </para>

  <para>
   La phase 0 de DeepSea met à jour le système à l'aide de la commande <command>zypper update</command> et redémarre le système si le kernel est mis à jour. Pour éliminer la possibilité d'un redémarrage forcé de tous les noeuds, assurez-vous que le kernel le plus récent est installé et en cours d'exécution avant de lancer la phase 0 de DeepSea.
  </para>

  <tip>
   <title><command>zypper patch</command></title>
   <para>
    Si vous préférez mettre à jour le système en utilisant la commande <command>zypper patch</command>, ajoutez à la ligne suivante au fichier <filename>/srv/pillar/ceph/stack/global.yml</filename> :
   </para>
<screen>update_method_init: zypper-patch</screen>
  </tip>

  <para>
   Vous pouvez modifier le comportement de redémarrage par défaut de la phase 0 de DeepSea, en ajoutant les lignes suivantes au fichier <filename>/srv/pillar/ceph/stack/global.yml</filename> :
  </para>

<screen>stage_prep_master: default-update-no-reboot
stage_prep_minion: default-update-no-reboot</screen>

  <para>
   <literal>stage_prep_master</literal> définit le comportement de la phase 0 de Salt Master, tandis que <literal>stage_prep_minion</literal> définit le comportement de tous les minions. Tous les paramètres disponibles sont les suivants :
  </para>

  <variablelist>
   <varlistentry>
    <term>default</term>
    <listitem>
     <para>
      Installe les mises à jour et redémarre le système après la mise à jour.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-update-no-reboot</term>
    <listitem>
     <para>
      Installe les mises à jour sans redémarrer.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-reboot</term>
    <listitem>
     <para>
      Redémarre sans installer les mises à jour.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-no-reboot</term>
    <listitem>
     <para>
      N'installe pas de mises à jour et ne redémarre pas.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-salt-cluster-reboot">
  <title>Arrêt ou redémarrage de la grappe</title>

  <para>
   Dans certains cas, il faudra peut-être arrêter ou redémarrer l'ensemble de la grappe. Nous vous recommandons de contrôler soigneusement les dépendances des services en cours d'exécution. Les étapes suivantes fournissent un aperçu de l'arrêt et du démarrage de la grappe :
  </para>

  <procedure>
   <step>
    <para>
     Ordonnez à la grappe Ceph de ne pas marquer les OSD comme étant hors service :
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd set noout</screen>
   </step>
   <step>
    <para>
     Arrêtez les daemons et les noeuds dans l'ordre suivant :
    </para>
    <orderedlist>
     <listitem>
      <para>
       Clients de stockage
      </para>
     </listitem>
     <listitem>
      <para>
       Passerelles, par exemple NFS Ganesha ou Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Serveur de métadonnées
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Si nécessaire, effectuez des tâches de maintenance.
    </para>
   </step>
   <step>
    <para>
     Démarrez les noeuds et les serveurs dans l'ordre inverse du processus d'arrêt :
    </para>
    <orderedlist>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Serveur de métadonnées
      </para>
     </listitem>
     <listitem>
      <para>
       Passerelles, par exemple NFS Ganesha ou Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Clients de stockage
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Supprimez l'indicateur noout :
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd unset noout</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ds-custom-cephconf">
  <title>Fichier <filename>ceph.conf</filename> personnalisé</title>

  <para>
   Si vous devez personnaliser des paramètres dans le fichier <filename>ceph.conf</filename>, vous pouvez le faire en modifiant les fichiers de configuration dans le répertoire <filename>/srv/salt/ceph/configuration/files/ceph.conf.d</filename> :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     global.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mon.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mgr.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mds.conf
    </para>
   </listitem>
   <listitem>
    <para>
     osd.conf
    </para>
   </listitem>
   <listitem>
    <para>
     client.conf
    </para>
   </listitem>
   <listitem>
    <para>
     rgw.conf
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title><filename>rgw.conf</filename> exclusif</title>
   <para>
    La passerelle Object Gateway est très flexible et se démarque des autres sections de <filename>ceph.conf</filename>. Tous les autres composants Ceph ont des en-têtes statiques, tels que <literal>[lun]</literal> ou <literal>[osd]</literal>. La passerelle Object Gateway possède des en-têtes uniques, tels que <literal>[client.rgw.rgw1]</literal>. Cela signifie que le fichier <filename>rgw.conf</filename> nécessite une entrée d'en-tête. Reportez-vous au fichier <filename>/srv/salt/ceph/configuration/files/rgw.conf</filename> pour obtenir un exemple.
   </para>
  </note>

  <important>
   <title>exécution de la phase 3</title>
   <para>
    Après avoir apporté des modifications personnalisées aux fichiers de configuration mentionnés ci-dessus, exécutez la phase 3 pour appliquer ces modifications aux noeuds de la grappe :
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
  </important>

  <para>
   Ces fichiers sont inclus dans le fichier modèle <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> et correspondent aux différentes sections acceptées par le fichier de configuration Ceph. Si vous placez un extrait de configuration dans le fichier approprié, DeepSea sera en mesure de la copier dans la section appropriée. Il est inutile d'ajouter des en-têtes de section.
  </para>

  <tip>
   <para>
    Pour appliquer des options de configuration uniquement à des instances spécifiques d'un daemon, ajoutez un en-tête tel que <literal>[osd.1]</literal>. Les options de configuration suivantes ne seront appliquées qu'au daemon OSD ayant l'ID 1.
   </para>
  </tip>

  <sect2>
   <title>Remplacement des valeurs par défaut</title>
   <para>
    Dans une section, les instructions les plus récentes remplacent les plus anciennes. Par conséquent, il est possible de remplacer la configuration par défaut comme indiqué dans le modèle <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>. Par exemple, pour désactiver l'authentification cephx, ajoutez les trois lignes suivantes au fichier <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename> :
   </para>
<screen>auth cluster required = none
auth service required = none
auth client required = none</screen>
  </sect2>

  <sect2>
   <title>Inclusion des fichiers de configuration</title>
   <para>
    Si vous devez appliquer un grand nombre de configurations personnalisées, utilisez les instructions include suivantes dans les fichiers de configuration personnalisés afin de faciliter la gestion des fichiers. Voici un exemple de fichier <filename>osd.conf</filename> :
   </para>
<screen>[osd.1]
{% include "ceph/configuration/files/ceph.conf.d/osd1.conf" ignore missing %}
[osd.2]
{% include "ceph/configuration/files/ceph.conf.d/osd2.conf" ignore missing %}
[osd.3]
{% include "ceph/configuration/files/ceph.conf.d/osd3.conf" ignore missing %}
[osd.4]
{% include "ceph/configuration/files/ceph.conf.d/osd4.conf" ignore missing %}</screen>
   <para>
    Dans l'exemple précédent, les fichiers <filename>osd1.conf</filename>, <filename>osd2.conf</filename>, <filename>osd3.conf</filename> et <filename>osd4.conf</filename> contiennent les options de configuration propres à l'OSD connexe.
   </para>
   <tip>
    <title>configuration d'exécution</title>
    <para>
     Les modifications apportées aux fichiers de configuration de Ceph prennent effet après le redémarrage des daemons Ceph connexes. Reportez-vous à la <xref linkend="ceph-config-runtime"/> pour plus d'informations sur la modification de la configuration de l'exécution de Ceph.
    </para>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-config-runtime">
  <title>Configuration de l'exécution de Ceph</title>

  <para>
   La <xref linkend="ds-custom-cephconf"/> décrit la procédure d'ajout de modifications au fichier de configuration Ceph <filename>ceph.conf</filename>. Cependant, le comportement réel de la grappe n'est pas déterminé par l'état actuel du fichier <filename>ceph.conf</filename>, mais par la configuration stockée en mémoire pour les daemons Ceph en cours d'exécution.
  </para>

  <para>
   Vous pouvez interroger un daemon Ceph individuel pour un paramètre de configuration particulier à l'aide du <emphasis>socket admin</emphasis> sur le noeud où le daemon est en cours d'exécution. Par exemple, la commande suivante obtient la valeur du paramètre de configuration <option>osd_max_write_size</option> à partir du daemon nommé <literal>osd.0</literal> :
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/ceph-osd.0.asok \
config get osd_max_write_size
{
  "osd_max_write_size": "90"
}</screen>

  <para>
   Vous pouvez aussi <emphasis>modifier</emphasis> les paramètres des daemons au moment de l'exécution. N'oubliez pas que cette modification est temporaire et sera perdue après le prochain redémarrage du daemon. Par exemple, la commande suivante modifie le paramètre <option>osd_max_write_size</option> sur « 50 » pour tous les OSD de la grappe :
  </para>

<screen><prompt>root # </prompt>ceph tell osd.* injectargs --osd_max_write_size 50</screen>

  <warning>
   <title><command>injectargs</command> n'est pas fiable</title>
   <para>
    Malheureusement, la modification des paramètres de grappe n'est pas fiable à 100 % avec la commande <command>injectargs</command>. Si vous devez vous assurer que le paramètre modifié est actif, modifiez-le dans le fichier de configuration et redémarrez tous les daemons de la grappe.
   </para>
  </warning>
 </sect1>
</chapter>
