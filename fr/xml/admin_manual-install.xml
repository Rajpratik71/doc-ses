<?xml version="1.0" encoding="UTF-8"?>
<appendix xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_manual-install.xml" version="5.0" xml:id="app-storage-manual-inst">
 <title>Exemple de procédure d'installation manuelle de Ceph</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>oui</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  La procédure suivante présente les commandes dont vous avez besoin pour installer la grappe de stockage Ceph manuellement.
 </para>
 <procedure>
  <step>
   <para>
    Générez les secrets de clés des services Ceph que vous prévoyez d'exécuter. Vous pouvez utiliser la commande suivante pour le générer :
   </para>
<screen>python -c "import os ; import struct ; import time; import base64 ; \
 key = os.urandom(16) ; header = struct.pack('&lt;hiih',1,int(time.time()),0,len(key)) ; \
 print base64.b64encode(header + key)"</screen>
  </step>
  <step>
   <para>
    Ajoutez les clés aux trousseaux associés. D'abord pour <systemitem class="username">client.admin</systemitem>, puis pour les moniteurs et enfin pour les autres services associés, tels qu'OSD, Object Gateway ou MDS :
   </para>
<screen>ceph-authtool -n client.admin \
 --create-keyring /etc/ceph/ceph.client.admin.keyring \
 --cap mds 'allow *' --cap mon 'allow *' --cap osd 'allow *'
ceph-authtool -n mon. \
 --create-keyring /var/lib/ceph/bootstrap-mon/ceph-osceph-03.keyring \
 --set-uid=0 --cap mon 'allow *'
ceph-authtool -n client.bootstrap-osd \
 --create-keyring /var/lib/ceph/bootstrap-osd/ceph.keyring \
 --cap mon 'allow profile bootstrap-osd'
ceph-authtool -n client.bootstrap-rgw \
 --create-keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring \
 --cap mon 'allow profile bootstrap-rgw'
ceph-authtool -n client.bootstrap-mds \
 --create-keyring /var/lib/ceph/bootstrap-mds/ceph.keyring \
 --cap mon 'allow profile bootstrap-mds'</screen>
  </step>
  <step>
   <para>
    Créez une base de données monmap de tous les moniteurs d'une grappe :
   </para>
<screen>monmaptool --create --fsid eaac9695-4265-4ca8-ac2a-f3a479c559b1 \
 /tmp/tmpuuhxm3/monmap
monmaptool --add osceph-02 192.168.43.60 /tmp/tmpuuhxm3/monmap
monmaptool --add osceph-03 192.168.43.96 /tmp/tmpuuhxm3/monmap
monmaptool --add osceph-04 192.168.43.80 /tmp/tmpuuhxm3/monmap</screen>
  </step>
  <step>
   <para>
    Créez un trousseau de clés dans lequel vous allez importer les trousseaux de l'administrateur et des moniteurs. Utilisez-le alors pour démarrer les moniteurs :
   </para>
<screen>ceph-authtool --create-keyring /tmp/tmpuuhxm3/keyring \
 --import-keyring /var/lib/ceph/bootstrap-mon/ceph-osceph-03.keyring
ceph-authtool /tmp/tmpuuhxm3/keyring \
 --import-keyring /etc/ceph/ceph.client.admin.keyring
sudo -u ceph ceph-mon --mkfs -i osceph-03 \
 --monmap /tmp/tmpuuhxm3/monmap --keyring /tmp/tmpuuhxm3/keyring
systemctl restart ceph-mon@osceph-03</screen>
  </step>
  <step>
   <para>
    Vérifiez l'état des moniteurs dans <systemitem class="daemon">systemd</systemitem> :
   </para>
<screen>systemctl show --property ActiveState ceph-mon@osceph-03</screen>
  </step>
  <step>
   <para>
    Vérifiez si Ceph est en cours d'exécution et signale l'état du moniteur :
   </para>
<screen>ceph --cluster=ceph \
 --admin-daemon /var/run/ceph/ceph-mon.osceph-03.asok mon_status</screen>
  </step>
  <step>
   <para>
    Vérifiez l'état de services en particulier à l'aide des clés existantes :
   </para>
<screen>ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin -f json-pretty status
[...]
ceph --connect-timeout 5 \
 --keyring /var/lib/ceph/bootstrap-mon/ceph-osceph-03.keyring \
 --name mon. -f json-pretty status</screen>
  </step>
  <step>
   <para>
    Importez le trousseau de clés à partir des services Ceph existants et vérifiez l'état :
   </para>
<screen>ceph auth import -i /var/lib/ceph/bootstrap-osd/ceph.keyring
ceph auth import -i /var/lib/ceph/bootstrap-rgw/ceph.keyring
ceph auth import -i /var/lib/ceph/bootstrap-mds/ceph.keyring
ceph --cluster=ceph \
 --admin-daemon /var/run/ceph/ceph-mon.osceph-03.asok mon_status
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin -f json-pretty status</screen>
  </step>
  <step>
   <para>
    Préparez les disques/partitions pour les OSD en vous appuyant sur le système de fichiers XFS :
   </para>
<screen>ceph-disk -v prepare --fs-type xfs --data-dev --cluster ceph \
 --cluster-uuid eaac9695-4265-4ca8-ac2a-f3a479c559b1 /dev/vdb
ceph-disk -v prepare --fs-type xfs --data-dev --cluster ceph \
 --cluster-uuid eaac9695-4265-4ca8-ac2a-f3a479c559b1 /dev/vdc
[...]</screen>
  </step>
  <step>
   <para>
    Activez les partitions :
   </para>
<screen>ceph-disk -v activate --mark-init systemd --mount /dev/vdb1
ceph-disk -v activate --mark-init systemd --mount /dev/vdc1</screen>
  </step>
  <step>
   <para>
    Pour SUSE Enterprise Storage 2.1 et versions antérieures, créez les réserves par défaut :
   </para>
<screen>ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .users.swift 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .intent-log 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .rgw.gc 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .users.uid 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .rgw.control 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .users 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .usage 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .log 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .rgw 16 16</screen>
  </step>
  <step>
   <para>
    Créez la clé d'instance Object Gateway à partir de la clé d'amorçage :
   </para>
<screen>ceph --connect-timeout 5 --cluster ceph --name client.bootstrap-rgw \
 --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create \
 client.rgw.0dc1e13033d2467eace46270f0048b39 osd 'allow rwx' mon 'allow rw' \
 -o /var/lib/ceph/radosgw/ceph-rgw.<replaceable>rgw_name</replaceable>/keyring
  </screen>
  </step>
  <step>
   <para>
    Activez et démarrez Object Gateway :
   </para>
<screen>systemctl enable ceph-radosgw@rgw.<replaceable>rgw_name</replaceable>
systemctl start ceph-radosgw@rgw.<replaceable>rgw_name</replaceable></screen>
  </step>
  <step>
   <para>
    Le cas échéant, créez la clé d'instance MDS à partir de la clé d'amorçage, puis activez-la et démarrez-la :
   </para>
<screen>ceph --connect-timeout 5 --cluster ceph --name client.bootstrap-mds \
 --keyring /var/lib/ceph/bootstrap-mds/ceph.keyring auth get-or-create \
 mds.mds.<replaceable>rgw_name</replaceable> osd 'allow rwx' mds allow mon \
 'allow profile mds' \
 -o /var/lib/ceph/mds/ceph-mds.<replaceable>rgw_name</replaceable>/keyring
systemctl enable ceph-mds@mds.<replaceable>rgw_name</replaceable>
systemctl start ceph-mds@mds.<replaceable>rgw_name</replaceable></screen>
  </step>
 </procedure>
</appendix>
