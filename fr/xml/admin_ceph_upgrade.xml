<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Mise à jour à partir de versions précédentes</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>modification</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>oui</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Ce chapitre présente les étapes à suivre pour mettre à niveau SUSE Enterprise Storage à partir des versions précédentes vers la version actuelle.
 </para>
 <sect1 xml:id="ceph-upgrade-relnotes">
  <title>Lecture des notes de version</title>

  <para>
   Les notes de version contiennent des informations supplémentaires sur les modifications apportées depuis la version précédente de SUSE Enterprise Storage. Consultez les notes de version pour vérifier les aspects suivants :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Votre matériel doit tenir compte de certaines considérations spéciales.
    </para>
   </listitem>
   <listitem>
    <para>
     Les paquetages logiciels utilisés ont été considérablement modifiés.
    </para>
   </listitem>
   <listitem>
    <para>
     Des précautions spéciales sont nécessaires pour votre installation.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Les notes de version incluent également des informations de dernière minute qui, faute de temps, n'ont pas pu être intégrées au manuel. Elles contiennent également des notes concernant les problèmes connus.
  </para>

  <para>
   Après avoir installé le paquetage <package>release-notes-ses</package>, les notes de version sont disponibles en local dans le répertoire <filename>/usr/share/doc/release-notes</filename> ou en ligne à l'adresse <link xlink:href="https://www.suse.com/releasenotes/"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-upgrade-general">
  <title>Procédure générale de mise à niveau</title>

  <para>
   Tenez compte des éléments suivants avant de lancer la procédure de mise à niveau :
  </para>

  <variablelist>
   <varlistentry>
    <term>Ordre de mise à niveau</term>
    <listitem>
     <para>
      Avant de mettre à niveau la grappe Ceph, les serveurs SUSE Linux Enterprise Server et SUSE Enterprise Storage sous-jacents doivent être correctement enregistrés auprès de SCC ou SMT. Vous pouvez mettre à niveau les daemons de la grappe alors que celle-ci est en ligne et en service. Certains types de daemons dépendent d'autres. Par exemple, les daemons Ceph Object Gateway dépendent des daemons Ceph Monitor et Ceph OSD. Il est recommandé de mettre à niveau les différentes instances dans l'ordre suivant :
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        Ceph Monitor
       </para>
      </listitem>
      <listitem>
       <para>
        Ceph Manager
       </para>
      </listitem>
      <listitem>
       <para>
        Ceph OSD
       </para>
      </listitem>
      <listitem>
       <para>
        Serveur de métadonnées (MDS)
       </para>
      </listitem>
      <listitem>
       <para>
        Object Gateway
       </para>
      </listitem>
      <listitem>
       <para>
        Passerelle iSCSI
       </para>
      </listitem>
      <listitem>
       <para>
        NFS Ganesha
       </para>
      </listitem>
     </orderedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Suppression des instantanés de système d'exploitation inutiles</term>
    <listitem>
     <para>
      Supprimez les instantanés de système de fichiers non nécessaires sur les partitions de système d'exploitation des noeuds. Vous êtes ainsi sûr de disposer de suffisamment d'espace disque pendant la mise à niveau.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Vérification de la santé de la grappe</term>
    <listitem>
     <para>
      Il est recommandé de vérifier l'état de santé de la grappe avant d'entamer la procédure de mise à niveau.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Mise à niveau un par un</term>
    <listitem>
     <para>
      Il est recommandé de mettre à niveau tous les daemons d'un type spécifique, par exemple tous les daemons Monitor ou tous les daemons OSD, un par un, afin de vérifier qu'ils appartiennent tous à la même version. Il est également recommandé de mettre à niveau tous les daemons de votre grappe avant d'essayer d'utiliser de nouvelles fonctionnalités dans une version.
     </para>
     <para>
      Une fois tous les daemons d'un type spécifique mis à niveau, vérifiez leur état.
     </para>
     <para>
      Vérifiez que chaque daemon Monitor a rejoint le quorum une fois que toutes les instances de ce type ont été mises à niveau :
     </para>
<screen><prompt>root # </prompt>ceph mon stat</screen>
     <para>
      Vérifiez que chaque daemon Ceph OSD a rejoint la grappe une fois que toutes les instances de ce type ont été mises à niveau :
     </para>
<screen><prompt>root # </prompt>ceph osd stat</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>
     Définition du drapeau <option>require-osd-release luminous</option>
    </term>
    <listitem>
     <para>
      Lorsque le dernier OSD est mis à niveau vers SUSE Enterprise Storage 5, les noeuds de moniteur détectent que tous les OSD exécutent la version « luminous » de Ceph et peuvent avertir que le drapeau <option>require-osd-release luminous</option> n'est pas défini. Dans ce cas, vous devez définir manuellement ce drapeau pour reconnaître que, maintenant que la grappe a été mise à niveau vers « luminous », elle ne peut pas être rétrogradée en Ceph « jewel ». Définissez le drapeau en exécutant la commande suivante :
     </para>
<screen><prompt>root@minion &gt; </prompt>sudo ceph osd require-osd-release luminous</screen>
     <para>
      Une fois la commande terminée, l'avertissement disparaît.
     </para>
     <para>
      Sur les nouvelles installations de SUSE Enterprise Storage 5, ce drapeau est défini automatiquement lorsque les daemons Ceph Monitor créent l'osdmap initial. Aucune action de l'utilisateur final n'est alors nécessaire.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="ds-migrate-osd-encrypted">
  <title>Chiffrement des OSD lors de la mise à niveau</title>

  <para>
   À compter de SUSE Enterprise Storage 5, les OSD sont déployés par défaut en utilisant BlueStore au lieu de FileStore. Bien que BlueStore prenne en charge le chiffrement, les Ceph OSD sont déployés par défaut sans chiffrement. La procédure suivante décrit les étapes de chiffrement des OSD pendant le processus de mise à niveau. Supposons que les données et les disques WAL/DB à utiliser pour le déploiement de l'OSD sont propres, sans partitions. Si le disque a déjà été utilisé, effacez-le en suivant la procédure décrite à l'<xref linkend="deploy-wiping-disk"/>.
  </para>

  <important>
   <title>un OSD à la fois</title>
   <para>
    Vous devez déployer les OSD chiffrés un par un, et non simultanément, car les données des OSD sont déchargées et la grappe passe par plusieurs itérations de rééquilibrage.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Déterminez les valeurs <option>bluestore block db size</option> et <option>bluestore block wal size</option> pour votre déploiement, puis ajoutez-les au fichier <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename> sur Salt Master. Les valeurs doivent être spécifiées en octets.
    </para>
<screen>
[global]
bluestore block db size = 48318382080
bluestore block wal size = 2147483648
</screen>
    <para>
     Pour plus d'informations sur la personnalisation du fichier <filename>ceph.conf</filename>, reportez-vous au <xref linkend="ds-custom-cephconf"/>.
    </para>
   </step>
   <step>
    <para>
     Exécutez la phase 3 de DeepSea pour distribuer les modifications :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
   </step>
   <step>
    <para>
     Vérifiez que le fichier <filename>ceph.conf</filename> est mis à jour sur les noeuds OSD pertinents :
    </para>
<screen>
<prompt>root@minion &gt; </prompt>cat /etc/ceph/ceph.conf
</screen>
   </step>
   <step>
    <para>
     Modifiez les fichiers *.yml du répertoire <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions</filename> qui sont pertinents pour les OSD que vous chiffrez. Vérifiez leur chemin par rapport à celui défini dans le fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> pour vous assurer que vous modifiez les fichiers *.yml appropriés.
    </para>
    <important>
     <title>Identificateurs de disque longs</title>
     <para>
      Lors de l'identification des disques OSD dans les fichiers <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/*.yml</filename>, utilisez des identificateurs de disque longs.
     </para>
    </important>
    <para>
     Vous trouverez ci-dessous un exemple de configuration d'un OSD. Notez que, puisque nous utilisons le chiffrement, les options <option>db_size</option> et <option>wal_size</option> sont supprimées :
    </para>
<screen>
ceph:
 storage:
   osds:
     /dev/disk/by-id/scsi-SDELL_PERC_H730_Mini_007027b1065faa972100d34d7aa06d86:
       format: bluestore
       encryption: dmcrypt
       db: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
       wal: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
     /dev/disk/by-id/scsi-SDELL_PERC_H730_Mini_00d146b1065faa972100d34d7aa06d86:
       format: bluestore
       encryption: dmcrypt
       db: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
       wal: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
</screen>
   </step>
   <step>
    <para>
     Déployez les nouveaux OSD de stockage de blocs avec chiffrement en exécutant les phases 2 et 3 de DeepSea :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
    <para>
     Vous pouvez surveiller la progression avec <command>ceph -s</command> ou <command>ceph osd tree</command>. Il est essentiel de laisser la grappe se rééquilibrer avant de répéter le processus sur le prochain noeud OSD.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5">
  <title>Mise à niveau de SUSE Enterprise Storage 4 (déploiement DeepSea) vers la version 5</title>

  <important xml:id="u4to5-softreq">
   <title>configuration logicielle requise</title>
   <para>
    Vous devez disposer des logiciels suivants installés et mis à jour avec les dernières versions des paquetages sur tous les noeuds Ceph à mettre à niveau avant de lancer la procédure de mise à niveau :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
   <para>
    En outre, avant de commencer la mise à niveau, vous devez mettre à niveau le noeud Salt Master vers SUSE Linux Enterprise Server 12 SP3 et SUSE Enterprise Storage 5 en exécutant <command>zypper migration</command> (ou votre méthode préférée de mise à niveau).
   </para>
  </important>

  <warning>
   <title>points à prendre en compte avant la mise à niveau</title>
   <itemizedlist>
    <listitem>
     <para>
      Vérifiez si le service AppArmor est en cours d'exécution et désactivez-le sur chaque noeud de la grappe. Démarrez le module YaST AppArmor, sélectionnez <guimenu>Settings</guimenu> (Paramètres), puis désactivez la case à cocher <guimenu>Enable Apparmor</guimenu> (Activer Apparmor). Confirmez en cliquant sur <guimenu>Done</guimenu> (Terminé).
     </para>
     <para>
      Notez que SUSE Enterprise Storage ne fonctionnera <emphasis>pas</emphasis> si AppArmor est activé.
     </para>
    </listitem>
    <listitem>
     <para>
      Bien que la grappe soit entièrement fonctionnelle pendant la mise à niveau, DeepSea définit le drapeau « noout » qui empêche Ceph de rééquilibrer les données pendant le temps hors service et évite ainsi les transferts de données inutiles.
     </para>
    </listitem>
    <listitem>
     <para>
      Pour optimiser le processus de mise à niveau, DeepSea met à niveau les noeuds dans l'ordre, en fonction de leur rôle assigné tel que recommandé par Ceph en amont : MON, MGR, OSD, MDS, RGW, IGW et NFS Ganesha.
     </para>
     <para>
      Notez que DeepSea ne peut pas empêcher la violation de l'ordre spécifié si un noeud exécute plusieurs services.
     </para>
    </listitem>
    <listitem>
     <para>
      Bien que la grappe Ceph soit opérationnelle lors de la mise à niveau, les noeuds peuvent être redémarrés afin d'appliquer des nouvelles versions du kernel, par exemple. Pour réduire les opérations d'E/S en attente, il est recommandé de refuser les demandes entrantes pendant la durée du processus de mise à niveau.
     </para>
    </listitem>
    <listitem>
     <para>
      La mise à niveau de la grappe peut prendre beaucoup de temps : environ le temps nécessaire pour mettre à niveau une machine multiplié par le nombre de noeuds de la grappe.
     </para>
    </listitem>
    <listitem>
     <para>
      À compter de Ceph Luminous, l'option de configuration <option>osd crush location</option> n'est plus prise en charge. Mettez à jour vos fichiers de configuration DeepSea afin d'utiliser <command>crush location</command> avant la mise à niveau.
     </para>
    </listitem>
   </itemizedlist>
  </warning>

  <para>
   Pour mettre à niveau la grappe SUSE Enterprise Storage 4 vers la version 5, procédez comme suit :
  </para>

  <procedure>
   <step>
    <para>
     Définissez le nouvel ordre de tri des objets internes, puis exécutez :
    </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    <tip>
     <para>
      Pour vérifier que la commande a réussi, il est recommandé d'exécuter :
     </para>
<screen><prompt>root # </prompt>ceph osd dump --format json-pretty | grep sortbitwise
 "flags": "sortbitwise,recovery_deletes,purged_snapdirs",</screen>
    </tip>
   </step>
   <step>
    <para>
     À l'aide de <command>rpm -q deepsea</command>, vérifiez que la version du paquetage DeepSea sur le noeud Salt Master démarre avec au moins la valeur <literal>0.7</literal>. Par exemple :
    </para>
<screen><prompt>root # </prompt>rpm -q deepsea
deepsea-0.7.27+git.0.274c55d-5.1</screen>
    <para>
     Si le numéro de version du paquetage DeepSea commence par 0.6, vérifiez si vous avez correctement migré le noeud Salt Master vers SUSE Linux Enterprise Server 12 SP3 et SUSE Enterprise Storage 5 (reportez-vous à la note <xref linkend="u4to5-softreq"/> au début de cette section). Il s'agit d'une condition requise qui doit être terminée avant de lancer la procédure de mise à niveau.
    </para>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Si vous avez enregistré vos systèmes avec SUSEConnect et que vous utilisez SCC/SMT, aucune action supplémentaire ne doit être entreprise. Passez à l'<xref linkend="step-updatepillar"/>.
      </para>
     </step>
     <step>
      <para>
       Si vous n'utilisez <emphasis role="bold">pas</emphasis> SCC/SMT, mais un Media-ISO ou une autre source de paquetage, ajoutez manuellement les dépôts suivants : SLE12-SP3 Base, SLE12-SP3 Update, SES5 Base et SES5 Update. Vous pouvez le faire avec la commande <command>zypper</command>. Tout d'abord, supprimez tous les dépôts logiciels existants, puis ajoutez les nouveaux dépôts requis et, enfin, rafraîchissez les sources des dépôts :
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
      <para>
       Modifiez ensuite vos données Pillar afin d'utiliser une autre stratégie. Éditez
      </para>
<screen>/srv/pillar/ceph/stack/<replaceable>name_of_cluster</replaceable>/cluster.yml</screen>
      <para>
       et ajoutez la ligne suivante :
      </para>
<screen>upgrade_init: zypper-dup</screen>
      <tip>
       <para>
        La stratégie <literal>zypper-dup</literal> vous oblige à ajouter manuellement les derniers dépôts logiciels, tandis que la stratégie <literal>zypper-migration</literal> par défaut repose sur les dépôts fournis par SCC/SMT.
       </para>
      </tip>
     </step>
    </substeps>
   </step>
   <step xml:id="step-updatepillar">
    <para>
     Mettez à jour votre interface Pillar :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> saltutil.sync_all</screen>
    <para>
     Reportez-vous à la <xref linkend="ds-minion-targeting"/> pour plus d'informations sur le ciblage des minions Salt.
    </para>
   </step>
   <step>
    <para>
     Vérifiez que l'écriture sur Pillar s'est bien déroulée :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.get upgrade_init</screen>
    <para>
     La sortie de la commande doit refléter l'entrée que vous avez ajoutée.
    </para>
   </step>
   <step>
    <para>
     Mettez à niveau les minions Salt :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> state.apply ceph.updates.salt</screen>
   </step>
   <step>
    <para>
     Vérifiez que tous les minions Salt sont mis à niveau :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> test.version</screen>
   </step>
   <step>
    <para>
     Incluez les minions Salt de la grappe. Pour plus d'informations, reportez-vous à la <xref linkend="ds-minion-targeting"/> de la <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Démarrez la mise à niveau de SUSE Linux Enterprise Server et de Ceph :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.maintenance.upgrade</screen>
    <tip>
     <title>nouvelle exécution lors du redémarrage</title>
     <para>
      Si le processus entraîne le redémarrage de Salt Master, exécutez à nouveau la commande pour redémarrer le processus de mise à niveau pour les minions Salt.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Vérifiez qu'AppArmor est désactivé et arrêté sur tous les noeuds après la mise à niveau :
    </para>
<screen><prompt>root # </prompt>systemctl disable apparmor.service
systemctl stop apparmor.service</screen>
   </step>
   <step>
    <para>
     Après la mise à niveau, les instances Ceph Manager ne sont pas encore installées. Pour obtenir un état de la grappe en bonne santé, procédez comme suit :
    </para>
    <substeps>
     <step>
      <para>
       Exécutez la phase 0 pour activer l'API REST Salt :
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
     </step>
     <step>
      <para>
       Exécuter la phase 1 pour créer le sous-répertoire <filename>role-mgr/</filename> :
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
     </step>
     <step>
      <para>
       Modifiez <guimenu>policy.cfg</guimenu> comme décrit à la <xref linkend="policy-configuration"/> et ajoutez un rôle Ceph Manager aux noeuds sur lesquels les instances Ceph Monitor sont déployées. En outre, ajoutez le rôle openATTIC à l'un des noeuds de la grappe. Pour plus d'informations, reportez-vous au <xref linkend="ceph-oa"/>.
      </para>
     </step>
     <step>
      <para>
       Exécutez la phase 2 pour mettre à jour l'interface Pillar :
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
     </step>
     <step>
      <para>
       DeepSea utilise désormais une approche différente pour générer le fichier de configuration <filename>ceph.conf</filename>. Pour plus d'informations, reportez-vous au <xref linkend="ds-custom-cephconf"/>.
      </para>
     </step>
     <step>
      <para>
       Exécutez la phase 3 pour déployer les instances Ceph Manager :
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     </step>
     <step>
      <para>
       Exécutez la phase 4 pour configurer correctement openATTIC :
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
     </step>
    </substeps>
    <note>
     <title>non mise en correspondance des fonctions de clés « caps » de Ceph</title>
     <para>
      Si <literal>ceph.stage.3</literal> échoue avec le message « Error EINVAL: entity client.bootstrap-osd exists but caps do not match » (Erreur EINVAL : l'entité client.bootstrap-osd existe, mais les caps ne correspondent pas), cela signifie que les fonctions de clés (caps) pour la grappe existante <literal>client.bootstrap.osd</literal> ne correspondent pas aux caps que DeepSea tentent de définir. Au-dessus du message d'erreur, dans le texte en rouge, vous pouvez voir un vidage de la commande <command>ceph auth</command> qui a échoué. Examinez cette commande pour vérifier l'ID de la clé et le fichier utilisé. Dans le cas de <literal>client.bootstrap-osd</literal>, la commande est :
     </para>
<screen><prompt>root # </prompt>ceph auth add client.bootstrap-osd \
 -i /srv/salt/ceph/osd/cache/bootstrap.keyring</screen>
     <para>
      Pour corriger les caps ne correspondant pas, vérifiez le contenu du fichier de porte-clés que DeepSea tente de déployer, par exemple :
     </para>
<screen><prompt>cephadm &gt; </prompt>cat /srv/salt/ceph/osd/cache/bootstrap.keyring
[client.bootstrap-osd]
     key = AQD6BpVZgqVwHBAAQerW3atANeQhia8m5xaigw==
     caps mgr = "allow r"
     caps mon = "allow profile bootstrap-osd"</screen>
     <para>
      Comparez ce fichier à la sortie de <command>ceph auth get client.bootstrap-osd</command> :
     </para>
<screen><prompt>root # </prompt>ceph auth get client.bootstrap-osd
exported keyring for client.bootstrap-osd
[client.bootstrap-osd]
     key = AQD6BpVZgqVwHBAAQerW3atANeQhia8m5xaigw==
     caps mon = "allow profile bootstrap-osd"</screen>
     <para>
      Notez que la dernière clé est manquante <literal>caps mgr = "allow r"</literal>. Pour corriger ce problème, exécutez :
     </para>
<screen><prompt>root # </prompt>ceph auth caps client.bootstrap-osd mgr \
 "allow r" mon "allow profile bootstrap-osd"</screen>
     <para>
      L'exécution de <literal>ceph.stage.3</literal> doit désormais réussir.
     </para>
     <para>
      Le même problème peut se produire avec les porte-clés MDS et Object Gateway lors de l'exécution de <literal>ceph.stage.4</literal>. La même procédure que ci-dessus s'applique : vérifiez la commande qui a échoué, le fichier de porte-clés en cours de déploiement et les caps de la clé existante. Exécutez ensuite <command>ceph auth caps</command> pour mettre à jour les caps de la clé existante pour qu'elles correspondent aux caps en cours de déploiement par DeepSea.
     </para>
    </note>
   </step>
  </procedure>

  <important>
   <title>échec de la mise à niveau</title>
   <para>
    Si la grappe est à l'état « HEALTH_ERR » pendant plus de 300 secondes, ou si l'un des services pour chaque rôle assigné est en panne pendant plus de 900 secondes, la mise à niveau a échoué. Dans ce cas, recherchez le problème, résolvez-le, puis exécutez à nouveau la procédure de mise à niveau. Notez que, dans les environnements virtualisés, les timeouts sont plus courts.
   </para>
  </important>

  <important>
   <title>redémarrage des OSD</title>
   <para>
    Après la mise à niveau vers SUSE Enterprise Storage 5, les OSD FileStore ont besoin d'environ cinq minutes de plus pour démarrer, car l'OSD effectue une conversion unique de ses fichiers sur disque.
   </para>
  </important>

  <tip>
   <title>vérification de la version des composants/noeuds de la grappe</title>
   <para>
    Lorsque vous devez trouver les versions de composants et de noeuds de grappe individuels, par exemple pour savoir si tous les noeuds sont sur le même niveau de correctif après la mise à niveau, vous pouvez exécuter :
   </para>
<screen><prompt>root@master # </prompt>salt-run status.report</screen>
   <para>
    La commande passe par les minions Salt connectés et analyse les numéros de version de Ceph, Salt et SUSE Linux Enterprise Server, puis fournit un rapport affichant la version de la majorité des noeuds et indiquant les noeuds dont la version est différente de la majorité.
   </para>
  </tip>

  <sect2 xml:id="filestore2bluestore">
   <title>Migration des OSD vers BlueStore</title>
   <para>
    OSD BlueStore est une nouvelle interface dorsale pour les daemons OSD. Il s'agit de l'option par défaut depuis la version 5 de SUSE Enterprise Storage. Comparé à FileStore, qui stocke des objets en tant que fichiers dans un système de fichiers XFS, BlueStore peut fournir des performances accrues, car il stocke les objets directement sur le périphérique de bloc sous-jacent. BlueStore utilise également d'autres fonctions, telles que la compression intégrée et les écrasements EC, qui ne sont pas disponibles avec FileStore.
   </para>
   <para>
    En particulier pour BlueStore, un OSD dispose d'un périphérique « wal » (Write Ahead Log) et d'un périphérique « db » (base de données RocksDB). La base de données RocksDB conserve les métadonnées pour un OSD BlueStore. Ces deux périphériques résident sur le même périphérique qu'un OSD par défaut, mais peuvent être placés sur un média plus rapide/différent.
   </para>
   <para>
    Dans SES5, FileStore et BlueStore sont tous deux pris en charge et il est possible que les OSD FileStore et BlueStore coexistent dans une seule grappe. Pendant la procédure de mise à niveau de SUSE Enterprise Storage, les OSD FileStore ne sont pas automatiquement convertis en OSD BlueStore. Sachez que les fonctions spécifiques à BlueStore ne seront pas disponibles sur les OSD qui n'ont pas été migrés vers BlueStore.
   </para>
   <para>
    Avant la conversion vers BlueStore, les OSD doivent exécuter SUSE Enterprise Storage 5. La conversion est un processus lent, car toutes les données sont réécrites deux fois. Bien que le processus de migration puisse prendre beaucoup de temps, il n'y a pas d'interruption de la grappe et tous les clients peuvent continuer à y accéder pendant cette période. Cependant, attendez-vous à des performances inférieures pendant la durée de la migration. Cela est dû au rééquilibrage et au renvoi des données de la grappe.
   </para>
   <para>
    Utilisez la procédure suivante pour migrer les OSD FileStore vers BlueStore :
   </para>
   <tip>
    <title>désactivation des mesures de sécurité</title>
    <para>
     Les commandes Salt nécessaires pour exécuter la migration sont bloquées par des mesures de sécurité. Pour désactiver ces précautions, exécutez la commande suivante :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disengage.safety
</screen>
   </tip>
   <procedure>
    <step>
     <para>
      Migrez les profils matériels :
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.policy</screen>
     <para>
      Cet exécuteur (runner) migre tous les profils matériels actuellement en cours d'utilisation par le fichier <filename>policy.cfg</filename>. Il traite <filename>policy.cfg</filename>, recherche tout profil matériel en utilisant la structure de données d'origine et le convertit en la nouvelle structure de données. Le résultat est un nouveau profil matériel nommé migrated-<replaceable>original_name</replaceable> (nom_origine). Le fichier <filename>policy.cfg</filename> est ainsi mis à jour.
     </para>
     <para>
      Si la configuration d'origine comportait des journaux distincts, la configuration BlueStore utilisera le même périphérique pour le « wal » et le « db » pour cet OSD.
     </para>
    </step>
    <step>
     <para>
      DeepSea migre les OSD en définissant leur pondération sur 0, ce qui « nettoie » les données jusqu'à ce que l'OSD soit vide. Vous pouvez migrer les OSD un par un ou bien, tous les OSD à la fois. Dans les deux cas, lorsque l'OSD est vide, l'orchestration le supprime, puis le recrée avec la nouvelle configuration.
     </para>
     <tip>
      <title>méthode recommandée</title>
      <para>
       Utilisez <command>ceph.migrate.nodes</command> si vous avez un grand nombre de noeuds de stockage physiques ou presque aucune donnée. Si un noeud représente moins de 10 % de votre capacité, les noeuds <command>ceph.migrate.nodes</command> peuvent être légèrement plus rapides en déplaçant toutes les données de ces OSD en parallèle.
      </para>
      <para>
       Si vous n'êtes pas sûr de la méthode à utiliser ou si le site possède peu de noeuds de stockage (par exemple, chaque noeud dispose de plus de 10 % des données de la grappe), sélectionnez <command>ceph.migrate.osds</command>.
      </para>
     </tip>
     <substeps>
      <step>
       <para>
        Pour migrer les OSD un à la fois, exécutez :
       </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.osds</screen>
      </step>
      <step>
       <para>
        Pour migrer tous les OSD sur chaque noeud en parallèle, exécutez :
       </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.nodes</screen>
      </step>
     </substeps>
     <tip>
      <para>
       Comme l'orchestration ne donne aucun retour sur la progression de la migration, utilisez
      </para>
<screen><prompt>root # </prompt>ceph osd tree</screen>
      <para>
       pour savoir quels OSD ont une pondération de zéro périodiquement.
      </para>
     </tip>
    </step>
   </procedure>
   <para>
    Après la migration vers BlueStore, le nombre d'objets restera le même et l'utilisation du disque sera presque la même.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5cephdeloy">
  <title>Mise à niveau de SUSE Enterprise Storage 4 (<command>déploiement ceph-deploy</command>) vers la version 5</title>

  <important>
   <title>configuration logicielle requise</title>
   <para>
    Vous devez disposer des logiciels suivants installés et mis à jour avec les dernières versions des paquetages sur tous les noeuds Ceph à mettre à niveau avant de lancer la procédure de mise à niveau :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Choisissez l'instance Salt Master de la grappe. Si votre grappe a déployé Calamari, le noeud Calamari <emphasis>est</emphasis> déjà le Salt Master. Sinon, le noeud admin à partir duquel vous avez exécuté la commande <command>ceph-deploy</command> deviendra le Salt Master.
   </para>
   <para>
    Avant de commencer la procédure ci-dessous, vous devez mettre à niveau le noeud Salt Master vers SUSE Linux Enterprise Server 12 SP3 et SUSE Enterprise Storage 5 en exécutant <command>zypper migration</command> (ou votre méthode préférée de mise à niveau).
   </para>
  </important>

  <para>
   Pour mettre à niveau la grappe SUSE Enterprise Storage 4 qui a été déployée avec <command>ceph-deploy</command> vers la version 5, procédez comme suit :
  </para>

  <procedure xml:id="upgrade4to5cephdeploy-all">
   <title>étapes à appliquer à tous les noeuds de la grappe (y compris le noeud Calamari)</title>
   <step>
    <para>
     Installez le paquetage <systemitem>salt</systemitem> à partir de SLE-12-SP2/SES4 :
    </para>
<screen><prompt>root # </prompt>zypper install salt</screen>
   </step>
   <step>
    <para>
     Installez le paquetage <systemitem>salt-minion</systemitem> à partir de SLE-12-SP2/SES4, puis activez et démarrez le service connexe :
    </para>
<screen><prompt>root # </prompt>zypper install salt-minion
<prompt>root # </prompt>systemctl enable salt-minion
<prompt>root # </prompt>systemctl start salt-minion</screen>
   </step>
   <step>
    <para>
     Assurez-vous que le nom d'hôte « salt » se résout sur l'adresse IP du noeud Salt Master. Si votre Salt Master n'est pas accessible par le nom d'hôte <literal>salt</literal>, modifiez le fichier <filename>/etc/salt/minion</filename> ou créez un fichier <filename>/etc/salt/minion.d/master.conf</filename> avec le contenu suivant :
    </para>
<screen>master: <replaceable>host_name_of_salt_master</replaceable></screen>
    <tip>
     <para>
      L'option <option>master:</option> est déjà définie dans <filename>/etc/salt/minion.d/calamari.conf</filename> pour les minions Salt existants. Le nom du fichier de configuration n'a pas d'importance, c'est le répertoire <filename>/etc/salt/minion.d/</filename> qui importe.
     </para>
    </tip>
    <para>
     Si vous avez apporté des modifications aux fichiers de configuration ci-dessus, redémarrez le service Salt sur tous les minions Salt :
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Si vous avez enregistré vos systèmes avec SUSEConnect et que vous utilisez SCC/SMT, aucune action supplémentaire ne doit être entreprise.
      </para>
     </step>
     <step>
      <para>
       Si vous n'utilisez <emphasis role="bold">pas</emphasis> SCC/SMT, mais un Media-ISO ou une autre source de paquetage, ajoutez manuellement les dépôts suivants : SLE12-SP3 Base, SLE12-SP3 Update, SES5 Base et SES5 Update. Vous pouvez le faire avec la commande <command>zypper</command>. Tout d'abord, supprimez tous les dépôts logiciels existants, puis ajoutez les nouveaux dépôts requis et, enfin, rafraîchissez les sources des dépôts :
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
     </step>
    </substeps>
   </step>
  </procedure>

  <procedure xml:id="upgrade4to5cephdeploy-admin">
   <title>étapes à appliquer au noeud Salt Master</title>
   <step>
    <para>
     Définissez le nouvel ordre de tri des objets internes, puis exécutez :
    </para>
<screen><prompt>root@master # </prompt>ceph osd set sortbitwise</screen>
    <tip>
     <para>
      Pour vérifier que la commande a réussi, il est recommandé d'exécuter :
     </para>
<screen><prompt>root@master # </prompt>ceph osd dump --format json-pretty | grep sortbitwise
 "flags": "sortbitwise,recovery_deletes,purged_snapdirs",</screen>
    </tip>
   </step>
   <step>
    <para>
     Mettez à niveau le noeud Salt Master vers SUSE Linux Enterprise Server 12 SP3 et SUSE Enterprise Storage 5. Pour les systèmes enregistrés sous SCC, utilisez <command>zypper migration</command>. Si vous indiquez manuellement les dépôts logiciels requis, utilisez <command>zypper dup</command>. Après la mise à niveau, assurez-vous que seuls les dépôts pour SUSE Linux Enterprise Server 12 SP3 et SUSE Enterprise Storage 5 sont actifs (et rafraîchis) sur le noeud Salt Master avant de poursuivre.
    </para>
   </step>
   <step>
    <para>
     S'il n'est pas déjà présent, installez le paquetage <systemitem>salt-master</systemitem>, puis activez et démarrez le service connexe :
    </para>
<screen><prompt>root@master # </prompt>zypper install salt-master
<prompt>root@master # </prompt>systemctl enable salt-master
<prompt>root@master # </prompt>systemctl start salt-master</screen>
   </step>
   <step>
    <para>
     Vérifiez la présence de tous les minions Salt en répertoriant leurs clés :
    </para>
<screen><prompt>root@master # </prompt>salt-key -L</screen>
   </step>
   <step>
    <para>
     Ajoutez toutes les clés des minions Salt à Salt Master, y compris le maître des minions :
    </para>
<screen><prompt>root@master # </prompt>salt-key -A -y</screen>
   </step>
   <step>
    <para>
     Assurez-vous que toutes les clés des minions Salt ont été acceptées :
    </para>
<screen><prompt>root@master # </prompt>salt-key -L</screen>
   </step>
   <step>
    <para>
     Assurez-vous que le logiciel du noeud Salt Master est à jour :
    </para>
<screen><prompt>root@master # </prompt>zypper migration</screen>
   </step>
   <step>
    <para>
     Installez le paquetage <systemitem>deepsea</systemitem> :
    </para>
<screen><prompt>root@master # </prompt>zypper install deepsea</screen>
   </step>
   <step>
    <para>
     Incluez les minions Salt de la grappe. Pour plus d'informations, reportez-vous à la <xref linkend="ds-minion-targeting"/> de la <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Importez la grappe existante <command>ceph-deploy</command> installée :
    </para>
<screen><prompt>root@master # </prompt>salt-run populate.engulf_existing_cluster</screen>
    <para>
     La commande effectue les opérations suivantes :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Distribuer tous les modules requis de Salt et DeepSea à tous les minions.
      </para>
     </listitem>
     <listitem>
      <para>
       Inspecter la grappe Ceph en cours d'exécution et remplir <filename>/srv/pillar/ceph/proposals</filename> avec une présentation de la grappe.
      </para>
      <para>
       Le fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> est créé avec des rôles correspondant à tous les services Ceph détectés en cours d'exécution. Consultez ce fichier pour vérifier que chacun de vos noeuds MON, OSD, RGW et MDS existants dispose des rôles appropriés. Les noeuds OSD seront importés dans le sous-répertoire <filename>profile-import/</filename>, afin que vous puissiez examiner les fichiers dans <filename>/srv/pillar/ceph/proposals/profile-import/cluster/</filename> et <filename>/srv/pillar/ceph/proposals/profile-import/stack/default/ceph/minions/</filename> pour confirmer que les OSD ont été correctement récupérés.
      </para>
      <note>
       <para>
        Le fichier <filename>policy.cfg</filename> généré ne s'applique qu'aux rôles des services Ceph détectés : role-mon, role-mgr, role-mds, role-rgw, role-admin et role-master pour le noeud Salt Master. Tous les autres rôles souhaités doivent être ajoutés manuellement au fichier (reportez-vous à la <xref linkend="policy-role-assignment"/>).
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       Le fichier <filename>ceph.conf</filename> de la grappe existante est enregistré dans <filename>/srv/salt/ceph/configuration/files/ceph.conf.import</filename>.
      </para>
     </listitem>
     <listitem>
      <para>
       Le fichier <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename> inclut le fsid de la grappe, la grappe et les réseaux publics, et indique également l'option <option>configuration_init: default-import</option>, ce qui fait que DeepSea utilise le fichier de configuration <filename>ceph.conf.import</filename> mentionné précédemment au lieu du modèle par défaut de DeepSea <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>.
      </para>
      <note>
       <title>fichier <filename>ceph.conf</filename> personnalisé</title>
       <para>
        Si vous avez besoin d'intégrer le fichier <filename>ceph.conf</filename> avec des modifications personnalisées, attendez que le processus d'importation/de mise à niveau se termine. Modifiez ensuite le fichier <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename> et commentez la ligne suivante :
       </para>
<screen>
configuration_init: default-import
</screen>
       <para>
        Enregistrez le fichier et suivez les instructions du <xref linkend="ds-custom-cephconf"/>.
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       Les différents porte-clés de la grappe sont enregistrés dans les répertoires suivants :
      </para>
<screen>/srv/salt/ceph/admin/cache/
/srv/salt/ceph/mon/cache/
/srv/salt/ceph/osd/cache/
/srv/salt/ceph/mds/cache/
/srv/salt/ceph/rgw/cache/</screen>
      <para>
       Vérifiez que les fichiers de porte-clés existent et qu'il n'existe <emphasis>aucun</emphasis> fichier de porte-clés dans le répertoire suivant (Ceph Manager n'existait pas avant SUSE Enterprise Storage 5) :
      </para>
<screen>
/srv/salt/ceph/mgr/cache/
</screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     La commande <command>salt-run populate.engulf_existing_clusterr</command> ne gère pas l'importation de la configuration openATTIC. Vous devez modifier manuellement le fichier <filename>policy.cfg</filename> et ajouter une ligne <literal>role-openattic</literal>. Pour plus d'informations, reportez-vous à la <xref linkend="policy-configuration"/>.
    </para>
   </step>

   <step>
    <para>
     La commande <command>salt-run populate.engulf_existing_cluster</command> ne gère pas l'importation de la configuration des passerelles iSCSI. Si votre grappe comporte des passerelles iSCSI, importez leur configuration manuellement :
    </para>
    <substeps>
     <step>
      <para>
       Sur l'un des noeuds de la passerelle iSCSI, exportez le fichier <filename>lrbd.conf</filename> actuel et copiez-le vers le noeud Salt Master :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o &gt;/tmp/lrbd.conf
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf admin:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
     </step>
     <step>
      <para>
       Sur le noeud Salt Master, ajoutez la configuration par défaut de la passerelle iSCSI à la configuration DeepSea :
      </para>
<screen>
<prompt>root@master # </prompt>mkdir -p /srv/pillar/ceph/stack/ceph/
<prompt>root@master # </prompt>echo 'igw_config: default-ui' &gt;&gt; /srv/pillar/ceph/stack/ceph/cluster.yml
<prompt>root@master # </prompt>chown salt:salt /srv/pillar/ceph/stack/ceph/cluster.yml
</screen>
     </step>
     <step>
      <para>
       Ajoutez les rôles de la passerelle iSCSI au fichier <filename>policy.cfg</filename> et enregistrez-le :
      </para>
<screen>
role-igw/stack/default/ceph/minions/ses-1.ses.suse.yml
role-igw/cluster/ses-1.ses.suse.sls
[...]
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Exécutez la phase 1 pour créer tous les rôles possibles :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Générez des sous-répertoires requis sous <filename>/srv/pillar/ceph/stack</filename> :
    </para>
<screen><prompt>root@master # </prompt>salt-run push.proposal</screen>
   </step>
   <step>
    <para>
     Vérifiez qu'il existe une grappe gérée par DeepSea en cours d'exécution avec des rôles correctement assignés :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.get roles</screen>
    <para>
     Comparez les résultats avec la disposition réelle de la grappe.
    </para>
   </step>
   <step>
    <para>
     Calamari conserve une tâche planifiée Salt en cours d'exécution pour vérifier l'état de la grappe. Supprimez la tâche :
    </para>
<screen>
<prompt>root@minion &gt; </prompt>salt <replaceable>target</replaceable> schedule.delete ceph.heartbeat
</screen>
   </step>
   <step>
    <para>
     À présent, suivez la procédure décrite à la <xref linkend="ceph-upgrade-4to5"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5crowbar">
  <title>Mise à niveau de SUSE Enterprise Storage 4 (déploiement Crowbar) vers la version 5</title>

  <important>
   <title>configuration logicielle requise</title>
   <para>
    Vous devez disposer des logiciels suivants installés et mis à jour avec les dernières versions des paquetages sur tous les noeuds Ceph à mettre à niveau avant de lancer la procédure de mise à niveau :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
  </important>

  <para>
   Pour mettre à niveau SUSE Enterprise Storage 4 déployé à l'aide de Crowbar vers la version 5, procédez comme suit :
  </para>

  <procedure>
   <step>
    <para>
     Pour chaque noeud Ceph (y compris le noeud Calamari), arrêtez et désactivez tous les services connexes à Crowbar :
    </para>
<screen>
<prompt>root@minion &gt; </prompt>sudo systemctl stop chef-client
<prompt>root@minion &gt; </prompt>sudo systemctl disable chef-client
<prompt>root@minion &gt; </prompt>sudo systemctl disable crowbar_join
<prompt>root@minion &gt; </prompt>sudo systemctl disable crowbar_notify_shutdown
</screen>
   </step>
   <step>
    <para>
     Pour chaque noeud Ceph (y compris le noeud Calamari), vérifiez que les dépôts logiciels pointent vers les produits SUSE Enterprise Storage 5 et SUSE Linux Enterprise Server 12 SP3. Si des dépôts pointant vers des anciennes versions des produits sont toujours présents, désactivez-les.
    </para>
   </step>
   <step>
    <para>
     Pour chaque noeud Ceph (y compris le noeud Calamari), vérifiez que le paquetage
     <package>salt-minion</package> est installé. Le cas échéant, installez-le :
    </para>
<screen><prompt>root@minion &gt; </prompt>sudo zypper in salt salt-minion</screen>
   </step>
   <step>
    <para>
     Pour les noeuds Ceph pour lesquels le paquetage <package>salt-minion</package>
     n'est pas installé, créez le fichier <filename>/etc/salt/minion.d/master.conf</filename> avec l'option <option>master</option> pointant vers le nom d'hôte du noeud Calamari complet :
    </para>
<screen>master: <replaceable>full_calamari_hostname</replaceable></screen>
    <tip>
     <para>
      L'option <option>master:</option> est déjà définie dans <filename>/etc/salt/minion.d/calamari.conf</filename> pour les minions Salt existants. Le nom du fichier de configuration n'a pas d'importance, c'est le répertoire <filename>/etc/salt/minion.d/</filename> qui importe.
     </para>
    </tip>
    <para>
     Activez et démarrez le service <systemitem class="daemon">salt-minion</systemitem> :
    </para>
<screen>
<prompt>root@minion &gt; </prompt>sudo systemctl enable salt-minion
<prompt>root@minion &gt; </prompt>sudo systemctl start salt-minion
</screen>
   </step>
   <step>
    <para>
     Sur le noeud Calamari, acceptez toutes les clés des minions Salt restantes :
    </para>
<screen>
<prompt>root@master # </prompt>salt-key -L
[...]
Unaccepted Keys:
d52-54-00-16-45-0a.example.com
d52-54-00-70-ac-30.example.com
[...]

<prompt>root@master # </prompt>salt-key -A
The following keys are going to be accepted:
Unaccepted Keys:
d52-54-00-16-45-0a.example.com
d52-54-00-70-ac-30.example.com
Proceed? [n/Y] y
Key for minion d52-54-00-16-45-0a.example.com accepted.
Key for minion d52-54-00-70-ac-30.example.com accepted.
</screen>
   </step>
   <step>
    <para>
     Si Ceph a été déployé sur le réseau public et qu'aucune interface VLAN n'est présente, ajoutez une interface VLAN sur le réseau public de Crowbar au noeud Calamari.
    </para>
   </step>
   <step>
    <para>
     Mettez à niveau le noeud Calamari vers SUSE Linux Enterprise Server 12 SP3 et SUSE Enterprise 5 à l'aide de <command>zypper migration</command> ou de votre méthode préférée. À ce stade, le noeud Calamari devient <emphasis>Salt Master</emphasis>. Après la mise à niveau, redémarrez Salt Master.
    </para>
   </step>
   <step>
    <para>
     Installez DeepSea sur Salt Master :
    </para>
<screen><prompt>root@master # </prompt>zypper in deepsea</screen>
   </step>
   <step>
    <para>
     Spécifiez l'option <option>deepsea_minions</option> afin d'inclure le groupe approprié de minions Salt dans les phases de déploiement. Pour plus d'informations, reportez-vous à la <xref linkend="ds-minion-targeting-dsminions"/>.
    </para>
   </step>
   <step>
    <para>
     DeepSea s'attend à ce que tous les noeuds Ceph aient un fichier <filename>/etc/ceph/ceph.conf</filename> identique. Crowbar déploie un fichier <filename>ceph.conf</filename> légèrement différent sur chaque noeud, vous devez donc les consolider :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Supprimez l'option <option>osd crush location hook</option>, elle a été incluse par Calamari.
      </para>
     </listitem>
     <listitem>
      <para>
       Supprimez l'option <option>public addr</option> de la section <literal>[mon]</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       Supprimez les numéros de port de l'option <option>mon host</option>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Si vous utilisiez l'instance Object Gateway, Crowbar a déployé un fichier distinct <filename>/etc/ceph/ceph.conf.radosgw</filename> pour garder les secrets keystone séparés du fichier <filename>ceph.conf</filename> type. Crowbar a également ajouté un fichier <filename>/etc/systemd/system/ceph-radosgw@.service</filename> personnalisé. Comme DeepSea ne le prend pas en charge, vous devez le supprimer :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Ajoutez toutes les sections <literal>[client.rgw...]</literal> du fichier <filename>ceph.conf.radosgw</filename> au fichier <filename>/etc/ceph/ceph.conf</filename> sur tous les noeuds.
      </para>
     </listitem>
     <listitem>
      <para>
       Sur le noeud Object Gateway, exécutez la commande suivante :
      </para>
<screen><prompt>root@minion &gt; </prompt>rm /etc/systemd/system/ceph-radosgw@.service
systemctl reenable ceph-radosgw@rgw.public.$<replaceable>hostname</replaceable></screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Vérifiez que <command>ceph status</command> fonctionne lorsqu'il est exécuté à partir de Salt Master :
    </para>
<screen><prompt>root@master # </prompt>ceph status
cluster a705580c-a7ae-4fae-815c-5cb9c1ded6c2
health HEALTH_OK
[...]
</screen>
   </step>
   <step>
    <para>
     Importez la grappe existante :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run populate.engulf_existing_cluster
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run push.proposal
</screen>
   </step>

   <step>
    <para>
     La commande <command>salt-run populate.engulf_existing_cluster</command> ne gère pas l'importation de la configuration des passerelles iSCSI. Si votre grappe comporte des passerelles iSCSI, importez leur configuration manuellement :
    </para>
    <substeps>
     <step>
      <para>
       Sur l'un des noeuds de la passerelle iSCSI, exportez le fichier <filename>lrbd.conf</filename> actuel et copiez-le vers le noeud Salt Master :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o &gt; /tmp/lrbd.conf
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf admin:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
     </step>
     <step>
      <para>
       Sur le noeud Salt Master, ajoutez la configuration par défaut de la passerelle iSCSI à la configuration DeepSea :
      </para>
<screen>
<prompt>root@master # </prompt>mkdir -p /srv/pillar/ceph/stack/ceph/
<prompt>root@master # </prompt>echo 'igw_config: default-ui' &gt;&gt; /srv/pillar/ceph/stack/ceph/cluster.yml
<prompt>root@master # </prompt>chown salt:salt /srv/pillar/ceph/stack/ceph/cluster.yml
</screen>
     </step>
     <step>
      <para>
       Ajoutez les rôles de la passerelle iSCSI au fichier <filename>policy.cfg</filename> et enregistrez-le :
      </para>
<screen>
role-igw/stack/default/ceph/minions/ses-1.ses.suse.yml
role-igw/cluster/ses-1.ses.suse.sls
[...]
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Si vous avez enregistré vos systèmes avec SUSEConnect et que vous utilisez SCC/SMT, aucune action supplémentaire ne doit être entreprise.
      </para>
     </step>
     <step>
      <para>
       Si vous n'utilisez <emphasis role="bold">pas</emphasis> SCC/SMT, mais un Media-ISO ou une autre source de paquetage, ajoutez manuellement les dépôts suivants : SLE12-SP3 Base, SLE12-SP3 Update, SES5 Base et SES5 Update. Vous pouvez le faire avec la commande <command>zypper</command>. Tout d'abord, supprimez tous les dépôts logiciels existants, puis ajoutez les nouveaux dépôts requis et, enfin, rafraîchissez les sources des dépôts :
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
      <para>
       Modifiez ensuite vos données Pillar afin d'utiliser une autre stratégie. Éditez
      </para>
<screen>/srv/pillar/ceph/stack/<replaceable>name_of_cluster</replaceable>/cluster.yml</screen>
      <para>
       et ajoutez la ligne suivante :
      </para>
<screen>upgrade_init: zypper-dup</screen>
      <tip>
       <para>
        La stratégie <literal>zypper-dup</literal> vous oblige à ajouter manuellement les derniers dépôts logiciels, tandis que la stratégie <literal>zypper-migration</literal> par défaut repose sur les dépôts fournis par SCC/SMT.
       </para>
      </tip>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Corrigez les grains host pour que DeepSea utilise des noms d'hôtes courts sur le réseau public pour les ID d'instance du daemon Ceph. Pour chaque noeud, vous devez exécuter <command>grains.set</command> avec le nouveau nom (court) d'hôte. Avant d'exécuter <command>grains.set</command>, vérifiez les instances Monitor actuelles en exécutant <command>ceph status</command>. Vous trouverez ci-dessous un exemple avant et après :
    </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.get host
d52-54-00-16-45-0a.example.com:
    d52-54-00-16-45-0a
d52-54-00-49-17-2a.example.com:
    d52-54-00-49-17-2a
d52-54-00-76-21-bc.example.com:
    d52-54-00-76-21-bc
d52-54-00-70-ac-30.example.com:
    d52-54-00-70-ac-30
</screen>
<screen>
<prompt>root@master # </prompt>salt d52-54-00-16-45-0a.example.com grains.set \
 host public.d52-54-00-16-45-0a
<prompt>root@master # </prompt>salt d52-54-00-49-17-2a.example.com grains.set \
 host public.d52-54-00-49-17-2a
<prompt>root@master # </prompt>salt d52-54-00-76-21-bc.example.com grains.set \
 host public.d52-54-00-76-21-bc
<prompt>root@master # </prompt>salt d52-54-00-70-ac-30.example.com grains.set \
 host public.d52-54-00-70-ac-30
</screen>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.get host
d52-54-00-76-21-bc.example.com:
    public.d52-54-00-76-21-bc
d52-54-00-16-45-0a.example.com:
    public.d52-54-00-16-45-0a
d52-54-00-49-17-2a.example.com:
    public.d52-54-00-49-17-2a
d52-54-00-70-ac-30.example.com:
    public.d52-54-00-70-ac-30
</screen>
   </step>
   <step>
    <para>
     Exécutez la mise à niveau :
    </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> state.apply ceph.updates
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> test.version
<prompt>root@master # </prompt>salt-run state.orch ceph.maintenance.upgrade
</screen>
    <para>
     Chaque noeud va redémarrer. La grappe revient en indiquant qu'il n'y a pas d'instance Ceph Manager active. C'est normal. Calamari ne doit plus être installé/en cours d'exécution à ce stade.
    </para>
   </step>
   <step>
    <para>
     Exécutez toutes les étapes de déploiement requises pour que la grappe atteigne un état sain :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
   </step>
   <step>
    <para>
     Pour déployer openATTIC (reportez-vous au manuel <xref linkend="ceph-oa"/>), ajoutez une ligne <literal>role-openattic</literal> appropriée (reportez-vous à la <xref linkend="policy-role-assignment"/>) au fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>, puis exécutez :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
   </step>
   <step>
    <para>
     Au cours de la mise à niveau, vous risquez de recevoir des erreurs du type « Error EINVAL: entity [...] exists but caps do not match » (Erreur EINVAL : l'entité existe [...] mais les caps ne correspondent pas). Pour les résoudre, reportez-vous à la <xref linkend="ceph-upgrade-4to5"/>.
    </para>
   </step>
   <step>
    <para>
     Effectuez le nettoyage restant :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Crowbar crée des entrées dans <filename>/etc/fstab</filename> pour chaque OSD. Elles ne sont pas nécessaires, supprimez-les.
      </para>
     </listitem>
     <listitem>
      <para>
       Calamari conserve une tâche planifiée Salt en cours d'exécution pour vérifier l'état de la grappe. Supprimez la tâche :
      </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> schedule.delete ceph.heartbeat
</screen>
     </listitem>
     <listitem>
      <para>
       Il reste néanmoins certains paquetages inutiles installés, principalement liés à ruby gems et chef. Leur suppression n'est pas obligatoire, mais vous pouvez les supprimer en exécutant <command>zypper rm <replaceable>pkg_name</replaceable></command> (nom_paquetage).
      </para>
     </listitem>
    </itemizedlist>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-3to5">
  <title>Mise à niveau de SUSE Enterprise Storage 3 vers la version 5</title>

  <important>
   <title>Configuration logicielle requise</title>
   <para>
    Vous devez disposer des logiciels suivants installés et mis à jour avec les dernières versions des paquetages sur tous les noeuds Ceph à mettre à niveau avant de lancer la procédure de mise à niveau :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP1
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 3
     </para>
    </listitem>
   </itemizedlist>
  </important>

  <para>
   Pour mettre à niveau la grappe SUSE Enterprise Storage 3 vers la version 5, suivez les étapes décrites dans la <xref linkend="upgrade4to5cephdeploy-all"/>, puis dans la <xref linkend="upgrade4to5cephdeploy-admin"/>.
  </para>
 </sect1>
</chapter>
