<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_saltcluster.xml" version="5.0" xml:id="storage-salt-cluster">
 <title>Salt 叢集管理</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>yes</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  部署 Ceph 叢集後，有些時候可能還需要對它執行若干修改。這些修改包括新增或移除新的節點、磁碟或服務。本章介紹該如何完成這些管理任務。
 </para>
 <sect1 xml:id="salt-adding-nodes">
  <title>新增新的叢集節點</title>

  <para>
   新增新節點至叢集的程序與<xref linkend="ceph-install-saltstack"/>中所述的初始叢集節點部署程序幾乎完全相同。
  </para>

  <procedure>
   <step>
    <para>
     在新節點上安裝 SUSE Linux Enterprise Server 12 SP3、進行其網路設定，以使其能夠正確解析 Salt Master 主機名稱，並安裝 <systemitem>salt-minion</systemitem> 套件︰
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper in salt-minion</screen>
    <para>
     如果 Salt Master 的主機名稱不是 <literal>salt</literal>，請編輯 <filename>/etc/salt/minion</filename> 並新增下面一行︰
    </para>
<screen>master: <replaceable>DNS_name_of_your_salt_master</replaceable></screen>
    <para>
     如果您對上面提到的組態檔案進行了任何變更，請重新啟動 <systemitem>salt.minion</systemitem> 服務︰
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <para>
     在 Salt Master 上接受所有 Salt 金鑰︰
    </para>
<screen><prompt>root@master # </prompt>salt-key --accept-all</screen>
   </step>
   <step>
    <para>
     驗證 <filename>/srv/pillar/ceph/deepsea_minions.sls</filename> 是否也以新的 Salt Minion 為目標。如需更多詳細資料，請參閱<xref linkend="ds-depl-stages"/>的<xref linkend="ds-minion-targeting-name"/>。
    </para>
   </step>
   <step>
    <para>
     執行準備階段。該階段會同步模組和 Grains 資料，以便新的 Minion 可以提供 DeepSea 需要的所有資訊︰
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
   </step>
   <step>
    <para>
     執行探查階段。該階段將在 <filename>/srv/pillar/ceph/proposals</filename> 目錄中寫入新的檔案項目，您可在其中編輯相關的 .yml 檔案︰
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     (選擇性) 如果新增的主機與現有命名規劃不符，請變更 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>。如需詳細資訊，請參閱<xref linkend="policy-configuration"/>。
    </para>
   </step>
   <step>
    <para>
     執行組態階段。該階段會讀取 <filename>/srv/pillar/ceph</filename> 下的所有內容，並相應地更新 Pillar︰
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
    <para>
     Pillar 用於儲存可以使用以下指令存取的資料︰
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.items</screen>
   </step>
   <step>
    <para>
     組態和部署階段包含新增的節點︰
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-adding-services">
  <title>新增新的角色至節點</title>

  <para>
   您可透過 DeepSea 部署所有受支援的角色類型。如需受支援角色類型的詳細資訊以及相符範例，請參閱<xref linkend="policy-role-assignment"/>。
  </para>

  <tip>
   <title>必需的與選擇性的角色和階段</title>
   <para>
    一般而言，在將新角色新增至叢集節點時，建議您執行全部部署階段 0 到 5。為了節省一些時間，可根據要部署的角色類型，跳過階段 3 或 4。OSD 和 MON 角色包含核心服務，是 Ceph 的必要組成部分，而其他角色 (例如物件閘道) 則是選擇性角色。DeepSea 部署階段是階層式的︰階段 3 部署核心服務，而階段 4 則部署選擇性服務。
   </para>
   <para>
    因此，部署核心角色 (例如在現有 OSD 節點上部署 MON) 時需要執行階段 3，可以跳過階段 4。
   </para>
   <para>
    同樣，部署選擇性服務 (例如物件閘道) 時可以跳過階段 3，但需要執行階段 4。
   </para>
  </tip>

  <para>
   若要將新服務新增至現有節點，請執行下列步驟︰
  </para>

  <procedure>
   <step>
    <para>
     修改 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>，以使現有主機與新角色相符。如需詳細資料，請參閱<xref linkend="policy-configuration"/>。例如，如果您需要在 MON 節點上執行物件閘道，指令行類似下方所示︰
    </para>
<screen>role-rgw/xx/x/example.mon-1.sls</screen>
   </step>
   <step>
    <para>
     執行階段 2 以更新 Pillar︰
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     執行階段 3 以部署核心服務，或者執行階段 4 以部署選擇性服務。同時執行這兩個階段也沒有問題。
    </para>
   </step>
  </procedure>

  <tip>
   <para>
    將 OSD 新增至現有叢集時請注意，叢集將在此後的一段時間內進行重新平衡。為了盡可能縮短重新平衡的時間，建議您同時新增所有要新增的 OSD。
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="salt-node-removing">
  <title>移除和重新安裝叢集節點</title>

  <para>
   若要從叢集中移除角色，請編輯 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>，移除相應的行。然後依<xref linkend="ceph-install-stack"/>所述執行階段 2 和 5。
  </para>

  <note>
   <title>從叢集中移除 OSD</title>
   <para>
    如果您需要從叢集中移除特定 OSD 節點，請確定叢集的可用磁碟空間大於要移除的磁碟空間。切記，移除 OSD 會導致整個叢集進行重新平衡。
   </para>
  </note>

  <para>
   從 Minion 中移除角色時，其目的是復原與該角色相關的所有變更。對於大部分角色，要實現該任務都很簡單，但可能會存在套件相依項問題。如果解除安裝某個套件，並不會解除安裝其相依項。
  </para>

  <para>
   移除的 OSD 會顯示為空白磁碟機。相關任務除了會抹除分割區表外，還會覆寫檔案系統的開頭並移除備份分割區。
  </para>

  <note>
   <title>保留透過其他方法建立的分割區</title>
   <para>
    先前透過其他方法 (例如 <command>ceph-deploy</command>) 設定的磁碟機可能仍然包含分割區。DeepSea 不會自動摧毀這些分割區。管理員必須收回這些磁碟機。
   </para>
  </note>

  <example xml:id="ex-ds-rmnode">
   <title>從叢集中移除 Salt Minion</title>
   <para>
    舉例來說，如果您的儲存 Minion 名為「data1.ceph」、「data2.ceph」...「data6.ceph」，則 <filename>policy.cfg</filename> 中的相關行類似下方所示︰
   </para>
<screen>[...]
# Hardware Profile
profile-default/cluster/data*.sls
profile-default/stack/default/ceph/minions/data*.yml
[...]</screen>
   <para>
    若要移除 Salt Minion「data2.ceph」，請將這些行變更為︰
   </para>
<screen>
[...]
# Hardware Profile
profile-default/cluster/data[1,3-6]*.sls
profile-default/stack/default/ceph/minions/data[1,3-6]*.yml
[...]</screen>
   <para>
    然後執行階段 2 和 5︰
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5</screen>
  </example>

  <example xml:id="ex-ds-mignode">
   <title>移轉節點</title>
   <para>
    假設出現下面的情況︰在全新安裝叢集期間，您 (管理員) 在等待閘道硬體就緒時，將其中一個儲存節點配置為獨立的物件閘道。現在，當閘道的永久硬體就緒時，您就可以將所需角色最終指定給備用儲存節點，並移除閘道角色。
   </para>
   <para>
    在針對新硬體執行階段 0 和 1 (請參閱<xref linkend="ds-depl-stages"/>) 之後，您將新閘道命名為 <literal>rgw1</literal>。如果節點 <literal>data8</literal> 需要移除物件閘道角色並新增儲存角色，且目前的 <filename>policy.cfg</filename> 類似下方所示︰
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-7]*.sls
profile-default/stack/default/ceph/minions/data[1-7]*.sls

# Roles
role-rgw/cluster/data8*.sls</screen>
   <para>
    則將它變更為︰
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-8]*.sls
profile-default/stack/default/ceph/minions/data[1-8]*.sls

# Roles
role-rgw/cluster/rgw1*.sls</screen>
   <para>
    執行階段 2 到 5。階段 3 會將 <literal>data8</literal> 新增為儲存節點。稍候片刻，<literal>data8</literal> 將同時具有兩個角色。階段 4 會將物件閘道角色新增至 <literal>rgw1</literal>，而階段 5 會從 <literal>data8</literal> 中移除物件閘道角色。
   </para>
  </example>
 </sect1>
 <sect1 xml:id="ds-mon">
  <title>重新部署監控程式節點</title>

  <para>
   當一或多個監控程式節點發生故障且不回應時，您需要將發生故障的監控程式從叢集中移除，然後再新增回叢集 (如有需要)。
  </para>

  <important>
   <title>至少須有三個監控程式節點</title>
   <para>
    監控程式節點的數量不能少於 3。如果某個監控程式節點發生故障，導致您的叢集中只有一個或兩個監控程式節點，您需要暫時將監控程式角色指定給其他叢集節點，然後再重新部署發生故障的監控程式節點。重新部署發生故障的監控程式節點後，便可以解除安裝臨時監控程式角色。
   </para>
   <para>
    如需有關將新節點/角色新增至 Ceph 叢集的詳細資訊，請參閱<xref linkend="salt-adding-nodes"/>和<xref linkend="salt-adding-services"/>。
   </para>
   <para>
    如需有關移除叢集節點的詳細資訊，請參閱<xref linkend="salt-node-removing"/>。
   </para>
  </important>

  <para>
   Ceph 節點故障基本分為以下兩種程度︰
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Salt Minion 主機發生實體或 OS 層級損毀，無法回應 <command>salt '<replaceable>minion_name</replaceable>' test.ping</command> 呼叫。在此情況下，您需要依照<xref linkend="ceph-install-stack"/>中的相關說明，對伺服器進行徹底的重新部署。
    </para>
   </listitem>
   <listitem>
    <para>
     監控程式相關服務失敗並拒絕復原，但主機會回應 <command>salt '<replaceable>minion_name</replaceable>' test.ping</command> 呼叫。在此情況下，請執行以下步驟︰
    </para>
   </listitem>
  </itemizedlist>

  <procedure>
   <step>
    <para>
     編輯 Salt Master 上的 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>，移除或更新發生故障的監控程式節點對應的行，使它們現在指向正常運作的監控程式節點。
    </para>
   </step>
   <step>
    <para>
     執行 DeepSea 階段 2 到 5 以套用這些變更︰
    </para>
<screen>
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.4
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.5
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-node-add-disk">
  <title>新增 OSD 至節點</title>

  <para>
   若要新增磁碟至現有 OSD 節點，請驗證是否已移除並抹除磁碟上的所有分割區。如需詳細資料，請參閱<xref linkend="ceph-install-stack"/>中的<xref linkend="deploy-wiping-disk"/>。磁碟變為空白磁碟後，將磁碟新增至節點的 YAML 檔案。該檔案的路徑是 <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/<replaceable>node_name</replaceable>.yml</filename>。儲存檔案後，執行 DeepSea 階段 2 和 3︰
  </para>

<screen><prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>

  <tip>
   <title>自動更新的設定檔</title>
   <para>
    您無需手動編輯 YAML 檔案，DeepSea 可建立新的設定檔。若要讓 DeepSea 建立新的設定檔，需要移走現有的設定檔︰
   </para>
<screen><prompt>root@master # </prompt><command>old</command> /srv/pillar/ceph/proposals/profile-default/
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.1
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>
  </tip>
 </sect1>
 <sect1 xml:id="salt-removing-osd">
  <title>移除 OSD</title>

  <para>
   您可以透過執行以下指令從叢集中移除 Ceph OSD︰
  </para>

<screen><prompt>root@master # </prompt><command>salt-run</command> disengage.safety
<prompt>root@master # </prompt><command>salt-run</command> remove.osd <replaceable>OSD_ID</replaceable></screen>

  <para>
   <replaceable>OSD_ID</replaceable> 需為 OSD 的編號，不含 <literal>osd</literal> 一詞。例如，對於 <literal>osd.3</literal>，僅使用數字 <literal>3</literal>。
  </para>

  <tip>
   <title>移除多個 OSD</title>
   <para>
    使用 <command>salt-run remove.osd</command> 指令無法同時移除多個 OSD。若要自動移除多個 OSD，您可以使用以下迴圈 (5、21、33、19 是要移除的 OSD 的 ID 編號)︰
   </para>
<screen>
for i in 5 21 33 19
do
 echo $i
 salt-run disengage.safety
 salt-run remove.osd $i
done
</screen>
  </tip>

  <sect2 xml:id="osd-forced-removal">
   <title>強制移除已中止的 OSD</title>
   <para>
    有時會出現無法正常移除 OSD 的情況 (請參閱<xref linkend="salt-removing-osd"/>)。例如，如果 OSD 或其快取中止、I/O 操作擱置，或者 OSD 磁碟無法卸載。在上述情況下，您需要強制移除 OSD︰
   </para>
<screen><prompt>root@master # </prompt><replaceable>target</replaceable> osd.remove <replaceable>OSD_ID</replaceable> force=True</screen>
   <para>
    此指令不僅會移除資料分割區，還會移除記錄或 WAL/DB 分割區。
   </para>
   <para>
    若要識別可能處於孤立狀態的記錄/WAL/DB 裝置，請執行以下步驟︰
   </para>
   <procedure>
    <step>
     <para>
      選取可能存在孤立分割區的裝置，並將其分割區清單儲存到檔案中︰
     </para>
<screen>
<prompt>root@minion &gt; </prompt>ls /dev/sdd?* &gt; /tmp/partitions
</screen>
    </step>
    <step>
     <para>
      針對所有 block.wal、block.db 和記錄裝置執行 <command>readlink</command>，並將輸出與先前儲存的分割區清單進行比較︰
     </para>
<screen>
<prompt>root@minion &gt; </prompt>readlink -f /var/lib/ceph/osd/ceph-*/{block.wal,block.db,journal} \
 | sort | comm -23 /tmp/partitions -
</screen>
     <para>
      輸出內容為 Ceph <emphasis>未</emphasis>使用的分割區清單。
     </para>
    </step>
    <step>
     <para>
      使用您偏好的指令 (例如 <command>fdisk</command>、<command>parted</command> 或 <command>sgdisk</command>) 移除不屬於 Ceph 的孤立分割區。
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ds-osd-recover">
  <title>復原重新安裝的 OSD 節點</title>

  <para>
   如果您的某個 OSD 節點上的作業系統損毀且無法恢復，請執行以下步驟復原該節點，並在叢集資料保持不變的情況下，重新部署該節點的 OSD 角色︰
  </para>

  <procedure>
   <step>
    <para>
     在節點上重新安裝作業系統。
    </para>
   </step>
   <step>
    <para>
     在 OSD 節點上安裝 <package>salt-minion</package> 套件，刪除 Salt Master 上的舊 Salt Minion 金鑰，並在 Salt Master 中註冊新 Salt Minion 的金鑰。如需 Salt Minion 部署的詳細資訊，請參閱<xref linkend="ceph-install-stack"/>。
    </para>
   </step>
   <step>
    <para>
     不要執行整個階段 0，而是執行以下部分︰
    </para>
<screen>
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.sync
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.packages.common
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.mines
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.updates
</screen>
   </step>
   <step>
    <para>
     執行 DeepSea 階段 1 到 5︰
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5
</screen>
   </step>
   <step>
    <para>
     執行 DeepSea 階段 0︰
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
</screen>
   </step>
   <step>
    <para>
     將相關的 OSD 節點重新開機。系統將重新探查並重新使用所有 OSD 磁碟。
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-automated-installation">
  <title>透過 Salt 實現自動安裝</title>

  <para>
   透過使用 Salt 反應器可讓安裝自動進行。對於虛擬環境或一致的硬體環境，此組態將允許建立具有指定行為的 Ceph 叢集。
  </para>

  <warning>
   <para>
    Salt 無法根據反應器事件執行相依項檢查。存在使 Salt Master 過載而無法回應的風險。
   </para>
  </warning>

  <para>
   自動安裝需要︰
  </para>

  <itemizedlist>
   <listitem>
    <para>
     正確建立的 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>。
    </para>
   </listitem>
   <listitem>
    <para>
     準備好並已放入 <filename>/srv/pillar/ceph/stack</filename> 目錄中的自訂組態。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   預設反應器組態只會執行階段 0 和 1。如此不必等待後續階段完成即可測試反應器。
  </para>

  <para>
   第一個 salt-minion 啟動時，階段 0 即會開始。使用鎖定可阻止多個例項。所有 Minion 都完成階段 0 後，階段 1 將會開始。
  </para>

  <para>
   如果該操作正確執行，請將 <filename>/etc/salt/master.d/reactor.conf</filename> 中的最後一行︰
  </para>

<screen>- /srv/salt/ceph/reactor/discovery.sls</screen>

  <para>
   變更為
  </para>

<screen>- /srv/salt/ceph/reactor/all_stages.sls</screen>
 </sect1>
 <sect1 xml:id="deepsea-rolling-updates">
  <title>更新叢集節點</title>

  <para>
   最好定期向您的叢集節點套用輪替式更新。若要套用更新，請執行階段 0︰
  </para>

<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>

  <para>
   如果 DeepSea 偵測到執行中 Ceph 叢集，它會循序套用更新並重新啟動節點。DeepSea 會遵照 Ceph 的官方建議，先更新監控程式，然後更新 OSD，最後再更新其他服務，例如 MDS、物件閘道、iSCSI 閘道或 NFS Ganesha。如果 DeepSea 偵測到叢集中存在問題，會停止更新程序。觸發問題的因素可能是︰
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Ceph 報告「HEALTH_ERR」的持續時長超過 300 秒。
    </para>
   </listitem>
   <listitem>
    <para>
     查詢 Salt Minion，以瞭解所指定的服務在更新後是否仍然啟動且在執行中。如果服務處於關閉狀態超過 900 秒，更新即會失敗。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   如此安排可確保即使更新損毀或失敗，Ceph 叢集仍可以運作。
  </para>

  <para>
   DeepSea 階段 0 透過 <command>zypper update</command> 更新系統，如果更新了核心，該階段會將系統重新開機。如果您想避免發生將所有可能的節點強制重新開機的情況，請在啟動 DeepSea 階段 0 之前，確定最新的核心已安裝且正在執行。
  </para>

  <tip>
   <title><command>zypper patch</command></title>
   <para>
    如果您更想使用 <command>zypper patch</command> 指令來更新系統，請編輯 <filename>/srv/pillar/ceph/stack/global.yml</filename>，新增下面一行︰
   </para>
<screen>update_method_init: zypper-patch</screen>
  </tip>

  <para>
   您可以透過將下面幾行新增至 <filename>/srv/pillar/ceph/stack/global.yml</filename>，來變更 DeepSea 階段 0 的預設重新開機行為︰
  </para>

<screen>stage_prep_master: default-update-no-reboot
stage_prep_minion: default-update-no-reboot</screen>

  <para>
   <literal>stage_prep_master</literal> 用於設定 Salt Master 的階段 0 行為，<literal>stage_prep_minion</literal> 用於設定所有 Minion 的行為。所有可用的參數如下︰
  </para>

  <variablelist>
   <varlistentry>
    <term>default</term>
    <listitem>
     <para>
      安裝更新並在更新後重新開機。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-update-no-reboot</term>
    <listitem>
     <para>
      安裝更新而不重新開機。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-reboot</term>
    <listitem>
     <para>
      重新開機而不安裝更新。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-no-reboot</term>
    <listitem>
     <para>
      不安裝更新，也不重新開機。
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-salt-cluster-reboot">
  <title>將叢集停止或重新開機</title>

  <para>
   在某些情況下，可能需要將整個叢集停止或重新開機。建議您仔細檢查執行中服務的相依項。下列步驟簡要說明如何停止和啟動叢集︰
  </para>

  <procedure>
   <step>
    <para>
     告知 Ceph 叢集不要將 OSD 標示為 out︰
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd set noout</screen>
   </step>
   <step>
    <para>
     依下面的順序停止精靈和節點︰
    </para>
    <orderedlist>
     <listitem>
      <para>
       儲存用戶端
      </para>
     </listitem>
     <listitem>
      <para>
       閘道，例如 NFS Ganesha 或物件閘道
      </para>
     </listitem>
     <listitem>
      <para>
       中繼資料伺服器
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     視需要執行維護任務。
    </para>
   </step>
   <step>
    <para>
     依與關閉過程相反的順序啟動節點和伺服器︰
    </para>
    <orderedlist>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       中繼資料伺服器
      </para>
     </listitem>
     <listitem>
      <para>
       閘道，例如 NFS Ganesha 或物件閘道
      </para>
     </listitem>
     <listitem>
      <para>
       儲存用戶端
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     移除 noout 旗標︰
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd unset noout</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ds-custom-cephconf">
  <title>自訂 <filename>ceph.conf</filename> 檔案</title>

  <para>
   如果您需要將自訂設定放入 <filename>ceph.conf</filename> 檔案中，可透過修改 <filename>/srv/salt/ceph/configuration/files/ceph.conf.d</filename> 目錄中的組態檔案來實現︰
  </para>

  <itemizedlist>
   <listitem>
    <para>
     global.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mon.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mgr.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mds.conf
    </para>
   </listitem>
   <listitem>
    <para>
     osd.conf
    </para>
   </listitem>
   <listitem>
    <para>
     client.conf
    </para>
   </listitem>
   <listitem>
    <para>
     rgw.conf
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>唯一的 <filename>rgw.conf</filename></title>
   <para>
    與 <filename>ceph.conf</filename> 的其他區段相比，物件閘道具有很強的靈活性，並且是唯一的。所有其他 Ceph 元件都包含靜態標頭，例如 <literal>[mon]</literal> 或 <literal>[osd]</literal>。物件閘道的標頭是唯一的，例如 <literal>[client.rgw.rgw1]</literal>。也就是說，<filename>rgw.conf</filename> 檔案需要有標頭項目。如需範例，請參閱 <filename>/srv/salt/ceph/configuration/files/rgw.conf</filename>。
   </para>
  </note>

  <important>
   <title>執行階段 3</title>
   <para>
    對上述組態檔案進行自訂變更之後，執行階段 3 以將這些變更套用到叢集節點︰
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
  </important>

  <para>
   這些檔案透過 <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> 範本檔案加入，與 Ceph 組態檔案接受的不同區段相對應。將組態片段放入正確的檔案，可讓 DeepSea 將其放入正確的區段中。您不需要新增任何區段標頭。
  </para>

  <tip>
   <para>
    若要將任何組態選項僅套用於精靈的特定例項，請新增一個標頭，例如 <literal>[osd.1]</literal>。以下組態選項將只套用於 ID 為 1 的 OSD 精靈。
   </para>
  </tip>

  <sect2>
   <title>覆寫預設值</title>
   <para>
    區段中位於後面的陳述式會覆寫前面的陳述式。因此，可以依 <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> 範本中指定的內容來覆寫預設組態。例如，若要關閉 cephx 驗證，可將下面三行新增至 <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename> 檔案︰
   </para>
<screen>auth cluster required = none
auth service required = none
auth client required = none</screen>
  </sect2>

  <sect2>
   <title>加入組態檔案</title>
   <para>
    如果您需要套用大量自訂組態，請在自訂組態檔案中使用以下 include 陳述式來讓檔案管理工作更輕鬆。下面是 <filename>osd.conf</filename> 檔案的範例︰
   </para>
<screen>[osd.1]
{% include "ceph/configuration/files/ceph.conf.d/osd1.conf" ignore missing %}
[osd.2]
{% include "ceph/configuration/files/ceph.conf.d/osd2.conf" ignore missing %}
[osd.3]
{% include "ceph/configuration/files/ceph.conf.d/osd3.conf" ignore missing %}
[osd.4]
{% include "ceph/configuration/files/ceph.conf.d/osd4.conf" ignore missing %}</screen>
   <para>
    在前面的範例中，<filename>osd1.conf</filename>、<filename>osd2.conf</filename>、<filename>osd3.conf</filename> 和 <filename>osd4.conf</filename> 檔案包含相關 OSD 特定的組態選項。
   </para>
   <tip>
    <title>執行時期組態</title>
    <para>
     對 Ceph 組態檔案所做的變更會在相關 Ceph 精靈重新啟動之後生效。如需變更 Ceph 執行時期組態的詳細資訊，請參閱<xref linkend="ceph-config-runtime"/>。
    </para>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-config-runtime">
  <title>執行時期 Ceph 組態</title>

  <para>
   <xref linkend="ds-custom-cephconf"/>介紹如何對 Ceph 組態檔案 <filename>ceph.conf</filename> 進行變更。但是，實際的叢集行為並不是由 <filename>ceph.conf</filename> 檔案的目前狀態決定，而是由執行中 Ceph 精靈的組態 (儲存在記憶體中) 決定。
  </para>

  <para>
   若要查詢個別 Ceph 精靈以瞭解特定的組態設定，您可以在執行精靈的節點上使用 <emphasis>admin socket</emphasis>。例如，以下指令可從名為 <literal>osd.0</literal> 的精靈獲取 <option>osd_max_write_size</option> 組態參數的值︰
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/ceph-osd.0.asok \
config get osd_max_write_size
{
  "osd_max_write_size": "90"
}</screen>

  <para>
   您還可以在執行時期<emphasis>變更</emphasis>精靈的設定。請注意，此變更是暫時性的，精靈下次重新啟動時，變更將會遺失。例如，以下指令可針對叢集中的所有 OSD 將 <option>osd_max_write_size</option> 參數變更為「50」︰
  </para>

<screen><prompt>root # </prompt>ceph tell osd.* injectargs --osd_max_write_size 50</screen>

  <warning>
   <title><command>injectargs</command> 並非百分百可靠</title>
   <para>
    有時，使用 <command>injectargs</command> 指令可能無法成功變更叢集設定。如果您需要確保啟用變更的參數，請在組態檔案中進行變更，並重新啟動叢集中的所有精靈。
   </para>
  </warning>
 </sect1>
</chapter>
