<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph-monitor">
 <title>Determinazione dello stato del cluster</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>sì</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Quando un cluster è in esecuzione, è possibile utilizzare lo strumento <command>ceph</command> per monitorare il cluster. Di norma, per determinare lo stato del cluster è necessario verificare lo stato di OSD, monitoraggio, gruppo di posizionamento e server dei metadati. <remark role="fixme">Maybe revert to old version of sentence: Determining the cluster state typically involves
  checking OSD status, monitor status, placement group status and metadata
  server status.</remark>
 </para>
 <tip>
  <title>modalità interattiva</title>
  <para>
   Per eseguire lo strumento <command>ceph</command> in modalità interattiva, digitare <command>ceph</command> nella riga di comando senza argomenti. La modalità interattiva è più pratica se si devono immettere più comandi <command>ceph</command> in una riga. Ad esempio:
  </para>
<screen><prompt>cephadm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon_status</screen>
 </tip>
 <sect1 xml:id="monitor-health">
  <title>Verifica dello stato di integrità del cluster</title>

  <para>
   Dopo l'avvio del cluster e prima della lettura e/o scrittura dei dati, verificare lo stato di integrità del cluster:
  </para>

<screen><prompt>root # </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <para>
   Il cluster Ceph restituisce uno dei seguenti codici di stato di integrità:
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      Uno o più OSD sono contrassegnati. È possibile che il deamon OSD sia stato interrotto o gli OSD peer potrebbero non essere in grado di raggiungere l'OSD nella rete. Tra le cause comuni sono inclusi un'interruzione o crash del daemon, un host inattivo o un'interruzione della rete.
     </para>
     <para>
      Verificare che l'host sia integro, il daemon avviato e la rete funzionante. Se ha avuto luogo un crash del daemon, è possibile che il file di log del daemon (<filename>/var/log/ceph/ceph-osd.*</filename>) contenga informazioni di debug.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>crush type</replaceable>_DOWN, ad esempio OSD_HOST_DOWN</term>
    <listitem>
     <para>
      Tutti gli OSD in un determinato sottoalbero CRUSH vengono contrassegnati, ad esempio tutti gli OSD in un host.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      Un OSD è un riferimento nella gerarchia della mappa CRUSH, ma non esiste. È possibile rimuovere l'OSD dalla gerarchia CRUSH con:
     </para>
<screen><prompt>root # </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      Le soglie di utilizzo per <emphasis>backfillfull</emphasis>, <emphasis>nearfull</emphasis>, <emphasis>full</emphasis> e/o <emphasis>failsafe_full</emphasis> non sono in ordine crescente. In particolare, ci si aspetta <emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>, <emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis> e <emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis>. È possibile regolare le soglie con:
     </para>
<screen><prompt>root # </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      Uno o più OSD hanno superato la soglia <emphasis>full</emphasis> e impediscono al cluster di fornire servizi di scrittura. È possibile verificare l'utilizzo da parte del pool con:
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
     <para>
      È possibile visualizzare il rapporto <emphasis>full</emphasis> attualmente definito con:
     </para>
<screen><prompt>root # </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      Una soluzione immediata per ripristinare la disponibilità di scrittura consiste nell'aumentare leggermente la soglia completa (full):
     </para>
<screen><prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      Aggiungere un nuovo spazio di memorizzazione al cluster installando più OSD, o eliminare i dati esistenti per liberare spazio.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      Uno o più OSD hanno superato la soglia <emphasis>backfillfull</emphasis>, impedendo il ribilanciamento dei dati nel dispositivo. Questo è un avviso preliminare che informa l'utente sull'impossibilità di completare il ribilanciamento e che il cluster è quasi pieno. È possibile verificare l'utilizzo da parte del pool con:
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      Uno o più OSD hanno superato la soglia <emphasis>nearfull</emphasis>. Questo è un avviso preliminare che informa l'utente che il cluster è quasi pieno. È possibile verificare l'utilizzo da parte del pool con:
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      Sono stati impostati uno o più flag del cluster interessato. Ad eccezione di <emphasis>full</emphasis>, è possibile impostare o eliminare i flag con:
     </para>
<screen><prompt>root # </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>root # </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      Tali flag includono:
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         Il cluster è contrassegnato come full (pieno) e non può fornire servizi di scrittura.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd, pausewr </term>
       <listitem>
        <para>
         Letture o scritture in pausa
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         Viene impedito l'avvio degli OSD.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         I rapporti sugli errori degli OSD vengono ignorati, ad esempio quando i monitoraggi non contrassegnano gli OSD come <emphasis>down</emphasis> (inattivi).
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Gli OSD contrassegnati precedentemente come <emphasis>out</emphasis> non verranno contrassegnati di nuovo come <emphasis>in</emphasis> all'avvio.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Gli ODS <emphasis>down</emphasis> (inattivi) non verranno contrassegnati automaticamente come <emphasis>out</emphasis> dopo l'intervallo configurato.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill, norecover, norebalance</term>
       <listitem>
        <para>
         Il recupero o il ribilanciamento dei dati è sospeso.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub, nodeep_scrub</term>
       <listitem>
        <para>
         La pulitura (vedere <xref linkend="scrubbing"/>) è disabilitata.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         L'attività di suddivisione in livelli di cache è sospesa.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      Uno o più ODS presentano un flag per OSD del set di interesse. Tali flag includono:
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         All'OSD non è consentito l'avvio.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         I rapporti di errore per l'OSD specificato verranno ignorati.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Se precedentemente questo OSD è stato contrassegnato automaticamente come <emphasis>out</emphasis> in seguito a un errore, non verrà contrassegnato come <emphasis>in</emphasis> al suo avvio.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Se l'OSD è inattivo, non verrà contrassegnato automaticamente come <emphasis>out</emphasis> dopo l'intervallo configurato.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      È possibile impostare ed eliminare i flag per OSD con:
     </para>
<screen><prompt>root # </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>root # </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      Nella mappa CRUSH vengono utilizzate impostazioni molto obsolete e deve essere aggiornata. Gli elementi ottimizzabili più obsoleti (vale a dire la versione client più vecchia in grado di connettersi al cluster) che è possibile utilizzare senza attivare questo avviso di stato di integrità vengono determinati dall'opzione di configurazione <option>mon_crush_min_required_version</option>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      Nella mappa CRUSH viene utilizzato un metodo precedente, non ottimale per calcolare i valori del peso intermedio per i compartimenti straw. La mappa CRUSH deve essere aggiornata per utilizzare il metodo più recente (<option>straw_calc_version</option>=1).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      Uno o più pool di cache non sono configurati con un set di accessi per controllare l'utilizzo, impedendo all'agente di suddivisione in livelli di identificare gli oggetti a caldo di essere svuotati o rimossi dalla cache. È possibile configurare i set di accessi nel pool di cache con:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      Nessun OSD di versione precedente a Luminous v12 in esecuzione, ma il flag <option>sortbitwise</option> non è stato impostato. È necessario impostare il flag <option>sortbitwise</option> prima di poter avviare gli OSD Luminous v12 o versione più recente:
     </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Uno o più pool hanno raggiunto la rispettiva quota e non consentono più le scritture. È possibile impostare le quote dei pool e l'utilizzo con:
     </para>
<screen><prompt>root # </prompt>ceph df detail</screen>
     <para>
      È possibile aumentare la quota del pool con
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      o eliminare alcuni dati esistenti per ridurre l'utilizzo.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      La disponibilità dei dati è ridotta, vale a dire che il cluster non è in grado di fornire servizi di richieste di potenziali letture o scritture per alcuni dati nel cluster. Nello specifico, è impossibile fornire servizi a uno o più gruppi di posizionamento il cui stato non consente richieste IO. Gli stati dei gruppi di posizionamento problematici includono <emphasis>peering</emphasis>, <emphasis>stale (inattivo)</emphasis>, <emphasis>incomplete (incompleto)</emphasis> e la mancanza di <emphasis>active (attivo)</emphasis> (se tali condizioni non vengono annullate rapidamente). Informazioni dettagliate sui gruppi di posizionamento interessati sono recuperabili da:
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      Nella maggior parte dei casi, la causa radice risiede nell'attuale stato di inattività di uno o più OSD. È possibile interrogare lo stato di specifici gruppi di posizionamento problematici con:
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      La ridondanza dei dati è ridotta per alcuni dati, vale a dire che il cluster non dispone del numero desiderato di repliche per tutti i dati (per pool replicati) o di frammenti di codice di cancellazione (per pool con codice di cancellazione). Nello specifico, per uno o più gruppi di posizionamento è impostato il flag <emphasis>degraded</emphasis> o <emphasis>undersized </emphasis> (le istanze di tale gruppo di posizionamento nel cluster non sono sufficienti) oppure non è impostato il flag <emphasis>clean</emphasis> per un periodo di tempo. Informazioni dettagliate sui gruppi di posizionamento interessati sono recuperabili da:
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      Nella maggior parte dei casi, la causa radice risiede nell'attuale stato di inattività di uno o più OSD. È possibile interrogare lo stato di specifici gruppi di posizionamento problematici con:
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      È possibile che la ridondanza dei dati può sia ridotta o a rischio per alcuni dati a causa della mancanza di spazio libero nel cluster. Nello specifico, per uno o più gruppi di posizionamento è impostato il flag <emphasis>backfill_toofull</emphasis> o <emphasis>recovery_toofull</emphasis>, vale a dire che il cluster non è in grado di eseguire la migrazione o recuperare i dati perché uno o più OSD superano la soglia <emphasis>backfillfull</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      In seguito alla pulitura dei dati (vedere <xref linkend="scrubbing"/>), nel cluster sono stati rilevati alcuni problemi di incoerenza dei dati. Nello specifico, in uno o più gruppi di posizionamento è impostato il flag <emphasis>inconsistent</emphasis> o <emphasis>snaptrim_error</emphasis>, a indicare che a seguito di un'operazione di pulitura precedente è stato individuato un problema, oppure è impostato il flag <emphasis>repair</emphasis>, a indicare che attualmente è in corso una riparazione per tale incoerenza.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      Dalle puliture dell'OSD sono state rilevate incoerenze.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Un pool di livelli di cache è quasi pieno. "Pieno" in questo contesto è determinato dalla proprietà <emphasis>target_max_bytes</emphasis> e <emphasis>target_max_objects</emphasis> nel pool di cache. Quando il pool raggiunge la soglia di destinazione, è possibile che le richieste di scrittura nel pool si blocchino quando i dati vengono svuotati e rimossi dalla cache, uno stato che di norma comporta latenze molto elevate e prestazioni scarse. È possibile regolare le dimensioni di destinazione del pool di cache con:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      È inoltre possibile che le attività di svuotamento e rimozione siano bloccate a causa della disponibilità ridotta, delle prestazioni del livello base o a causa del carico complessivo del cluster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      Il numero di gruppi di posizionamento in uso è sotto la soglia configurabile dei gruppi di posizionamento per OSD <option>mon_pg_warn_min_per_osd</option>. Ciò può comportare una distribuzione e bilanciamento dei dati non ottimali negli OSD del cluster, riducendo le prestazioni complessive.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      Il numero di gruppi di posizionamento in uso supera la soglia configurabile di gruppi di posizionamento per OSD <option>mon_pg_warn_max_per_osd</option>. Ciò comporta un utilizzo della memoria maggiore per i daemon OSD, un peering più lento dopo le modifiche allo stato del cluster (ad esempio, riavvii, aggiunte o rimozioni di OSD) e un carico più elevato nei Ceph Manager e Ceph Monitor.
     </para>
     <para>
      Mentre è impossibile ridurre il valore <option>pg_num</option> per i pool esistenti, il valore <option>pgp_num</option> può essere ridotto. Ciò colloca effettivamente alcuni gruppi di posizionamento sugli stessi set di OSD, mitigando alcuni impatti negativi descritti sopra. È possibile regolare il valore <option>pgp_num</option> con:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      Il valore <option>pgp_num</option> di uno o più pool è inferiore a <option>pg_num</option>. Di norma ciò indica che il numero di gruppi di posizionamento è stato incrementato senza incrementare anche comportamento del posizionamento. Di norma questo problema viene risolto impostando <option>pgp_num</option> in modo che corrisponda a <option>pg_num</option>, attivando la migrazione dei dati, con:
     </para>
<screen>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      Uno o più pool presentano un numero di oggetti per gruppo di posizionamento che è significativamente più elevato della media complessiva del cluster. La soglia specifica è controllata dal valore di configurazione <option>mon_pg_warn_max_object_skew</option>. Di norma ciò indica che i pool che contengono la maggior parte dei dati nel cluster hanno un numero di gruppi di posizionamento insufficiente e/o che altri pool che non contengono una tale quantità di dati hanno troppi gruppi di posizionamento. È possibile aumentare la soglia per annullare l'avviso di stato di integrità regolando l'opzione di configurazione <option>mon_pg_warn_max_object_skew</option> nei monitoraggi.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED</term>
    <listitem>
     <para>
      Un pool contiene uno o più oggetti, ma non è stato contrassegnato per l'utilizzo da parte di un'applicazione particolare. Risolvere questo avviso etichettando il pool per l'utilizzo da parte di un'applicazione. Ad esempio, se il pool viene utilizzato da RBD:
     </para>
<screen><prompt>root # </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      Se il pool viene utilizzato da un'applicazione personalizzata "foo", è inoltre possibile etichettarla con il comando di livello basso:
     </para>
<screen><prompt>root # </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Uno o più pool hanno raggiunto (o sono prossimi a raggiungere) la rispettiva quota. La soglia per attivare questa condizione di errore è controllata dall'opzione di configurazione <option>mon_pool_quota_crit_threshold</option>. È possibile regolare verso l'alto o verso il basso (o rimuovere) le quote dei pool con:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      Impostando il valore di quota a 0, questa verrà disabilitata.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Uno o più pool stanno per raggiungere la rispettiva quota. La soglia per attivare questa condizione di avviso è controllata dall'opzione di configurazione <option>mon_pool_quota_warn_threshold</option>. È possibile regolare verso l'alto o verso il basso (o rimuovere) le quote dei pool con:
     </para>
<screen><prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      Impostando il valore di quota a 0, questa verrà disabilitata.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      Uno o più oggetti nel cluster non è memorizzato nel nodo indicato dal cluster. Ciò indica che la migrazione dei dati non è stata ancora completata a causa di una modifica recente del cluster. La posizione errata dei dati non rappresenta una condizione pericolosa. La coerenza dei dati non è mai a rischio e le copie precedenti degli oggetti non vengono mai rimosse finché è presente il numero di copie nuove desiderato (nelle ubicazioni desiderate).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      Impossibile individuare uno o più oggetti nel cluster. Nello specifico, gli OSD sanno che deve esistere una copia nuova o aggiornata di un oggetto, ma negli OSD attualmente online non è stata trovata una copia di tale versione dell'oggetto. Le richieste di lettura o scrittura negli oggetti "non trovati" verranno bloccate. Idealmente, è possibile riportare online un OSD inattivo con la copia più recente dell'oggetto non trovato. È possibile identificare gli OSD candidati in stato di peering per i gruppi di posizionamento responsabili dell'oggetto non trovato:
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      Una o più richieste OSD impiegano molto tempo per l'elaborazione. Ciò può essere un'indicazione di carico estremo, dispositivo di memorizzazione lento o bug del software. È possibile interrogare la coda delle richieste sugli OSD in questione mediante l'esecuzione del seguente comando dall'host OSD:
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      È possibile visualizzare un riepilogo delle richieste recenti più lente:
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      È possibile individuare l'ubicazione di un OSD con:
     </para>
<screen><prompt>root # </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      Una o più richieste OSD sono state bloccate per un periodo estremamente lungo. Ciò indica che lo stato del cluster non è integro da un periodo di tempo prolungato (ad esempio il numero di OSD in esecuzione non è sufficiente) o sono presenti alcuni problemi interni con l'OSD.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      Di recente non è stata eseguita la pulitura di uno o più gruppi di posizionamento (vedere <xref linkend="scrubbing"/>). Di norma la pulitura dei gruppi di posizionamento viene eseguita ogni <option>mon_scrub_interval</option> secondi e questo avviso si attiva quando sono trascorsi <option>mon_warn_not_scrubbed</option> secondi senza che abbia avuto luogo una pulitura. La pulitura dei gruppi di posizionamento non verrà eseguita se questi non sono contrassegnati come puliti, il che può verificarsi se sono posizionati male o sono danneggiati (vedere PG_AVAILABILITY e PG_DEGRADED di cui sopra). È possibile avviare manualmente la pulitura di un gruppo di posizionamento pulito con:
     </para>
<screen><prompt>root # </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      Di recente non è stata eseguita la pulitura approfondita di uno o più gruppi di posizionamento (vedere <xref linkend="scrubbing"/>). Di norma la pulitura dei gruppi di posizionamento viene eseguita ogni <option>osd_deep_mon_scrub_interval</option> secondi e questo avviso si attiva quando sono trascorsi <option>mon_warn_not_deep_scrubbed</option> secondi senza che abbia avuto luogo una pulitura. La pulitura (approfondita) dei gruppi di posizionamento non verrà eseguita se questi non sono contrassegnati come puliti, il che può verificarsi se sono posizionati male o sono danneggiati (vedere PG_AVAILABILITY e PG_DEGRADED di cui sopra). È possibile avviare manualmente la pulitura di un gruppo di posizionamento pulito con:
     </para>
<screen><prompt>root # </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    Se sono state specificate ubicazioni non di default per la configurazione o il portachiavi, è possibile specificarne le ubicazioni:
   </para>
<screen><prompt>root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-watch">
  <title>Osservazione di un cluster</title>

  <para>
   È possibile individuare lo stato immediato del cluster mediante <command>ceph -s</command>. Ad esempio, un cluster Ceph di piccole dimensioni costituito da un monitoraggio e due OSD può stampare quanto riportato di seguito quando è in esecuzione un workload:
  </para>

<screen>cluster:
  id:     6586341d-4565-3755-a4fd-b50f51bee248
  health: HEALTH_OK

services:
  mon: 3 daemons, quorum blueshark1,blueshark2,blueshark3
  mgr: blueshark3(active), standbys: blueshark2, blueshark1
  osd: 15 osds: 15 up, 15 in

data:
  pools:   8 pools, 340 pgs
  objects: 537 objects, 1985 MB
  usage:   23881 MB used, 5571 GB / 5595 GB avail
  pgs:     340 active+clean

io:
  client:   100 MB/s rd, 26256 op/s rd, 0 op/s wr</screen>

  <para>
   L'output fornisce le seguenti informazioni:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     ID cluster
    </para>
   </listitem>
   <listitem>
    <para>
     Stato di integrità del cluster
    </para>
   </listitem>
   <listitem>
    <para>
     Epoca della mappa di monitoraggio e stato del quorum del monitoraggio
    </para>
   </listitem>
   <listitem>
    <para>
     Epoca della mappa OSD e stato degli OSD
    </para>
   </listitem>
   <listitem>
    <para>
     Versione della mappa del gruppo di posizionamento
    </para>
   </listitem>
   <listitem>
    <para>
     Numero di gruppi di posizionamento e pool
    </para>
   </listitem>
   <listitem>
    <para>
     Quantità di dati <emphasis>nozionale</emphasis> memorizzati e numero di oggetti memorizzati
    </para>
   </listitem>
   <listitem>
    <para>
     Quantità totale di dati memorizzati.
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>calcolo dell'utilizzo dei dati da parte di Ceph</title>
   <para>
    Il valore <literal>used</literal> riflette la quantità effettiva di spazio di memorizzazione non elaborato utilizzato. Il valore <literal>xxx GB / xxx GB</literal> indica la quantità disponibile (il numero inferiore) della capacità di memorizzazione complessiva del cluster. Il numero nozionale riflette le dimensioni dei dati memorizzati prima che vengano replicati, clonati o che ne venga eseguito lo snapshot. Pertanto, di norma la quantità di dati effettivamente memorizzata supera la quantità nozionale memorizzata, poiché Ceph crea repliche dei dati e può anche utilizzare capacità di memorizzazione per la clonazione e gli snapshot.
   </para>
  </tip>

  <para>
   Altri comandi che consentono di visualizzare informazioni immediate sullo stato sono:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Per ottenere informazioni aggiornate in tempo reale, inserire uno di questi comandi (tra cui <command>ceph -s</command>) in un loop di attesa, ad esempio:
  </para>

<screen><systemitem class="username">root</systemitem>while true ; do ceph -s ; sleep 10 ; done</screen>

  <para>
   Premere <keycombo><keycap function="control"/><keycap>C</keycap></keycombo> quando non si desidera più visualizzare le informazioni.
  </para>
 </sect1>
 <sect1 xml:id="monitor-stats">
  <title>Verifica delle statistiche sull'utilizzo di un cluster</title>

  <para>
   Per verificare l'utilizzo dei dati di un cluster e la distribuzione degli stessi nei pool, è possibile utilizzare l'opzione <command>df</command>. È simile all'opzione <command>df</command> di Linux. Eseguire le operazioni seguenti:
  </para>

<screen><prompt>root # </prompt>ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    55886G     55826G       61731M          0.11
POOLS:
    NAME         ID     USED      %USED     MAX AVAIL     OBJECTS
    testpool     1          0         0        17676G           0
    ecpool       2      4077M      0.01        35352G        2102
    test1        3          0         0        17676G           0
    rbd          4         16         0        17676G           3
    rbd1         5         16         0        17676G           3
    ecpool1      6      5708M      0.02        35352G        2871</screen>

  <para>
   Nella sezione <literal>GLOBAL</literal> dell'output è fornita una panoramica della quantità di spazio di memorizzazione utilizzata dal cluster per i dati.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>SIZE</literal>: capacità di memorizzazione complessiva del cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal>: quantità di spazio libero disponibile nel cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal>: quantità di spazio di memorizzazione non elaborato utilizzato.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal>: percentuale di spazio di memorizzazione di dati non elaborati utilizzato. Utilizzare questo numero insieme a <literal>full ratio</literal> e <literal>near full ratio</literal> per assicurarsi che non si stia raggiungendo la capacità del cluster. Vedere <link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/mon-config-ref#storage-capacit">Storage Capacity</link> (in lingua inglese) per ulteriori dettagli.
    </para>
    <note>
     <title>livello di riempimento del cluster</title>
     <para>
      Il livello di riempimento dello spazio di memorizzazione di dati non elaborati compreso tra 70% e 80% indica che è necessario aggiungere nuovo spazio di memorizzazione al cluster. Un utilizzo più elevato può comportare a singoli OSD pieni e a problemi di integrità del cluster.
     </para>
     <para>
      Utilizzare il comando <command>ceph osd df tree</command> per elencare il livello di riempimento di tutti gli OSD.
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   Nella sezione <literal>POOLS</literal> dell'output è fornito un elenco di pool e l'utilizzo nozionale di ciascuno di essi. L'output di questa sezione <emphasis>non</emphasis> riflette repliche, cloni o snapshot. Ad esempio, se si memorizza un oggetto con 1 MB di dati, l'utilizzo nozionale sarà 1 MB, ma quello effettivo può essere di 2 MB o più a seconda del numero di repliche, cloni e snapshot.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>NAME</literal>: nome del pool.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal>: ID del pool.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: quantità di dati nozionale memorizzata, espressa in kilobyte, a meno che al numero non sia aggiunta una M per megabyte o G per gigabyte.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>%USED</literal>: percentuale nozionale di spazio di memorizzazione utilizzato per ciascun pool.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal>: spazio massimo disponibile nel pool specificato.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal>: numero nozionale di oggetti memorizzati per pool.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    I numeri nella sezione POOLS sono nozionali. Non includono il numero di repliche, snapshot o cloni. Ne risulta che la somma delle quantità di USED e %USED non verrà aggiunta alle quantità di RAW USED e %RAW USED nella sezione %GLOBAL dell'output.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor-status">
  <title>Verifica dello stato di un cluster</title>

  <para>
   Per verificare lo stato di un cluster, eseguire quanto riportato di seguito:
  </para>

<screen><prompt>root # </prompt>ceph status</screen>

  <para>
   oppure
  </para>

<screen><prompt>root # </prompt>ceph -s</screen>

  <para>
   In modalità interattiva, digitare <command>status</command> e premere<keycap function="enter"/>.
  </para>

<screen>ceph&gt; status</screen>

  <para>
   Ceph eseguirà la stampa dello stato del cluster. Ad esempio, un cluster Ceph di piccole dimensioni costituito da un monitoraggio e due OSD può stampare quanto riportato di seguito:
  </para>

<screen>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</screen>
 </sect1>
 <sect1 xml:id="monitor-osdstatus">
  <title>Verifica dello stato degli OSD</title>

  <para>
   È possibile verificare lo stato degli OSD per assicurarsi che siano attivi e funzionanti eseguendo:
  </para>

<screen><prompt>root # </prompt>ceph osd stat</screen>

  <para>
   oppure
  </para>

<screen><prompt>root # </prompt>ceph osd dump</screen>

  <para>
   È inoltre possibile visualizzare gli OSD in base alla rispettiva posizione nella mappa CRUSH.
  </para>

<screen><prompt>root # </prompt>ceph osd tree</screen>

  <para>
   Ceph eseguirà la stampa di un albero CRUSH con un host, i rispettivi OSD, se attivi, e il relativo peso.
  </para>

<screen># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</screen>
 </sect1>
 <sect1 xml:id="storage-bp-monitoring-fullosd">
  <title>Verifica degli OSD pieni</title>

  <para>
   Ceph impedisce la scrittura in un OSD pieno in modo da evitare perdite di dati. In un cluster operativo, quando questo è prossimo al rispettivo rapporto di riempimento si riceve un avviso. L'impostazione di default di <command>mon osd full ratio</command> è 0,95 o 95% della capacità, prima che venga interrotta la scrittura dei dati da parte dei client. L'impostazione di default di <command>mon osd nearfull ratio</command> è 0,85 o 85% della capacità, quando viene generato avviso sullo stato di integrità.
  </para>

  <para>
   I nodi OSD pieni verranno segnalati da <command>ceph health</command>:
  </para>

<screen>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   oppure
  </para>

<screen>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   Il modo migliore per gestire un cluster pieno consiste nell'aggiungere nuovi nodi OSD che consentono al cluster di ridistribuire dati nello spazio di memorizzazione che si è appena reso disponibile.
  </para>

  <para>
   Se non è possibile avviare un OSD perché è pieno, è possibile eliminare alcuni dati eliminando alcune directory dei gruppi di posizionamento nell'OSD pieno.
  </para>

  <tip>
   <title>esclusione degli ODS pieni</title>
   <para>
    Quando un OSD si riempie (utilizza il 100% del rispettivo spazio su disco), di norma questo si blocca rapidamente senza alcun avviso. Di seguito sono riportati alcuni suggerimenti utili per l'amministrazione dei nodi OSD.
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      È necessario posizionare lo spazio su disco di ciascun OSD (di norma montato in <filename>/var/lib/ceph/osd/osd-{1,2..}</filename>) su un disco o una partizione dedicati sottostanti.
     </para>
    </listitem>
    <listitem>
     <para>
      Controllare i file di configurazione Ceph e assicurarsi che il log file Ceph non venga memorizzato nei dischi o nelle partizioni dedicati all'uso da parte degli OSD.
     </para>
    </listitem>
    <listitem>
     <para>
      Assicurarsi che la scrittura nei dischi o nelle partizioni dedicati all'uso da parte degli OSD non venga eseguita da altri processi.
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-monstatus">
  <title>Verifica dello stato del monitoraggio</title>

  <para>
   Se il cluster contiene più monitoraggi (probabile), verificare lo stato di quorum del monitoraggio dopo aver avviato il cluster prima della lettura e/o scrittura dei dati. Quando sono in esecuzione più monitoraggi, deve essere presente un quorum. Periodicamente, verificare anche lo stato dei monitoraggi per assicurarsi che siano in esecuzione.
  </para>

  <para>
   Per visualizzare la mappa del monitoraggio, eseguire quanto riportato di seguito:
  </para>

<screen><prompt>root # </prompt>ceph mon stat</screen>

  <para>
   oppure
  </para>

<screen><prompt>root # </prompt>ceph mon dump</screen>

  <para>
   Per verificare lo stato del quorum per il cluster di monitoraggio, eseguire quanto riportato di seguito:
  </para>

<screen><prompt>root # </prompt>ceph quorum_status</screen>

  <para>
   Ceph restituirà lo stato del quorum. Ad esempio, un cluster Ceph costituito da tre monitoraggi può restituire quanto riportato di seguito:
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "127.0.0.1:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "127.0.0.1:6790\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "127.0.0.1:6791\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor-pgroupstatus">
  <title>Verifica degli stati dei gruppi di posizionamento</title>

  <para>
   Oggetti della mappa dei gruppi di posizionamento negli OSD. Quando si monitorano i gruppi di posizionamento, questi dovranno essere <literal>active</literal> e <literal>clean</literal>. Per informazioni dettagliate, fare riferimento a <link xlink:href="http://docs.ceph.com/docs/master/rados/operations/monitoring-osd-pg">Monitoring OSDs and Placement Groups</link> (in lingua inglese).
  </para>
 </sect1>
 <sect1 xml:id="monitor-adminsocket">
  <title>Utilizzo del socket amministrativo</title>

  <para>
   <remark role="fixme">Maybe give an example use case? No obvious difference to normal ceph command?!</remark> Il socket amministrativo Ceph consente di interrogare un daemon tramite un'interfaccia socket. Per default, i socket Ceph risiedono in <filename>/var/run/ceph</filename>. Per accedere a un daemon tramite il socket amministrativo, eseguire il login all'host sul quale è in esecuzione il daemon e utilizzare il seguente comando:
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable></screen>

  <para>
   Per visualizzare i comandi del socket amministrativo disponibili, eseguire il seguente comando:
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable> help</screen>

  <para>
   I comandi del socket amministrativo consentono di mostrare e impostare la configurazione al momento del runtime. Per informazioni dettagliate, fare riferimento a <link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf#ceph-runtime-config">Viewing a Configuration at Runtime</link> (in lingua inglese).
  </para>

  <para>
   È inoltre possibile impostare i valori di configurazione direttamente in fase di runtime (il socket amministrativo evita il monitoraggio, diversamente dall'injectarg <command>ceph tell</command>
   <replaceable>daemon-type</replaceable>.<replaceable>id</replaceable>, che fa affidamento al monitoraggio ma non richiede il login diretto all'host in questione).
  </para>
 </sect1>
</chapter>
