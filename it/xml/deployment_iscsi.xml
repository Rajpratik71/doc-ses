<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_iscsi.xml" version="5.0" xml:id="cha-ceph-as-iscsi">

 <title>Installazione di iSCSI Gateway</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>modifica</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>sì</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  iSCSI è un protocollo di rete dell'area di storage (SAN) che consente ai client (denominati <emphasis>iniziatori</emphasis>) di inviare comandi SCSI ai dispositivi di storage SCSI (<emphasis>destinazioni</emphasis>) su server remoti. SUSE Enterprise Storage include una struttura che apre la gestione dello storage Ceph a client eterogenei, come Microsoft Windows* e VMware* vSphere, attraverso il protocollo iSCSI. L'accesso multipercorso iSCSI garantisce disponibilità e scalabilità per questi client e il protocollo iSCSI standardizzato fornisce inoltre un ulteriore livello di isolamento di sicurezza tra client e il cluster SUSE Enterprise Storage. La struttura di configurazione è denominata <systemitem>lrbd</systemitem>. Con <systemitem>lrbd</systemitem>, gli amministratori dello storage Ceph possono definire volumi con thin-provisioning, replicati, ad alta disponibilità che supportano snapshot di sola lettura, clone di scrittura-lettura e ridimensionamento automatico con Ceph RADOS Block Device (RBD). Gli amministratori possono quindi esportare i volumi tramite un singolo host gateway <systemitem>lrbd</systemitem> o tramite più host gateway che supportano il failover multipercorso. Gli host Linux, Microsoft Windows e VMware possono collegarsi a volumi che utilizzano il protocollo iSCSI, che li rende disponibili come altri dispositivi di blocco SCSI. Questo significa che i clienti di SUSE Enterprise Storage possono efficacemente eseguire un sottosistema completo dell'infrastruttura di storage di blocco su Ceph che fornisce tutti i vantaggi di un SAN convenzionale, consentendo la crescita futura.
 </para>
 <para>
  Questo capitolo presenta informazioni dettagliate per configurare un'infrastruttura del cluster Ceph insieme con un iSCSI Gateway, in modo che gli host client possano utilizzare da remoto i dati memorizzati come dispositivi di storage locale con il protocollo iSCSI.
 </para>
 <sect1 xml:id="ceph-iscsi-iscsi">
  <title>Storage di blocco iSCSI</title>

  <para>
   iSCSI è un'implementazione del set di comandi Small Computer System Interface (SCSI) mediante il Protocollo Internet (IP), specificato in RFC 3720. iSCSI è implementato come servizio dove un client (l'iniziatore) parla a un server (la destinazione) tramite una sessione sulla porta TCP 3260. Una porta e un indirizzo IP della destinazione iSCSI sono denominati portale iSCSI, dove una destinazione può essere esposta attraverso uno o più portali. La combinazione di una destinazione e uno o più portali è detta gruppo portale di destinazione (target portal group, TPG).
  </para>

  <para>
   Il protocollo del livello collegamento dati sottostante per iSCSI e di solito Ethernet. Più specificamente, le moderne infrastrutture iSCSI utilizzano reti Ethernet 10 Gigabit o più veloci per un throughput ottimale. Si consiglia la connettività Ethernet 10 Gigabit tra iSCSI Gateway e il cluster Ceph back-end.
  </para>

  <sect2 xml:id="ceph-iscsi-iscsi-target">
   <title>La destinazione iSCSI Kernel Linux</title>
   <para>
    La destinazione iSCSI Kernel Linux era in origine denominata LIO per linux-iscsi.org, il dominio originale e sito Web del progetto. Per qualche tempo, erano disponibili per la piattaforma Linux non meno di quattro implementazioni di destinazione iSCSI in concorrenza, ma LIO alla fine ha prevalso come singola destinazione di riferimento iSCSI. Il codice kernel mainline di LIO utilizza il semplice ma certamente ambiguo nome "destinazione", che distingue tra "core di destinazione" e una varietà di moduli di destinazione front-end e back-end.
   </para>
   <para>
    Il modulo front-end più comunemente utilizzato è iSCSI. Tuttavia, LIO supporta anche i protocolli Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) e diversi altri protocolli front-end. Attualmente, è supportato da SUSE Enterprise Storage solo il protocollo iSCSI.
   </para>
   <para>
    Il modulo back-end di destinazione più utilizzato è quello in grado di riesportare semplicemente qualsiasi dispositivo di blocco disponibile sull'host di destinazione. Questo modulo è denominato iblock. Tuttavia, LIO ha anche un modulo back-end specifico RBD che supporta l'accesso I/O multipercorso parallelizzato alle immagini RBD.
   </para>
  </sect2>

  <sect2 xml:id="ceph-iscsi-iscsi-initiators">
   <title>Iniziatori iSCSI</title>
   <para>
    Questa sezione presenta brevi informazioni sugli iniziatori iSCSI utilizzati su piattaforme Linux, Microsoft Windows e VMware.
   </para>
   <sect3>
    <title>Linux</title>
    <para>
     L'iniziatore standard per la piattaforma Linux è <systemitem>open-iscsi</systemitem>. <systemitem>open-iscsi</systemitem> lancia un daemon, <systemitem>iscsid</systemitem>, che l'utente può quindi utilizzare per rilevare destinazioni iSCSI su qualsiasi portale dato, accedere alle destinazioni e mappare volumi iSCSI. <systemitem>iscsid</systemitem> comunica con il livello mediano SCSI per creare dispositivi di blocco nel kernel, che il kernel può quindi trattare come altri dispositivi di blocco SCSI nel sistema. L'iniziatore <systemitem>open-iscsi</systemitem> può essere distribuito insieme con la facility Device Mapper Multipath (<systemitem>dm-multipath</systemitem>) per fornire un dispositivo di blocco iSCSI ad alta disponibilità.
    </para>
   </sect3>
   <sect3>
    <title>Microsoft Windows e Hyper-V</title>
    <para>
     L'iniziatore iSCSI di default per il sistema operativo Microsoft Windows è l'iniziatore Microsoft iSCSI. Il servizio iSCSI può essere configurato tramite un'interfaccia grafica utente (GUI) e supporta I/O multipercorso per alta disponibilità.
    </para>
   </sect3>
   <sect3>
    <title>VMware</title>
    <para>
     L'iniziatore iSCSI di default per VMware vSphere ed ESX è l'iniziatore iSCSI del software VMware ESX, <systemitem>vmkiscsi</systemitem>. Quando abilitato, può essere configurato dal client vSphere o mediante il comando <command>vmkiscsi-tool</command>. È quindi possibile formattare i volumi di storage connessi attraverso l'adattatore di storage vSphere iSCSI con VMFS e utilizzarli come altri dispositivi di storage VM. L'iniziatore VMware supporta anche I/O multipercorso per alta disponibilità.
    </para>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-iscsi-lrbd">
  <title>Informazioni generali su lrbd</title>

  <para>
   <systemitem>lrbd</systemitem> combina i vantaggi dei dispositivi di blocco RADOS con la versatilità diffusa di iSCSI. Impiegando <systemitem>lrbd</systemitem> su un host di destinazione iSCSI (noto come il gateway <systemitem>lrbd</systemitem>), qualsiasi applicazione che deve utilizzare uno storage di blocco può avvantaggiarsi da Ceph, anche se non utilizza alcun protocollo del client Ceph. Al contrario, gli utenti possono utilizzare iSCSI o un altro protocollo front-end di destinazione per collegarsi a una destinazione LIO che traduce tutti gli I/O di destinazione in operazioni di storage RBD.
  </para>

  <figure>
   <title>Cluster Ceph con un singolo iSCSI Gateway</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="lrbd_scheme1.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="lrbd_scheme1.png" width="75%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   <systemitem>lrbd</systemitem> è inerentemente ad alta disponibilità e supporta operazioni multipercorso. Perciò, gli host iniziatori a valle possono utilizzare più iSCSI Gateway per alta disponibilità e scalabilità. Quando si comunica con una configurazione iSCSI con più gateway, gli iniziatori possono bilanciare il carico delle richieste iSCSI tra più gateway. Nel caso in cui un gateway sia in errore, temporaneamente irraggiungibile o disattivato per manutenzione, gli I/O continueranno in modo trasparente attraverso un altro gateway.
  </para>

  <figure>
   <title>Cluster Ceph con più iSCSI Gateway</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="lrbd_scheme2.png" width="75%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="lrbd_scheme2.png" width="75%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>
 </sect1>
 <sect1 xml:id="ceph-iscsi-deploy">
  <title>Considerazioni sull'installazione</title>

  <para>
   Una configurazione minima di SUSE Enterprise Storage con <systemitem>lrbd</systemitem> contiene i seguenti componenti:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Un cluster di storage Ceph. Il cluster Ceph consiste di un minimo di quattro server fisici contenenti almeno otto OSD (object storage daemon) ciascuno. In tale configurazione, tre nodi OSD raddoppiano come host monitor (MON).
    </para>
   </listitem>
   <listitem>
    <para>
     Un server di destinazione iSCSI che esegue la destinazione LIO iSCSI, configurato tramite <systemitem>lrbd</systemitem>.
    </para>
   </listitem>
   <listitem>
    <para>
     Un host iniziatore iSCSI, che esegue <systemitem>open-iscsi</systemitem> (Linux), l'iniziatore Microsoft iSCSI (Microsoft Windows) o qualsiasi altra implementazione di iniziatore iSCSI compatibile.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Una configurazione di produzione raccomandata di SUSE Enterprise Storage con <systemitem>lrbd</systemitem> consiste di:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Un cluster di storage Ceph. Un cluster Ceph di produzione consiste di un numero qualsiasi di (in genere oltre 10) nodi OSD, ciascuno che esegue in genere 10-12 OSD (object storage daemon), con non meno di tre host MON dedicati.
    </para>
   </listitem>
   <listitem>
    <para>
     Diversi server di destinazione iSCSI che eseguono la destinazione LIO iSCSI, configurati tramite <systemitem>lrbd</systemitem>. Per bilanciamento di carico e failover iSCSI, questi server devono eseguire un kernel che supporti il modulo <systemitem>target_core_rbd</systemitem>. Dal canale di manutenzione SUSE Linux Enterprise Server sono disponibili pacchetti di aggiornamento.
    </para>
   </listitem>
   <listitem>
    <para>
     Un numero a scelta di host iniziatori iSCSI, che eseguono <systemitem>open-iscsi</systemitem> (Linux), l'iniziatore Microsoft iSCSI (Microsoft Windows) o qualsiasi altra implementazione di iniziatore iSCSI compatibile.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="ceph-iscsi-install">
  <title>Installazione e configurazione</title>

  <para>
   Questa sezione descrive i passaggi per installare e configurare un iSCSI Gateway su SUSE Enterprise Storage.
  </para>

  <sect2>
   <title>Distribuire iSCSI Gateway in un cluster Ceph</title>
   <para>
    È possibile installare iSCSI Gateway durante il processo di installazione del cluster Ceph, oppure aggiungerlo a un cluster esistente con DeepSea.
   </para>
   <para>
    Per includere iSCSI Gateway durante il processo di installazione del cluster, consultare <xref linkend="policy-role-assignment"/>.
   </para>
   <para>
    Per aggiungere iSCSI Gateway a un cluster esistente, consultare <xref linkend="salt-adding-services"/>.
   </para>
  </sect2>

  <sect2>
   <title>Creare immagini RBD</title>
   <para>
    Le immagini RBD vengono create nello store Ceph e quindi esportate in iSCSI. Per questo scopo, si consiglia di utilizzare un pool RADOS dedicato. È possibile creare un volume da qualsiasi host in grado di collegarsi al cluster di storage mediante l'utility della riga di comando Ceph <command>rbd</command>. Ciò richiede che il client abbia almeno un file di configurazione ceph.conf minimo e appropriate credenziali di autenticazione CephX.
   </para>
   <para>
    Per creare un nuovo volume per la successiva esportazione tramite iSCSI, utilizzare il comando <command>rbd create</command>, specificando la dimensione del volume in megabyte. Ad esempio, per creare un volume da 100 GB con il nome <literal>testvol</literal> nel pool con nome <literal>iscsi</literal>, eseguire:
   </para>
<screen><prompt>root # </prompt>rbd --pool iscsi create --size=102400 testvol</screen>
   <para>
    Il comando precedente crea un volume RBD nel formato di default 2.
   </para>
   <note>
    <para>
     Da SUSE Enterprise Storage 3, il formato del volume di default è 2 mentre il formato 1 è obsoleto. Tuttavia, è ancora possibile creare volumi nel formato 1 obsoleto con l'opzione <option>--image-format 1</option>.
    </para>
   </note>
  </sect2>

  <sect2 xml:id="ceph-iscsi-rbd-export">
   <title>Esportare immagini RBD tramite iSCSI</title>
   <para>
    Per esportare immagini RBD tramite iSCSI, servirsi dell'utility <systemitem>lrbd</systemitem>. <systemitem>lrbd</systemitem> consente di creare, rivedere e modificare la configurazione di destinazione iSCSI che utilizza un formato JSON.
   </para>
   <tip>
    <title>importare modifiche in openATTIC</title>
    <para>
     Eventuali modifiche alla configurazione di iSCSI Gateway apportate con il comando <command>lrbd</command> non sono visibili in DeepSea e openATTIC. Per importare le modifiche manuali, occorre esportare la configurazione di iSCSI Gateway su file:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o /tmp/lrbd.conf
</screen>
    <para>
     Copiarla quindi sul Salt master in modo che sia visibile da DeepSea e openATTIC:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf ses5master:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
    <para>
     Modificare infine <filename>/srv/pillar/ceph/stack/global.yml</filename> e impostare:
    </para>
<screen>
igw_config: default-ui
</screen>
   </tip>
   <para>
    Per modificare la configurazione, utilizzare <command>lrbd -e</command> o <command>lrbd --edit</command>. Questo comando richiama l'editor di default, come definito dalla variabile ambientale <literal>EDITOR</literal>. È possibile sovrascrivere questo comportamento impostando l'opzione <option>-E</option> oltre a <option>-e</option>.
   </para>
   <para>
    Di seguito viene fornita una configurazione di esempio per
   </para>
   <itemizedlist>
    <listitem>
     <para>
      due host iSCSI Gateway denominati <literal>iscsi1.example.com</literal> e <literal>iscsi2.example.com</literal>,
     </para>
    </listitem>
    <listitem>
     <para>
      definendo una singola destinazione iSCSI con un iSCSI Qualified Name (IQN) di <literal>iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol</literal>,
     </para>
    </listitem>
    <listitem>
     <para>
      con una singola unità logica (Logical Unit, LU) iSCSI,
     </para>
    </listitem>
    <listitem>
     <para>
      supportata da un'immagine RBD denominata <literal>testvol</literal> nel pool RADOS <literal>rbd</literal>,
     </para>
    </listitem>
    <listitem>
     <para>
      ed esportando la destinazione tramite due portali denominati "east" e "west":
     </para>
    </listitem>
   </itemizedlist>
<screen>{
    "auth": [
        {
            "target": "iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol",
            "authentication": "none"
        }
    ],
    "targets": [
        {
            "target": "iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol",
            "hosts": [
                {
                    "host": "iscsi1.example.com",
                    "portal": "east"
                },
                {
                    "host": "iscsi2.example.com",
                    "portal": "west"
                }
            ]
        }
    ],
    "portals": [
        {
            "name": "east",
            "addresses": [
                "192.168.124.104"
            ]
        },
        {
            "name": "west",
            "addresses": [
                "192.168.124.105"
            ]
        }
    ],
    "pools": [
        {
            "pool": "rbd",
            "gateways": [
                {
                    "target": "iqn.2003-01.org.linux-iscsi.iscsi.x86:testvol",
                    "tpg": [
                        {
                            "image": "testvol"
                        }
                    ]
                }
            ]
        }
    ]
    }</screen>
   <para>
    Tenere presente che qualora si facesse riferimento a un nome host nella configurazione, tale nome host deve corrispondere al risultato del comando <command>uname -n</command> di iSCSI Gateway.
   </para>
   <para>
    Lo JSON modificato viene memorizzato negli attributi estesi (xattrs) di un singolo oggetto RADOS per pool. Questo oggetto è disponibile per gli host gateway dove viene modificato JSON, oltre che per tutti gli host gateway collegati allo stesso cluster Ceph. Localmente non vengono memorizzate informazioni sul gateway <systemitem>lrbd</systemitem>.
   </para>
   <para>
    Per attivare la configurazione, memorizzarla nel cluster Ceph ed eseguire una delle azioni indicate (come <systemitem class="username">root</systemitem>):
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Eseguire il comando <command>lrbd</command> (senza opzioni aggiuntive) dalla riga di comando,
     </para>
    </listitem>
   </itemizedlist>
   <para>
    oppure
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Riavviare il servizio <systemitem>lrbd</systemitem> con <command>service lrbd restart</command>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Il "servizio" <systemitem>lrbd</systemitem> non opera alcun daemon in background. Richiama invece semplicemente il comando <command>lrbd</command>. Questo tipo di servizio è noto come "one-shot".
   </para>
   <para>
    Abilitare inoltre <systemitem>lrbd</systemitem> per l'autoconfigurazione all'avvio del sistema. Per questo scopo, eseguire il comando <command>systemctl enable lrbd</command>.
   </para>
   <para>
    La configurazione precedente riflette una semplice configurazione con un gateway. La configurazione <systemitem>lrbd</systemitem> può essere molto più complessa e potente. Il pacchetto RPM <systemitem>lrbd</systemitem> è fornito di un set completo di esempi di configurazione, a cui si può fare riferimento controllando il contenuto della directory <filename>/usr/share/doc/packages/lrbd/samples</filename> dopo l'installazione. Gli esempi sono inoltre disponibili da <link xlink:href="https://github.com/SUSE/lrbd/tree/master/samples"/>.
   </para>
  </sect2>

  <sect2 xml:id="ceph-iscsi-rbd-optional">
   <title>Impostazioni opzionali</title>
   <para>
    Le impostazioni seguenti possono essere utili per alcuni ambienti. Per le immagini, sono disponibili gli attributi <option>uuid</option>, <option>lun</option>, <option>retries</option>, <option>sleep</option> e <option>retry_errors</option>. I primi due, <option>uuid</option> e <option>lun</option>, consentono l'hardcoding di "uuid" o "lun" per un'immagine specifica. È possibile specificare uno o l'altro per un'immagine. <option>retries</option>, <option>sleep</option> e <option>retry_errors</option> riguardano i tentativi di mappare un'immagine rbd.
   </para>
<screen>"pools": [
    {
        "pool": "rbd",
        "gateways": [
        {
        "host": "igw1",
        "tpg": [
                    {
                        "image": "archive",
                        "uuid": "12345678-abcd-9012-efab-345678901234",
                        "lun": "2",
                        "retries": "3",
                        "sleep": "4",
                        "retry_errors": [ 95 ],
                        [...]
                    }
                ]
            }
        ]
    }
]</screen>
  </sect2>

  <sect2 xml:id="ceph-iscsi-rbd-advanced">
   <title>Impostazioni avanzate</title>
   <para>
    È possibile configurare <systemitem>lrbd</systemitem> con parametri avanzati passati quindi alla destinazione di I/O di LIO. I parametri sono suddivisi in componenti iSCSI e memorizzazione di massa e possono essere quindi specificati nelle sezioni "targets" e "tpg", rispettivamente, della configurazione <systemitem>lrbd</systemitem>.
   </para>
   <warning>
    <para>
     Si consiglia di non modificare l'impostazione di default di questi parametri.
    </para>
   </warning>
<screen>"targets": [
    {
        [...]
        "tpg_default_cmdsn_depth": "64",
        "tpg_default_erl": "0",
        "tpg_login_timeout": "10",
        "tpg_netif_timeout": "2",
        "tpg_prod_mode_write_protect": "0",
    }
]</screen>
   <para>
    Di seguito viene fornita una descrizione delle opzioni:
   </para>
   <variablelist>
    <varlistentry>
     <term>tpg_default_cmdsn_depth</term>
     <listitem>
      <para>
       Profondità di default CmdSN (Command Sequence Number). Limita la quantità di richieste che l'iniziatore iSCSI può avere in sospeso in qualsiasi momento.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>tpg_default_erl</term>
     <listitem>
      <para>
       Livello di ripristino errore di default.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>tpg_login_timeout</term>
     <listitem>
      <para>
       Valore timeout di login in secondi.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>tpg_netif_timeout</term>
     <listitem>
      <para>
       Timeout errore NIC in secondi.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>tpg_prod_mode_write_protect</term>
     <listitem>
      <para>
       Se impostato a 1, impedisce le scritture sui LUN.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
<screen>"pools": [
    {
        "pool": "rbd",
        "gateways": [
        {
        "host": "igw1",
        "tpg": [
                    {
                        "image": "archive",
                        "backstore_block_size": "512",
                        "backstore_emulate_3pc": "1",
                        "backstore_emulate_caw": "1",
                        "backstore_emulate_dpo": "0",
                        "backstore_emulate_fua_read": "0",
                        "backstore_emulate_fua_write": "1",
                        "backstore_emulate_model_alias": "0",
                        "backstore_emulate_rest_reord": "0",
                        "backstore_emulate_tas": "1",
                        "backstore_emulate_tpu": "0",
                        "backstore_emulate_tpws": "0",
                        "backstore_emulate_ua_intlck_ctrl": "0",
                        "backstore_emulate_write_cache": "0",
                        "backstore_enforce_pr_isids": "1",
                        "backstore_fabric_max_sectors": "8192",
                        "backstore_hw_block_size": "512",
                        "backstore_hw_max_sectors": "8192",
                        "backstore_hw_pi_prot_type": "0",
                        "backstore_hw_queue_depth": "128",
                        "backstore_is_nonrot": "1",
                        "backstore_max_unmap_block_desc_count": "1",
                        "backstore_max_unmap_lba_count": "8192",
                        "backstore_max_write_same_len": "65535",
                        "backstore_optimal_sectors": "8192",
                        "backstore_pi_prot_format": "0",
                        "backstore_pi_prot_type": "0",
                        "backstore_queue_depth": "128",
                        "backstore_unmap_granularity": "8192",
                        "backstore_unmap_granularity_alignment": "4194304"
                    }
                ]
            }
        ]
    }
]</screen>
   <para>
    Di seguito viene fornita una descrizione delle opzioni:
   </para>
   <variablelist>
    <varlistentry>
     <term>backstore_block_size</term>
     <listitem>
      <para>
       Dimensione di blocco del dispositivo sottostante.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_3pc</term>
     <listitem>
      <para>
       Se impostato a 1, abilita Third Party Copy.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_caw</term>
     <listitem>
      <para>
       Se impostato a 1, abilita Compare e Write.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_dpo</term>
     <listitem>
      <para>
       Se impostato a 1, attiva Disable Page Out.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_fua_read</term>
     <listitem>
      <para>
       Se impostato a 1, attiva la lettura Force Unit Access.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_fua_write</term>
     <listitem>
      <para>
       Se impostato a 1, abilita la scrittura Force Unit Access.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_model_alias</term>
     <listitem>
      <para>
       Se impostato a 1, utilizza il nome del dispositivo back-end per l'alias modello.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_rest_reord</term>
     <listitem>
      <para>
       Se impostato a 0, il modificatore algoritmo di coda ha riordinamento limitato.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_tas</term>
     <listitem>
      <para>
       Se impostato a 1, abilita Task Aborted Status.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_tpu</term>
     <listitem>
      <para>
       Se impostato a 1, abilita Thin Provisioning Unmap.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_tpws</term>
     <listitem>
      <para>
       Se impostato a 1, abilita Thin Provisioning Write Same.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_ua_intlck_ctrl</term>
     <listitem>
      <para>
       Se impostato a 1, abilita Unit Attention Interlock.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_emulate_write_cache</term>
     <listitem>
      <para>
       Se impostato a 1, attiva Write Cache Enable.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_enforce_pr_isids</term>
     <listitem>
      <para>
       Se impostato a 1, applica gli ISID di prenotazione persistenti.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_fabric_max_sectors</term>
     <listitem>
      <para>
       Numero massimo di settori trasferibili dall'infrastruttura in una volta.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_hw_block_size</term>
     <listitem>
      <para>
       Dimensione blocco hardware in byte.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_hw_max_sectors</term>
     <listitem>
      <para>
       Numero massimo di settori trasferibili dall'hardware in una volta.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_hw_pi_prot_type</term>
     <listitem>
      <para>
       Se diverso da zero, la protezione DIF è abilitata sull'hardware sottostante.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_hw_queue_depth</term>
     <listitem>
      <para>
       Profondità coda hardware.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_is_nonrot</term>
     <listitem>
      <para>
       Se impostato a 1, il backstore è un dispositivo non rotativo.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_max_unmap_block_desc_count</term>
     <listitem>
      <para>
       Numero massimo di descrittori di blocco per UNMAP.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_max_unmap_lba_count:</term>
     <listitem>
      <para>
       Numero massimo di LBA per UNMAP.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_max_write_same_len</term>
     <listitem>
      <para>
       Lunghezza massima per WRITE_SAME.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_optimal_sectors</term>
     <listitem>
      <para>
       Dimensione richiesta ottimale in settori.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_pi_prot_format</term>
     <listitem>
      <para>
       Formato di protezione DIF.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_pi_prot_type</term>
     <listitem>
      <para>
       Tipo di protezione DIF.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_queue_depth</term>
     <listitem>
      <para>
       Profondità coda.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_unmap_granularity</term>
     <listitem>
      <para>
       Granularità UNMAP.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>backstore_unmap_granularity_alignment</term>
     <listitem>
      <para>
       Allineamento granularità UNMAP.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    Per le destinazioni, gli attributi <option>tpg</option> consentono la regolazione dei parametri del kernel. Utilizzare con cautela.
   </para>
<screen>"targets": [
{
    "host": "igw1",
    "target": "iqn.2003-01.org.linux-iscsi.generic.x86:sn.abcdefghijk",
    "tpg_default_cmdsn_depth": "64",
    "tpg_default_erl": "0",
    "tpg_login_timeout": "10",
    "tpg_netif_timeout": "2",
    "tpg_prod_mode_write_protect": "0",
    "tpg_t10_pi": "0"
}</screen>
   <tip>
    <para>
     Se un sito richiede LUN assegnati staticamente, assegnare numeri a ogni LUN.
    </para>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="iscsi-tcmu">
  <title>Esportazione di immagini dispositivo di blocco RADOS con <systemitem>tcmu-runner</systemitem></title>

  <para>
   Dalla versione 5, SUSE Enterprise Storage fornisce un back-end RBD di spazio utente per <systemitem>tcmu-runner</systemitem> (per informazioni, vedere <command>man 8 tcmu-runner</command>).
  </para>

  <warning>
   <title>tecnologia in anteprima</title>
   <para>
    Le distribuzioni di iSCSI Gateway basate su <systemitem>tcmu-runner</systemitem> sono attualmente un'anteprima. Vedere <xref linkend="cha-ceph-as-iscsi"/> per istruzioni sulla distribuzione di iSCSI Gateway basata su kernel con <systemitem>lrbd</systemitem>.
   </para>
  </warning>

  <para>
   A differenza delle distribuzioni di iSCSI Gateway <systemitem>lrbd</systemitem> basate su kernel, gli iSCSI Gateway basati su <systemitem>tcmu-runner</systemitem> non offrono supporto per I/O multipercorso o prenotazioni persistenti SCSI.
  </para>

  <para>
   Poiché DeepSea e openATTIC attualmente non supportano distribuzioni <systemitem>tcmu-runner</systemitem>, è necessario gestire installazione, distribuzione e monitoraggio manualmente.
  </para>

  <sect2 xml:id="iscsi-tcmu-install">
   <title>Installazione</title>
   <para>
    Sul nodo iSCSI Gateway, installare il pacchetto <systemitem>tcmu-runner-handler-rbd</systemitem> dal supporto di SUSE Enterprise Storage 5, insieme con le dipendenze del pacchetto <systemitem>libtcmu1</systemitem> e <systemitem>tcmu-runner</systemitem>. Installare il pacchetto <systemitem>targetcli-fb</systemitem> a scopo di configurazione. Tenere presente che il pacchetto <systemitem>targetcli-fb</systemitem> è incompatibile con la versione "non-fb" del pacchetto <systemitem>targetcli</systemitem>.
   </para>
   <para>
    Verificare che il servizio <systemitem>tcmu-runner</systemitem> <systemitem class="daemon">systemd</systemitem> sia in esecuzione:
   </para>
<screen><prompt>root # </prompt>systemctl enable tcmu-runner
tcmu-gw:~ # systemctl status tcmu-runner
● tcmu-runner.service - LIO Userspace-passthrough daemon
  Loaded: loaded (/usr/lib/systemd/system/tcmu-runner.service; static; vendor
  preset: disabled)
    Active: active (running) since ...</screen>
  </sect2>

  <sect2 xml:id="iscsi-tcmu-depl">
   <title>Configurazione e installazione</title>
   <para>
    Creare un'immagine del dispositivo di blocco RADOS sul cluster Ceph esistente. Nell'esempio seguente, si utilizza un'immagine 10G denominata "tcmu-lu" ubicata nel pool "rbd".
   </para>
   <para>
    Dopo la creazione dell'immagine del dispositivo di blocco RADOS, eseguire <command>targetcli</command> e assicurare che sia disponibile il gestore RBD tcmu-runner (plug-in):
   </para>
<screen><prompt>root # </prompt>targetcli
targetcli shell version 2.1.fb46
Copyright 2011-2013 by Datera, Inc and others.
For help on commands, type 'help'.

/&gt; ls
o- / ................................... [...]
  o- backstores ........................ [...]
...
  | o- user:rbd ......... [Storage Objects: 0]</screen>
   <para>
    Creare una voce di configurazione backstore per l'immagine RBD:
   </para>
<screen>/&gt; cd backstores/user:rbd
/backstores/user:rbd&gt; create tcmu-lu 10G /rbd/tcmu-lu
Created user-backed storage object tcmu-lu size 10737418240.</screen>
   <para>
    Creare una voce di configurazione trasparente iSCSI. Nell'esempio seguente, la destinazione IQN "iqn.2003-01.org.linux-iscsi.tcmu-gw.x8664:sn.cb3d2a3a" viene generata automaticamente da <command>targetcli</command> per l'uso come identificatore univoco della destinazione iSCSI:
   </para>
<screen>/backstores/user:rbd&gt; cd /iscsi
/iscsi&gt; create
Created target iqn.2003-01.org.linux-iscsi.tcmu-gw.x8664:sn.cb3d2a3a.
Created TPG 1.
Global pref auto_add_default_portal=true
Created default portal listening on all IPs (0.0.0.0), port 3260.</screen>
   <para>
    Creare una voce ACL per gli iniziatori iSCSI da connettere alla destinazione. Nell'esempio seguente, viene utilizzato un iniziatore IQN of "iqn.1998-01.com.vmware:esxi-872c4888":
   </para>
<screen>/iscsi&gt; cd
iqn.2003-01.org.linux-iscsi.tcmu-gw.x8664:sn.cb3d2a3a/tpg1/acls/
/iscsi/iqn.20...a3a/tpg1/acls&gt; create iqn.1998-01.com.vmware:esxi-872c4888</screen>
   <para>
    Infine, collegare la configurazione backstore RBD creata in precedenza alla destinazione iSCSI:
   </para>
<screen>/iscsi/iqn.20...a3a/tpg1/acls&gt; cd ../luns
/iscsi/iqn.20...a3a/tpg1/luns&gt; create /backstores/user:rbd/tcmu-lu
Created LUN 0.
Created LUN 0-&gt;0 mapping in node ACL iqn.1998-01.com.vmware:esxi-872c4888</screen>
   <para>
    Uscire dalla shell per salvare la configurazione esistente:
   </para>
<screen>/iscsi/iqn.20...a3a/tpg1/luns&gt; exit
Global pref auto_save_on_exit=true
Last 10 configs saved in /etc/target/backup.
Configuration saved to /etc/target/saveconfig.json</screen>
  </sect2>

  <sect2 xml:id="iscsi-tcmu-use">
   <title>Utilizzo</title>
   <para>
    Dal nodo iniziatore iSCSI (client), connettersi al target iSCSI appena predisposto mediante IQN e nome host configurati sopra.
   </para>
  </sect2>
 </sect1>
</chapter>
