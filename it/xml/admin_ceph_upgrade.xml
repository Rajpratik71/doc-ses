<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Upgrade dalle release precedenti</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>modifica</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>sì</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Questo capitolo presenta la procedura per l'upgrade di SUSE Enterprise Storage dalle release precedenti a quella attuale.
 </para>
 <sect1 xml:id="ceph-upgrade-relnotes">
  <title>Lettura delle note di rilascio</title>

  <para>
   Nelle note di rilascio è possibile trovare informazioni aggiuntive sulle modifiche apportate rispetto alla release precedente di SUSE Enterprise Storage. Controllare le note di rilascio per vedere se:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     l'hardware necessita di considerazioni speciali;
    </para>
   </listitem>
   <listitem>
    <para>
     i pacchetti software utilizzati hanno subito modifiche significative;
    </para>
   </listitem>
   <listitem>
    <para>
     è necessario adottare precauzioni speciali per l'installazione.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Le note di rilascio forniscono inoltre informazioni che non si è fatto in tempo a riportare nel manuale. Contengono anche alcune note su problemi noti.
  </para>

  <para>
   Dopo aver installato il pacchetto <package>release-notes-ses</package> , individuare localmente le note di rilascio nella directory <filename>/usr/share/doc/release-notes</filename> o online all'indirizzo <link xlink:href="https://www.suse.com/releasenotes/"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-upgrade-general">
  <title>Procedura di upgrade generica</title>

  <para>
   Prima di avviare la procedura di upgrade, considerare quanto segue:
  </para>

  <variablelist>
   <varlistentry>
    <term>Ordine di upgrade</term>
    <listitem>
     <para>
      Prima di eseguire l'upgrade del cluster Ceph, si devono registrare entrambi i SUSE Linux Enterprise Server e SUSE Enterprise Storage sottostanti a fronte di SCC o SMT. È possibile eseguire l'upgrade dei daemon nel cluster mentre il cluster è online e in servizio. Alcuni tipi di daemon dipendono da altri. Ad esempio, i Ceph Object Gateway dipendono dai Ceph monitor e dai daemon Ceph OSD. Si consiglia di eseguire l'upgrade in questo ordine:
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        Ceph Monitor
       </para>
      </listitem>
      <listitem>
       <para>
        Ceph Manager
       </para>
      </listitem>
      <listitem>
       <para>
        Ceph OSD
       </para>
      </listitem>
      <listitem>
       <para>
        Metadata Server
       </para>
      </listitem>
      <listitem>
       <para>
        Object Gateway
       </para>
      </listitem>
      <listitem>
       <para>
        iSCSI Gateway
       </para>
      </listitem>
      <listitem>
       <para>
        NFS Ganesha
       </para>
      </listitem>
     </orderedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Eliminare le snapshot non necessarie del sistema operativo</term>
    <listitem>
     <para>
      Rimuovere le snapshot non necessarie del file system nelle partizioni del sistema operativo dei nodi. Ciò garantisce che durante l'upgrade vi sia spazio libero sufficiente su disco.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Verificare lo stato del cluster</term>
    <listitem>
     <para>
      Si consiglia di verificare lo stato del cluster prima di avviare la procedura di upgrade.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Eseguire l'upgrade di uno alla volta</term>
    <listitem>
     <para>
      Si consiglia di eseguire l'upgrade di tutti i daemon di un tipo specifico, ad esempio tutti i daemon monitor o tutti i daemon OSD, uno a uno per garantire che abbiano tutti la stessa release. Consigliamo inoltre di eseguire l'upgrade di tutti i daemon nel cluster prima di poter utilizzare le nuove funzionalità di una release.
     </para>
     <para>
      Dopo aver eseguito l'upgrade di tutti i daemon di un tipo specifico, verificarne lo stato.
     </para>
     <para>
      Verificare che dopo l'upgrade di tutti i monitor, ogni monitor abbia raggiunto il quorum:
     </para>
<screen><prompt>root # </prompt>ceph mon stat</screen>
     <para>
      Accertare che ogni daemon Ceph OSD abbia raggiunto il cluster dopo l'upgrade di tutti gli OSD:
     </para>
<screen><prompt>root # </prompt>ceph osd stat</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>
     Impostare il flag <option>require-osd-release luminous</option>
    </term>
    <listitem>
     <para>
      Dopo aver eseguito l'upgrade dell'ultimo OSD a SUSE Enterprise Storage 5, i nodi monitor rilevano che tutti gli OSD eseguono la versione "luminous" di Ceph e possono rilevare che il flag osdmap <option>require-osd-release luminous</option> non è impostato. In tale caso, occorre impostare questo flag manualmente per prendere atto che, dopo aver effettuato l'upgrade del cluster a "luminous", non è possibile ripristinarlo a Ceph "jewel". Impostare il flag eseguendo il comando di seguito:
     </para>
<screen><prompt>root@minion &gt; </prompt>sudo ceph osd require-osd-release luminous</screen>
     <para>
      Al termine dell'esecuzione del comando, l'avvertenza scompare.
     </para>
     <para>
      Nelle nuove installazioni di SUSE Enterprise Storage 5, questo flag è impostato automaticamente quando i Ceph monitor creano l'osdmap iniziale, quindi non è richiesta alcuna azione dell'utente finale.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="ds-migrate-osd-encrypted">
  <title>Cifratura degli OSD durante l'upgrade</title>

  <para>
   A partire da SUSE Enterprise Storage 5, gli OSD sono distribuiti di default tramite BlueStore invece di FileStore. Sebbene BlueStore supporti la cifratura, i Ceph OSD sono distribuiti non cifrati di default. La procedura seguente descrive i passaggi per cifrare gli OSD durante il processo di upgrade. Supponiamo che entrambi i dischi WAL/DB e dati da utilizzare per la distribuzione OSD siano vuoti e senza partizioni. Se il disco è già stato utilizzato, cancellarlo mediante la procedura seguente descritta in <xref linkend="deploy-wiping-disk"/>.
  </para>

  <important>
   <title>un OSD alla volta</title>
   <para>
    È necessario distribuire gli OSD cifrati uno alla volta, non contemporaneamente. Il motivo è che i dati dell'OSD vengono eliminati e il cluster passa attraverso diverse iterazioni di ribilanciamento.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Determinare i valori <option>bluestore block db size</option> e <option>bluestore block wal size</option> per la distribuzione e aggiungerli al file <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename> nel Salt master. I valori devono essere specificati in byte.
    </para>
<screen>
[global]
bluestore block db size = 48318382080
bluestore block wal size = 2147483648
</screen>
    <para>
     Per ulteriori informazioni sulla personalizzazione di <filename>ceph.conf</filename>, consultare <xref linkend="ds-custom-cephconf"/>.
    </para>
   </step>
   <step>
    <para>
     Eseguire DeepSea Stage 3 per distribuire le modifiche:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
   </step>
   <step>
    <para>
     Verificare che il file <filename>ceph.conf</filename> sia aggiornato sui relativi nodi OSD:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>cat /etc/ceph/ceph.conf
</screen>
   </step>
   <step>
    <para>
     Modificare i file *.yml nella directory <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions</filename> pertinenti agli OSD che vengono cifrati. Verificare attentamente il percorso con quello definito nel file <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> per accertare di modificare i file *.yml corretti.
    </para>
    <important>
     <title>identificativi di disco lunghi</title>
     <para>
      Quando si identificano i dischi OSD nei file <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/*.yml</filename>, utilizzare identificativi di disco lunghi.
     </para>
    </important>
    <para>
     Di seguito viene fornito un esempio di configurazione OSD. Poiché è richiesta la cifratura, tenere presente che le opzioni <option>db_size</option> e <option>wal_size</option> sono eliminate:
    </para>
<screen>
ceph:
 storage:
   osds:
     /dev/disk/by-id/scsi-SDELL_PERC_H730_Mini_007027b1065faa972100d34d7aa06d86:
       format: bluestore
       encryption: dmcrypt
       db: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
       wal: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
     /dev/disk/by-id/scsi-SDELL_PERC_H730_Mini_00d146b1065faa972100d34d7aa06d86:
       format: bluestore
       encryption: dmcrypt
       db: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
       wal: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
</screen>
   </step>
   <step>
    <para>
     Distribuire i nuovi Block Storage OSD con la cifratura eseguendo le fasi 2 e 3 di DeepSea:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
    <para>
     È possibile controllare l'avanzamento con <command>ceph -s</command> o <command>ceph osd tree</command>. È fondamentale lasciare ribilanciare il cluster prima di ripetere il processo sul successivo nodo OSD.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5">
  <title>Eseguire l'upgrade da SUSE Enterprise Storage 4 (distribuzione DeepSea) a 5</title>

  <important xml:id="u4to5-softreq">
   <title>requisiti del software</title>
   <para>
    Prima di iniziare la procedura di upgrade, è necessario che il software seguente sia installato e aggiornato alle versioni del package più recenti su tutti i nodi Ceph per cui si desidera eseguire l'upgrade:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Inoltre, prima di avviare l'upgrade, occorre eseguire l'upgrade del nodo Salt master a SUSE Linux Enterprise Server 12 SP3 e SUSE Enterprise Storage 5 eseguendo <command>zypper migration</command> (o il modo di upgrade preferito).
   </para>
  </important>

  <warning>
   <title>punti da tenere presente prima dell'upgrade</title>
   <itemizedlist>
    <listitem>
     <para>
      Verificare che il servizio AppArmor sia in esecuzione e disattivarlo su ciascun nodo cluster. Avviare il modulo YaST AppArmor, selezionare <guimenu>Settings</guimenu> (Impostazioni), quindi deselezionare la casella di controllo <guimenu>Enable Apparmor</guimenu> (Abilita Apparmor). Confermare con <guimenu>Done</guimenu> (Fine).
     </para>
     <para>
      Tenere presente che SUSE Enterprise Storage <emphasis>non</emphasis> funziona con AppArmor attivato.
     </para>
    </listitem>
    <listitem>
     <para>
      Sebbene il cluster sia completamente funzionale durante l'upgrade, DeepSea imposta il flag "noout" che impedisce a Ceph di ribilanciare i dati durante il tempo di indisponibilità, quindi evita i trasferimenti di dati non necessari.
     </para>
    </listitem>
    <listitem>
     <para>
      Per ottimizzare il processo di upgrade, DeepSea esegue l'upgrade dei nodi nell'ordine, in base al ruolo assegnato come consigliato da Ceph a monte: MON, MGR, OSD, MDS, RGW, IGW e NFS Ganesha.
     </para>
     <para>
      Tenere presente che DeepSea non è in grado di impedire la violazione dell'ordine prescritto se un nodo esegue più servizi.
     </para>
    </listitem>
    <listitem>
     <para>
      Sebbene il cluster Ceph sia operativo durante l'upgrade, i nodi potrebbero venire riavviati per applicare, ad esempio, le nuove versioni del kernel. Per ridurre le operazioni di I/O in attesa, si consiglia di rifiutare le richieste in entrata durante il processo di upgrade.
     </para>
    </listitem>
    <listitem>
     <para>
      L'upgrade del cluster può richiedere molto tempo, circa lo stesso richiesto per eseguire l'upgrade su un computer moltiplicato per il numero di nodi del cluster.
     </para>
    </listitem>
    <listitem>
     <para>
      A partire da Ceph Luminous, l'opzione di configurazione <option>osd crush location</option> non è più supportata. Aggiornare i file di configurazione DeepSea per utilizzare <command>crush location</command> prima dell'upgrade.
     </para>
    </listitem>
   </itemizedlist>
  </warning>

  <para>
   Per eseguire l'upgrade del cluster SUSE Enterprise Storage 4 alla versione 5, attenersi a questa procedura:
  </para>

  <procedure>
   <step>
    <para>
     Impostare il nuovo ordinamento degli oggetti interni, eseguire:
    </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    <tip>
     <para>
      Per verificare che il comando sia stato eseguito, si consiglia di eseguire
     </para>
<screen><prompt>root # </prompt>ceph osd dump --format json-pretty | grep sortbitwise
 "flags": "sortbitwise,recovery_deletes,purged_snapdirs",</screen>
    </tip>
   </step>
   <step>
    <para>
     Con <command>rpm -q deepsea</command>, verificare che la versione del pacchetto DeepSea sul nodo Salt master inizi almeno con <literal>0.7</literal>. Ad esempio:
    </para>
<screen><prompt>root # </prompt>rpm -q deepsea
deepsea-0.7.27+git.0.274c55d-5.1</screen>
    <para>
     Se il numero di versione del pacchetto DeepSea inizia con 0.6, verificare di aver eseguito correttamente la migrazione del nodo Salt master a SUSE Linux Enterprise Server 12 SP3 e SUSE Enterprise Storage 5 (consultare <xref linkend="u4to5-softreq"/> all'inizio di questa sezione). Si tratta di un prerequisito da completare prima di avviare la procedura di upgrade.
    </para>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Se i sistemi sono stati registrati con SUSEConnect e si utilizza SCC/SMT, non sono richieste ulteriori azioni. Continuare con <xref linkend="step-updatepillar"/>.
      </para>
     </step>
     <step>
      <para>
       Se <emphasis role="bold">non</emphasis> si utilizza SCC/SMT ma un Media-ISO o altra sorgente del pacchetto, aggiungere i seguenti repository manualmente: SLE12-SP3 Base, SLE12-SP3 Update, SES5 Base e SES5 Update. Per questo scopo, è possibile utilizzare il comando <command>zypper</command>. Rimuovere prima tutti i repository software esistenti, quindi aggiungere quelli nuovi richiesti e infine aggiornare le sorgenti dei repository:
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
      <para>
       Cambiare quindi i dati di Pillar per utilizzare una diversa strategia. Modificare
      </para>
<screen>/srv/pillar/ceph/stack/<replaceable>name_of_cluster</replaceable>/cluster.yml</screen>
      <para>
       e aggiungere la riga seguente:
      </para>
<screen>upgrade_init: zypper-dup</screen>
      <tip>
       <para>
        La strategia <literal>zypper-dup</literal> richiede di aggiungere manualmente i repository software più recenti, mentre <literal>zypper-migration</literal> di default si basa sui repository forniti da SCC/SMT.
       </para>
      </tip>
     </step>
    </substeps>
   </step>
   <step xml:id="step-updatepillar">
    <para>
     Aggiornare il Pillar:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> saltutil.sync_all</screen>
    <para>
     Per informazioni sull'indirizzamento dei Salt minion, vedere <xref linkend="ds-minion-targeting"/>.
    </para>
   </step>
   <step>
    <para>
     Verificare che la scrittura su Pillar sia riuscita:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.get upgrade_init</screen>
    <para>
     Il risultato del comando dovrebbe rispecchiare la voce aggiunta.
    </para>
   </step>
   <step>
    <para>
     Eseguire l'upgrade dei Salt minion:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> state.apply ceph.updates.salt</screen>
   </step>
   <step>
    <para>
     Verificare che sia stato eseguito l'upgrade di tutti i Salt minion:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> test.version</screen>
   </step>
   <step>
    <para>
     Includere i Salt minion del cluster. Per ulteriori dettagli, fare riferimento a <xref linkend="ds-minion-targeting"/> di <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Avviare l'upgrade di SUSE Linux Enterprise Server e Ceph:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.maintenance.upgrade</screen>
    <tip>
     <title>rieseguire all'avvio</title>
     <para>
      Se il processo determina il riavvio del Salt master, rieseguire il comando per avviare il processo di upgrade per i Salt minion.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Verificare che dopo l'upgrade, AppArmor sia disattivato e arrestato su tutti i nodi:
    </para>
<screen><prompt>root # </prompt>systemctl disable apparmor.service
systemctl stop apparmor.service</screen>
   </step>
   <step>
    <para>
     Dopo l'upgrade, i Ceph Manager non sono ancora installati. Per ottenere uno stato migliore del cluster, attenersi a questa procedura:
    </para>
    <substeps>
     <step>
      <para>
       Eseguire la Fase 0 per attivare l'API REST Salt:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
     </step>
     <step>
      <para>
       Eseguire la Fase 1 per creare la sottodirectory <filename>role-mgr/</filename>:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
     </step>
     <step>
      <para>
       Modificare <guimenu>policy.cfg</guimenu> come descritto in <xref linkend="policy-configuration"/> e aggiungere un ruolo Ceph Manager dove sono distribuiti i Ceph Monitor. Inoltre, aggiungere il ruolo openATTIC a uno dei nodi cluster. Per ulteriori dettagli, fare riferimento a <xref linkend="ceph-oa"/>.
      </para>
     </step>
     <step>
      <para>
       Eseguire la Fase 2 per aggiornare il Pillar:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
     </step>
     <step>
      <para>
       DeepSea utilizza un diverso approccio per generare ora il file di configurazione <filename>ceph.conf</filename>, per ulteriori informazioni, consultare <xref linkend="ds-custom-cephconf"/>.
      </para>
     </step>
     <step>
      <para>
       Per distribuire i Ceph Manager, eseguire la Fase 3:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     </step>
     <step>
      <para>
       Per configurare correttamente openATTIC, eseguire la Fase 4:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
     </step>
    </substeps>
    <note>
     <title>errata corrispondenza capacità chiave Ceph</title>
     <para>
      Se si verifica un errore di <literal>ceph.stage.3</literal> con "Error EINVAL: entity client.bootstrap-osd exists but caps do not match", le capacità (cap) chiave per la chiave esistente <literal>client.bootstrap.osd</literal> del cluster non corrispondono alle cap che DeepSea sta cercando di impostare. Sopra il messaggio di errore, in testo rosso, è possibile vedere un dump del comando <command>ceph auth</command> non riuscito. Osservare il comando per verificare il file e ID chiave in uso. In caso di <literal>client.bootstrap-osd</literal>, il comando sarà
     </para>
<screen><prompt>root # </prompt>ceph auth add client.bootstrap-osd \
 -i /srv/salt/ceph/osd/cache/bootstrap.keyring</screen>
     <para>
      Per risolvere le cap chiave non corrispondenti, controllare il contenuto del file portachiavi che DeepSea cerca di distribuire, ad esempio:
     </para>
<screen><prompt>cephadm &gt; </prompt>cat /srv/salt/ceph/osd/cache/bootstrap.keyring
[client.bootstrap-osd]
     key = AQD6BpVZgqVwHBAAQerW3atANeQhia8m5xaigw==
     caps mgr = "allow r"
     caps mon = "allow profile bootstrap-osd"</screen>
     <para>
      Confrontarlo con il risultato di <command>ceph auth get client.bootstrap-osd</command>:
     </para>
<screen><prompt>root # </prompt>ceph auth get client.bootstrap-osd
exported keyring for client.bootstrap-osd
[client.bootstrap-osd]
     key = AQD6BpVZgqVwHBAAQerW3atANeQhia8m5xaigw==
     caps mon = "allow profile bootstrap-osd"</screen>
     <para>
      Notare nell'ultima chiave la mancanza di <literal>caps mgr = "allow r"</literal>. Per risolvere, eseguire:
     </para>
<screen><prompt>root # </prompt>ceph auth caps client.bootstrap-osd mgr \
 "allow r" mon "allow profile bootstrap-osd"</screen>
     <para>
      L'esecuzione di <literal>ceph.stage.3</literal> dovrebbe ora riuscire.
     </para>
     <para>
      Lo stesso problema può verificarsi con i portachiavi di Metadata Server e Object Gateway quando si esegue <literal>ceph.stage.4</literal>. Applicare la stessa procedura precedente: verificare il comando non riuscito, il file portachiavi distribuito e le cap della chiave esistente. Eseguire quindi <command>ceph auth caps</command> per aggiornare le cap della chiave esistenti in modo che corrispondano a quanto viene distribuito da DeepSea.
     </para>
    </note>
   </step>
  </procedure>

  <important>
   <title>upgrade non riuscito</title>
   <para>
    Se il cluster resta nello stato "HEALTH_ERR" per oltre 300 secondi, oppure uno dei servizi per ciascun ruolo assegnato non è attivo per oltre 900 secondi, l'upgrade non è riuscito. In tale caso, cercare di individuare il problema, risolverlo e rieseguire la procedura di upgrade. Tenere presente che negli ambienti virtualizzati, i timeout sono più brevi.
   </para>
  </important>

  <important>
   <title>riavvio degli OSD</title>
   <para>
    Dopo aver eseguito l'upgrade a SUSE Enterprise Storage 5, gli OSD FileStore richiedono circa cinque minuti di più per l'avvio, in quanto l'OSD esegue una conversione one-off dei propri file su disco.
   </para>
  </important>

  <tip>
   <title>verificare la versione dei nodi/componenti del cluster</title>
   <para>
    Se occorre individuare le versioni dei singoli componenti e nodi del cluster, ad esempio per vedere se tutti i nodi hanno effettivamente lo stesso livello di patch dopo l'upgrade, è possibile eseguire
   </para>
<screen><prompt>root@master # </prompt>salt-run status.report</screen>
   <para>
    Il comando passa attraverso i Salt minion connessi e analizza i numeri di versione di Ceph, Salt e SUSE Linux Enterprise Server, fornendo un report che visualizza la versione della maggioranza dei nodi e mostrando i nodi la cui versione è diversa da quella della maggioranza.
   </para>
  </tip>

  <sect2 xml:id="filestore2bluestore">
   <title>Migrazione OSD a BlueStore</title>
   <para>
    OSD BlueStore è un nuovo back end per i daemon OSD. È l'opzione predefinita da SUSE Enterprise Storage 5. Rispetto a FileStore, che memorizza gli oggetti come file in un file system XFS, BlueStore è in grado di fornire prestazioni migliori perché memorizza gli oggetti direttamente sul dispositivo di blocco sottostante. BlueStore dispone inoltre di altre funzionalità, come la compressione integrata e sovrascrittura EC, non disponibili in FileStore.
   </para>
   <para>
    Specificamente per BlueStore, un OSD ha un dispositivo "wal" (Write Ahead Log) e un dispositivo "db" (RocksDB database). Il database RocksDB contiene i metadati per un OSD BlueStore. Questi due dispositivi risiedono di default sullo stesso dispositivo di un OSD, ma è possibile posizionare uno o l'altro su supporti più veloci/diversi.
   </para>
   <para>
    In SES5, sono supportati FileStore e BlueStore ed è possibile che gli OSD FileStore e BlueStore coesistano in un singolo cluster. Durante la procedura di upgrade di SUSE Enterprise Storage, gli OSD FileStore non vengono convertiti automaticamente a BlueStore. Ricordare che le funzionalità specifiche di BlueStore non sono disponibili sugli OSD non migrati a BlueStore.
   </para>
   <para>
    Prima della conversione a BlueStore, gli OSD devono eseguire SUSE Enterprise Storage 5. La conversione è un processo lento, in quanto tutti i dati vengono riscritti due volte. Benché il processo di migrazione possa richiedere molto tempo per il completamento, non vi è interruzione dell'attività del cluster e tutti i client possono continuare ad accedere al cluster durante questo periodo. Tuttavia, durante il processo di migrazione le prestazioni saranno ridotte, perché i dati del cluster vengono ribilanciati e ricostituiti.
   </para>
   <para>
    Per migrare gli OSD FileStore a BlueStore, utilizzare la procedura seguente:
   </para>
   <tip>
    <title>disattivare tutte le misure di sicurezza</title>
    <para>
     I comandi Salt necessari per eseguire la migrazione sono bloccati da misure di sicurezza. Per disattivare queste precauzioni, eseguire questo comando:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disengage.safety
</screen>
   </tip>
   <procedure>
    <step>
     <para>
      Migrare i profili hardware:
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.policy</screen>
     <para>
      Questo runner si occupa della migrazione dei profili hardware utilizzati dal file <filename>policy.cfg</filename>. Elabora <filename>policy.cfg</filename>, individua eventuali profili hardware che utilizzano la struttura dati originale e li converte alla nuova struttura dei dati. Il risultato è un nuovo profilo hardware denominato "migrated-<replaceable>original_name</replaceable>". Viene anche aggiornato <filename>policy.cfg</filename>.
     </para>
     <para>
      Se la configurazione originale presenta giornali di registrazione separati, la configurazione di BlueStore utilizzerà lo stesso dispositivo per "wal" e "db" per tale OSD.
     </para>
    </step>
    <step>
     <para>
      DeepSea migra gli OSD impostandone i pesi a 0 "svuotando" i dati finché l'OSD non è vuoto. È possibile migrare gli OSD uno alla volta o tutti gli OSD insieme. In un caso o nell'altro, quando l'OSD è vuoto, l'orchestrazione lo rimuove e lo ricrea con la nuova configurazione.
     </para>
     <tip>
      <title>metodo consigliato</title>
      <para>
       Se è presente un grande numero di nodi di storage fisici o quasi assenza di dati, utilizzare <command>ceph.migrate.nodes</command>. Se un nodo rappresenta meno del 10% della capacità, <command>ceph.migrate.nodes</command> può essere marginalmente può veloce a spostare tutti i dati dagli OSD in parallelo.
      </para>
      <para>
       Se non si è certi del metodo da utilizzare, oppure se il sito contiene pochi nodi di storage (ad esempio ogni nodo ha più del 10% dei dati del cluster), selezionare <command>ceph.migrate.osds</command>.
      </para>
     </tip>
     <substeps>
      <step>
       <para>
        Per migrare gli OSD uno alla volta, eseguire:
       </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.osds</screen>
      </step>
      <step>
       <para>
        Per migrare tutti gli OSD nello stesso nodo in parallelo, eseguire:
       </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.nodes</screen>
      </step>
     </substeps>
     <tip>
      <para>
       Poiché l'orchestrazione non fornisce alcun feedback sull'avanzamento della migrazione, utilizzare
      </para>
<screen><prompt>root # </prompt>ceph osd tree</screen>
      <para>
       per vedere quali OSD hanno un peso pari a zero periodicamente.
      </para>
     </tip>
    </step>
   </procedure>
   <para>
    Dopo la migrazione a BlueStore, il numero di oggetti rimane lo stesso e l'utilizzo del disco quasi uguale.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5cephdeloy">
  <title>Eseguire l'upgrade da SUSE Enterprise Storage 4 (<command>ceph-deploy</command> Deployment) a 5</title>

  <important>
   <title>requisiti del software</title>
   <para>
    Prima di iniziare la procedura di upgrade, è necessario che il software seguente sia installato e aggiornato alle versioni del package più recenti su tutti i nodi Ceph per cui si desidera eseguire l'upgrade:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Scegliere il Salt master per il cluster. Se nel cluster è distribuito Calamari, il nodo Calamari <emphasis>è</emphasis> già il Salt master. In alternativa, il nodo admin da cui è stato eseguito il comando <command>ceph-deploy</command> diventa il Salt master.
   </para>
   <para>
    Prima di avviare la procedura seguente, occorre eseguire l'upgrade del nodo Salt master a SUSE Linux Enterprise Server 12 SP3 e SUSE Enterprise Storage 5 eseguendo <command>zypper migration</command> (o il modo di upgrade preferito).
   </para>
  </important>

  <para>
   Per eseguire l'upgrade al cluster SUSE Enterprise Storage 4 distribuito con <command>ceph-deploy</command> alla versione 5, attenersi a questa procedura:
  </para>

  <procedure xml:id="upgrade4to5cephdeploy-all">
   <title>Procedura da applicare a tutti i noi del cluster (compreso il nodo Calamari)</title>
   <step>
    <para>
     Installare il pacchetto <systemitem>salt</systemitem> da SLE-12-SP2/SES4:
    </para>
<screen><prompt>root # </prompt>zypper install salt</screen>
   </step>
   <step>
    <para>
     Installare il pacchetto <systemitem>salt-minion</systemitem> da SLE-12-SP2/SES4, quindi attivare e avviare il servizio correlato:
    </para>
<screen><prompt>root # </prompt>zypper install salt-minion
<prompt>root # </prompt>systemctl enable salt-minion
<prompt>root # </prompt>systemctl start salt-minion</screen>
   </step>
   <step>
    <para>
     Accertare che il nome host "salt" si risolva nell'indirizzo IP del nodo Salt master. Se il Salt master non è raggiungibile dal nome host <literal>salt</literal>, modificare il file <filename>/etc/salt/minion</filename> oppure creare un nuovo file <filename>/etc/salt/minion.d/master.conf</filename> con il seguente contenuto:
    </para>
<screen>master: <replaceable>host_name_of_salt_master</replaceable></screen>
    <tip>
     <para>
      Nei Salt minion esistenti l'opzione <option>master:</option> è già impostata in <filename>/etc/salt/minion.d/calamari.conf</filename>. Il nome del file di configurazione è ininfluente, la directory <filename>/etc/salt/minion.d/</filename> è importante.
     </para>
    </tip>
    <para>
     Se sono state apportate modifiche ai file di configurazione menzionati sopra, riavviare il servizio Salt su tutti i Salt minion:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Se i sistemi sono stati registrati con SUSEConnect e si utilizza SCC/SMT, non sono richieste ulteriori azioni. 
      </para>
     </step>
     <step>
      <para>
       Se <emphasis role="bold">non</emphasis> si utilizza SCC/SMT ma un Media-ISO o altra sorgente del pacchetto, aggiungere i seguenti repository manualmente: SLE12-SP3 Base, SLE12-SP3 Update, SES5 Base e SES5 Update. Per questo scopo, è possibile utilizzare il comando <command>zypper</command>. Rimuovere prima tutti i repository software esistenti, quindi aggiungere quelli nuovi richiesti e infine aggiornare le sorgenti dei repository:
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
     </step>
    </substeps>
   </step>
  </procedure>

  <procedure xml:id="upgrade4to5cephdeploy-admin">
   <title>Procedura da applicare al nodo Salt master</title>
   <step>
    <para>
     Impostare il nuovo ordinamento degli oggetti interni, eseguire:
    </para>
<screen><prompt>root@master # </prompt>ceph osd set sortbitwise</screen>
    <tip>
     <para>
      Per verificare che il comando sia stato eseguito, si consiglia di eseguire
     </para>
<screen><prompt>root@master # </prompt>ceph osd dump --format json-pretty | grep sortbitwise
 "flags": "sortbitwise,recovery_deletes,purged_snapdirs",</screen>
    </tip>
   </step>
   <step>
    <para>
     Eseguire l'upgrade del nodo Salt master a SUSE Linux Enterprise Server 12 SP3 e SUSE Enterprise Storage 5. Per i sistemi con registrazione SCC, utilizzare <command>zypper migration</command>. Se i repository software richiesti sono forniti manualmente, utilizzare <command>zypper dup</command>. Dopo l'upgrade, verificare che solo i repository per SUSE Linux Enterprise Server 12 SP3 e SUSE Enterprise Storage 5 siano attivi (e aggiornati) sul nodo Salt master prima di continuare.
    </para>
   </step>
   <step>
    <para>
     Se non è già presente, installare il pacchetto <systemitem>salt-package</systemitem>, quindi attivare e avviare il servizio correlato:
    </para>
<screen><prompt>root@master # </prompt>zypper install salt-master
<prompt>root@master # </prompt>systemctl enable salt-master
<prompt>root@master # </prompt>systemctl start salt-master</screen>
   </step>
   <step>
    <para>
     Verificare la presenza di tutti i Salt minion elencandone le chiavi:
    </para>
<screen><prompt>root@master # </prompt>salt-key -L</screen>
   </step>
   <step>
    <para>
     Aggiungere tutte le chiavi dei Salt minion al Salt master compreso il minion master:
    </para>
<screen><prompt>root@master # </prompt>salt-key -A -y</screen>
   </step>
   <step>
    <para>
     Verificare che tutte le chiavi dei Salt minion siano state accettate:
    </para>
<screen><prompt>root@master # </prompt>salt-key -L</screen>
   </step>
   <step>
    <para>
     Verificare che il software sul nodo Salt master sia aggiornato:
    </para>
<screen><prompt>root@master # </prompt>zypper migration</screen>
   </step>
   <step>
    <para>
     Installare il pacchetto <systemitem>deepsea</systemitem>:
    </para>
<screen><prompt>root@master # </prompt>zypper install deepsea</screen>
   </step>
   <step>
    <para>
     Includere i Salt minion del cluster. Per ulteriori dettagli, fare riferimento a <xref linkend="ds-minion-targeting"/> di <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Importare il cluster installato <command>ceph-deploy</command> esistente:
    </para>
<screen><prompt>root@master # </prompt>salt-run populate.engulf_existing_cluster</screen>
    <para>
     Il comando esegue quanto indicato di seguito:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Distribuzione di tutti i moduli Salt e DeepSea richiesti a tutti i Salt minion.
      </para>
     </listitem>
     <listitem>
      <para>
       Esaminare il cluster Ceph in esecuzione e inserire <filename>/srv/pillar/ceph/proposals</filename> in un layout del cluster.
      </para>
      <para>
       Viene creato <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> con ruoli corrispondenti a tutti i servizi Ceph in esecuzione rilevati. Visualizzare questo file per verificare che ogni nodo MON, OSD, RGW e MDS esistente abbia i ruoli appropriati. I nodi OSD verranno importati nella sottodirectory <filename>profile-import/</filename>, quindi è possibile esaminare i file in <filename>/srv/pillar/ceph/proposals/profile-import/cluster/</filename> e <filename>/srv/pillar/ceph/proposals/profile-import/stack/default/ceph/minions/</filename> per confermare che gli OSD siano stati prelevati correttamente.
      </para>
      <note>
       <para>
        Il file <filename>policy.cfg</filename> generato applica solo i ruoli per i servizi Ceph rilevati "role-mon", "role-mgr", "role-mds", "role-rgw", "role-admin" e "role-master" per il nodo Salt master. Altri eventuali ruoli desiderati devono essere aggiunti al file manualmente (vedere <xref linkend="policy-role-assignment"/>).
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       <filename>ceph.conf</filename> del cluster esistente viene salvato in <filename>/srv/salt/ceph/configuration/files/ceph.conf.import</filename>.
      </para>
     </listitem>
     <listitem>
      <para>
       <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename> comprende il fsid del cluster, reti pubbliche e cluster e inoltre specifica l'opzione <option>configuration_init: default-import</option> che consente a DeepSea di utilizzare il file di configurazione <filename>ceph.conf.import</filename> citato in precedenza, invece di utilizzare il modello predefinito di DeepSea <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>.
      </para>
      <note>
       <title><filename>ceph.conf</filename> personalizzato</title>
       <para>
        Se occorre integrare il file <filename>ceph.conf</filename> con modifiche personalizzate, attendere il corretto completamento del processo di importazione/upgrade. Modificare quindi il file <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename> e commentare la riga seguente:
       </para>
<screen>
configuration_init: default-import
</screen>
       <para>
        Salvare il file e seguire le informazioni in <xref linkend="ds-custom-cephconf"/>.
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       I diversi portachiavi del cluster vengono salvati nelle seguenti directory:
      </para>
<screen>/srv/salt/ceph/admin/cache/
/srv/salt/ceph/mon/cache/
/srv/salt/ceph/osd/cache/
/srv/salt/ceph/mds/cache/
/srv/salt/ceph/rgw/cache/</screen>
      <para>
       Verificare che siano presenti i file portachiavi e che <emphasis>non</emphasis> via sia alcun file portachiavi nella seguente directory (il Ceph Manager non esisteva prima di SUSE Enterprise Storage 5):
      </para>
<screen>
/srv/salt/ceph/mgr/cache/
</screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Il comando <command>salt-run populate.engulf_existing_cluster</command> non gestisce l'importazione della configurazione openATTIC. È necessario modificare manualmente il file <filename>policy.cfg</filename> e aggiungere una riga <literal>role-openattic</literal>. Per ulteriori dettagli, fare riferimento a <xref linkend="policy-configuration"/>.
    </para>
   </step>

   <step>
    <para>
     Il comando <command>salt-run populate.engulf_existing_cluster</command> non gestisce l'importazione delle configurazioni dei Gateway iSCSI. Se il cluster comprende iSCSI Gateway, importarne manualmente le configurazioni:
    </para>
    <substeps>
     <step>
      <para>
       Su uno dei nodi iSCSI Gateway, esportare il <filename>lrbd.conf</filename> corrente e copiarlo nel nodo Salt master:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o &gt;/tmp/lrbd.conf
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf admin:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
     </step>
     <step>
      <para>
       Sul nodo Salt master, aggiungere la configurazione iSCSI Gateway predefinita alla configurazione di DeepSea:
      </para>
<screen>
<prompt>root@master # </prompt>mkdir -p /srv/pillar/ceph/stack/ceph/
<prompt>root@master # </prompt>echo 'igw_config: default-ui' &gt;&gt; /srv/pillar/ceph/stack/ceph/cluster.yml
<prompt>root@master # </prompt>chown salt:salt /srv/pillar/ceph/stack/ceph/cluster.yml
</screen>
     </step>
     <step>
      <para>
       Aggiungere i ruoli iSCSI Gateway a <filename>policy.cfg</filename> e salvare il file:
      </para>
<screen>
role-igw/stack/default/ceph/minions/ses-1.ses.suse.yml
role-igw/cluster/ses-1.ses.suse.sls
[...]
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Eseguire la Fase 1 per creare tutti i ruoli possibili:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Generare le sottodirectory richieste in <filename>/srv/pillar/ceph/stack</filename>:
    </para>
<screen><prompt>root@master # </prompt>salt-run push.proposal</screen>
   </step>
   <step>
    <para>
     Verificare che sia presente un cluster operativo gestito da DeepSea con i ruoli assegnati correttamente:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.get roles</screen>
    <para>
     Confrontare il risultato con il layout effettivo del cluster.
    </para>
   </step>
   <step>
    <para>
     Calamari lascia un lavoro Salt pianificato in esecuzione per controllare lo stato del cluster. Rimuovere il lavoro:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>salt <replaceable>target</replaceable> schedule.delete ceph.heartbeat
</screen>
   </step>
   <step>
    <para>
     Da questo punto in avanti, seguire la procedura descritta in <xref linkend="ceph-upgrade-4to5"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5crowbar">
  <title>Eseguire l'upgrade da SUSE Enterprise Storage 4 (Crowbar Deployment) a 5</title>

  <important>
   <title>requisiti del software</title>
   <para>
    Prima di iniziare la procedura di upgrade, è necessario che il software seguente sia installato e aggiornato alle versioni del package più recenti su tutti i nodi Ceph per cui si desidera eseguire l'upgrade:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
  </important>

  <para>
   Per eseguire l'upgrade di SUSE Enterprise Storage 4 distribuito mediante Crowbar alla versione 5, attenersi a questa procedura:
  </para>

  <procedure>
   <step>
    <para>
     Per ciascun nodo Ceph (compreso il nodo Calamari), arrestare e disabilitare tutti i servizi relativi a Crowbar:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>sudo systemctl stop chef-client
<prompt>root@minion &gt; </prompt>sudo systemctl disable chef-client
<prompt>root@minion &gt; </prompt>sudo systemctl disable crowbar_join
<prompt>root@minion &gt; </prompt>sudo systemctl disable crowbar_notify_shutdown
</screen>
   </step>
   <step>
    <para>
     Per ciascun nodo Ceph (compreso il nodo Calamari), verificare che i repository software puntino ai prodotti SUSE Enterprise Storage 5 e SUSE Linux Enterprise Server 12 SP3. Se sono ancora presenti repository che puntano a versioni dei prodotti precedenti, disabilitarli.
    </para>
   </step>
   <step>
    <para>
     Per ciascun nodo Ceph (compreso il nodo Calamari), verificare che 
     <package>salt-minion</package> sia installato. In caso contrario, installarlo:
    </para>
<screen><prompt>root@minion &gt; </prompt>sudo zypper in salt salt-minion</screen>
   </step>
   <step>
    <para>
     Per i nodi Ceph che non hanno il pacchetto <package>salt-minion</package>
     installato, creare il file <filename>/etc/salt/minion.d/master.conf</filename> con l'opzione <option>master</option> che punta al nome host del nodo Calamari completo:
    </para>
<screen>master: <replaceable>full_calamari_hostname</replaceable></screen>
    <tip>
     <para>
      Nei Salt minion esistenti l'opzione <option>master:</option> è già impostata in <filename>/etc/salt/minion.d/calamari.conf</filename>. Il nome del file di configurazione è ininfluente, è importante la directory <filename>/etc/salt/minion.d/</filename>.
     </para>
    </tip>
    <para>
     Abilitare e avviare il servizio <systemitem class="daemon">salt-minion</systemitem>:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>sudo systemctl enable salt-minion
<prompt>root@minion &gt; </prompt>sudo systemctl start salt-minion
</screen>
   </step>
   <step>
    <para>
     Nel nodo Calamari, accettare eventuali chiavi salt minion rimanenti:
    </para>
<screen>
<prompt>root@master # </prompt>salt-key -L
[...]
Unaccepted Keys:
d52-54-00-16-45-0a.example.com
d52-54-00-70-ac-30.example.com
[...]

<prompt>root@master # </prompt>salt-key -A
The following keys are going to be accepted:
Unaccepted Keys:
d52-54-00-16-45-0a.example.com
d52-54-00-70-ac-30.example.com
Proceed? [n/Y] y
Key for minion d52-54-00-16-45-0a.example.com accepted.
Key for minion d52-54-00-70-ac-30.example.com accepted.
</screen>
   </step>
   <step>
    <para>
     Se Ceph è stato installato sulla rete pubblica ma non è presente alcuna interfaccia VLAN, aggiungere al nodo Calamari un'interfaccia (VLAN) sulla rete pubblica di Crowbar.
    </para>
   </step>
   <step>
    <para>
     Eseguire l'upgrade del nodo Calamari a SUSE Linux Enterprise Server 12 SP3 e SUSE Enterprise Storage 5, utilizzando <command>zypper migration</command> o il metodo prescelto. Da questo punto in avanti, il nodo Calamari diventa il <emphasis>Salt master</emphasis>. Dopo l'upgrade, riavviare il Salt master.
    </para>
   </step>
   <step>
    <para>
     Installare DeepSea sul Salt master:
    </para>
<screen><prompt>root@master # </prompt>zypper in deepsea</screen>
   </step>
   <step>
    <para>
     Specificare l'opzione <option>deepsea_minions</option> per includere il gruppo corretto di Salt minion nelle fasi di distribuzione. Per ulteriori dettagli, fare riferimento a <xref linkend="ds-minion-targeting-dsminions"/>.
    </para>
   </step>
   <step>
    <para>
     DeepSea si aspetta che tutti i nodi Ceph abbiano un identico <filename>/etc/ceph/ceph.conf</filename>. Crowbar distribuisce un <filename>ceph.conf</filename> leggermente diverso su ciascun nodo, quindi occorre consolidarli:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Rimuovere l'opzione <option>osd crush location hook</option> inclusa da Calamari.
      </para>
     </listitem>
     <listitem>
      <para>
       Rimuovere l'opzione <option>public addr</option> dalla sezione <literal>[mon]</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       Rimuovere i numeri di porta dall'opzione <option>mon host</option>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Se si stava eseguendo l'Object Gateway, Crowbar ha distribuito un file <filename>/etc/ceph/ceph.conf.radosgw</filename> separato per mantenere i segreti keystone separati dal file <filename>ceph.conf</filename> standard. Crowbar aggiunge anche un file <filename>/etc/systemd/system/ceph-radosgw@.service</filename> personalizzato. Poiché DeepSea non lo supporta, occorre rimuoverlo:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Aggiungere tutte le sezioni <literal>[client.rgw....]</literal> dal file <filename>ceph.conf.radosgw</filename> a <filename>/etc/ceph/ceph.conf</filename> su tutti i nodi.
      </para>
     </listitem>
     <listitem>
      <para>
       Sul nodo Object Gateway, eseguire:
      </para>
<screen><prompt>root@minion &gt; </prompt>rm /etc/systemd/system/ceph-radosgw@.service
systemctl reenable ceph-radosgw@rgw.public.$<replaceable>hostname</replaceable></screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Verificare che <command>ceph status</command> funzioni quando eseguito dal Salt master:
    </para>
<screen><prompt>root@master # </prompt>ceph status
cluster a705580c-a7ae-4fae-815c-5cb9c1ded6c2
health HEALTH_OK
[...]
</screen>
   </step>
   <step>
    <para>
     Importare il cluster esistente:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run populate.engulf_existing_cluster
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run push.proposal
</screen>
   </step>

   <step>
    <para>
     Il comando <command>salt-run populate.engulf_existing_cluster</command> non gestisce l'importazione delle configurazioni dei Gateway iSCSI. Se il cluster comprende iSCSI Gateway, importarne manualmente le configurazioni:
    </para>
    <substeps>
     <step>
      <para>
       Su uno dei nodi iSCSI Gateway, esportare il <filename>lrbd.conf</filename> corrente e copiarlo nel nodo Salt master:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o &gt; /tmp/lrbd.conf
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf admin:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
     </step>
     <step>
      <para>
       Sul nodo Salt master, aggiungere la configurazione iSCSI Gateway predefinita alla configurazione di DeepSea:
      </para>
<screen>
<prompt>root@master # </prompt>mkdir -p /srv/pillar/ceph/stack/ceph/
<prompt>root@master # </prompt>echo 'igw_config: default-ui' &gt;&gt; /srv/pillar/ceph/stack/ceph/cluster.yml
<prompt>root@master # </prompt>chown salt:salt /srv/pillar/ceph/stack/ceph/cluster.yml
</screen>
     </step>
     <step>
      <para>
       Aggiungere i ruoli iSCSI Gateway a <filename>policy.cfg</filename> e salvare il file:
      </para>
<screen>
role-igw/stack/default/ceph/minions/ses-1.ses.suse.yml
role-igw/cluster/ses-1.ses.suse.sls
[...]
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Se i sistemi sono stati registrati con SUSEConnect e si utilizza SCC/SMT, non sono richieste ulteriori azioni. 
      </para>
     </step>
     <step>
      <para>
       Se <emphasis role="bold">non</emphasis> si utilizza SCC/SMT ma un Media-ISO o altra sorgente del pacchetto, aggiungere i seguenti repository manualmente: SLE12-SP3 Base, SLE12-SP3 Update, SES5 Base e SES5 Update. Per questo scopo, è possibile utilizzare il comando <command>zypper</command>. Rimuovere prima tutti i repository software esistenti, quindi aggiungere quelli nuovi richiesti e infine aggiornare le sorgenti dei repository:
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
      <para>
       Cambiare quindi i dati di Pillar per utilizzare una diversa strategia. Modificare
      </para>
<screen>/srv/pillar/ceph/stack/<replaceable>name_of_cluster</replaceable>/cluster.yml</screen>
      <para>
       e aggiungere la riga seguente:
      </para>
<screen>upgrade_init: zypper-dup</screen>
      <tip>
       <para>
        La strategia <literal>zypper-dup</literal> richiede di aggiungere manualmente i repository software più recenti, mentre <literal>zypper-migration</literal> di default si basa sui repository forniti da SCC/SMT.
       </para>
      </tip>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Modificare i "grain" (piccoli elementi di dati) host affinché DeepSea utilizzi nomi host brevi sulla rete pubblica per gli ID istanza del daemon Ceph. Per ciascun nodo, occorre eseguire <command>grains.set</command> con il nuovo nome (breve) host. Prima di eseguire <command>grains.set</command>, verificare le istanze del monitor corrente eseguendo <command>ceph status</command>. Viene fornito un esempio per "prima" e "dopo":
    </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.get host
d52-54-00-16-45-0a.example.com:
    d52-54-00-16-45-0a
d52-54-00-49-17-2a.example.com:
    d52-54-00-49-17-2a
d52-54-00-76-21-bc.example.com:
    d52-54-00-76-21-bc
d52-54-00-70-ac-30.example.com:
    d52-54-00-70-ac-30
</screen>
<screen>
<prompt>root@master # </prompt>salt d52-54-00-16-45-0a.example.com grains.set \
 host public.d52-54-00-16-45-0a
<prompt>root@master # </prompt>salt d52-54-00-49-17-2a.example.com grains.set \
 host public.d52-54-00-49-17-2a
<prompt>root@master # </prompt>salt d52-54-00-76-21-bc.example.com grains.set \
 host public.d52-54-00-76-21-bc
<prompt>root@master # </prompt>salt d52-54-00-70-ac-30.example.com grains.set \
 host public.d52-54-00-70-ac-30
</screen>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.get host
d52-54-00-76-21-bc.example.com:
    public.d52-54-00-76-21-bc
d52-54-00-16-45-0a.example.com:
    public.d52-54-00-16-45-0a
d52-54-00-49-17-2a.example.com:
    public.d52-54-00-49-17-2a
d52-54-00-70-ac-30.example.com:
    public.d52-54-00-70-ac-30
</screen>
   </step>
   <step>
    <para>
     Eseguire l'upgrade:
    </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> state.apply ceph.updates
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> test.version
<prompt>root@master # </prompt>salt-run state.orch ceph.maintenance.upgrade
</screen>
    <para>
     Ogni nodo si riavvia. Il cluster si riattiva rilevando l'assenza dell'istanza attiva di Ceph Manager. Questa situazione è normale. A questo punto, Calamari non deve essere più installato/in esecuzione.
    </para>
   </step>
   <step>
    <para>
     Eseguire tutte le fasi di distribuzione richieste per portare il cluster a uno stato funzionale:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
   </step>
   <step>
    <para>
     Per distribuire openATTIC (vedere <xref linkend="ceph-oa"/>), aggiungere una riga <literal>role-openattic</literal> (vedere <xref linkend="policy-role-assignment"/>) appropriata a <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>, quindi eseguire:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
   </step>
   <step>
    <para>
     Durante l'upgrade, è possibile ricevere errori come/del tipo "Error EINVAL: entity [...] exists but caps do not match". Per risolverli, consultare <xref linkend="ceph-upgrade-4to5"/>.
    </para>
   </step>
   <step>
    <para>
     Eseguire la pulizia rimanente:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Crowbar crea voci in <filename>/etc/fstab</filename> per ogni OSD. Poiché non sono necessarie, cancellarle.
      </para>
     </listitem>
     <listitem>
      <para>
       Calamari lascia un lavoro Salt pianificato in esecuzione per controllare lo stato del cluster. Rimuovere il lavoro:
      </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> schedule.delete ceph.heartbeat
</screen>
     </listitem>
     <listitem>
      <para>
       Sono ancora presenti alcuni pacchetti installati non necessari, soprattutto correlati a ruby gems e chef. La loro rimozione non è richiesta, ma è possibile eliminarli eseguendo <command>zypper rm <replaceable>pkg_name</replaceable></command>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-3to5">
  <title>Eseguire l'upgrade da SUSE Enterprise Storage 3 a 5</title>

  <important>
   <title>requisiti del software</title>
   <para>
    Prima di iniziare la procedura di upgrade, è necessario che il software seguente sia installato e aggiornato alle versioni del package più recenti su tutti i nodi Ceph per cui si desidera eseguire l'upgrade:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP1
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 3
     </para>
    </listitem>
   </itemizedlist>
  </important>

  <para>
   Per eseguire l'upgrade del cluster SUSE Enterprise Storage 3 alla versione 5, seguire la procedura descritta in <xref linkend="upgrade4to5cephdeploy-all"/> quindi <xref linkend="upgrade4to5cephdeploy-admin"/>.
  </para>
 </sect1>
</chapter>
