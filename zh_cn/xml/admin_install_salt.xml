<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_install_salt.xml" version="5.0" xml:id="ceph-install-saltstack">
 <title>使用 DeepSea/Salt 部署</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>yes</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <note>
  <title>SUSE Enterprise Storage 5 中已删除 <command>ceph-deploy</command></title>
  <para>
   SUSE Enterprise Storage 4 中已弃用 <command>ceph-deploy</command> 集群部署工具。从 SUSE Enterprise Storage 5 开始，随着 DeepSea 的推出，此工具已完全删除。
  </para>
 </note>
 <para>
  Salt 连同 DeepSea 是一个组件<emphasis>堆栈</emphasis>，可帮助您部署和管理服务器基础架构。Salt 具有很高的可缩放性，速度快，且相对容易运行。在开始使用 Salt 部署集群之前，请阅读以下注意事项：
 </para>
 <itemizedlist>
  <listitem>
   <para>
    <emphasis>Salt Minion</emphasis> 是由一个称为 Salt Master 的专用节点控制的节点。Salt Minion 具有角色，例如 Ceph OSD、Ceph Monitor、Ceph Manager、对象网关、iSCSI 网关或 NFS Ganesha。
   </para>
  </listitem>
  <listitem>
   <para>
    Salt Master 运行自己的 Salt Minion。运行特权任务（例如，创建、授权密钥以及将密钥复制到 Minion）需要 Salt Master，这样，远程 Minion 就永远不需要运行特权任务。
   </para>
   <tip>
    <title>每台服务器共享多个角色</title>
    <para>
     如果将每个角色都部署在一个独立节点上，则 Ceph 集群的性能是最佳的。但实际部署有时会要求多个角色共享一个节点。为避免性能欠佳以及升级过程出现问题，请勿向 Salt Master 部署 Ceph OSD、元数据服务器或 Ceph Monitor 角色。
    </para>
   </tip>
  </listitem>
  <listitem>
   <para>
    Salt Minion 需要能通过网络正确解析 Salt Master 的主机名。默认情况下，Minion 会查找 <systemitem>salt</systemitem> 主机名，但您可以在 <filename>/etc/salt/minion</filename> 文件中指定可通过网络访问的其他任何主机名，具体请参见<xref linkend="ceph-install-stack"/>。
   </para>
  </listitem>
 </itemizedlist>
 <sect1 xml:id="cha-ceph-install-relnotes">
  <title>阅读发行说明</title>

  <para>
   在发行说明中，可以找到有关自 SUSE Enterprise Storage 的上一个版本发行后所进行的更改的其他信息。检查发行说明以了解：
  </para>

  <itemizedlist>
   <listitem>
    <para>
     您的硬件是否有特殊的注意事项。
    </para>
   </listitem>
   <listitem>
    <para>
     所用的任何软件包是否已发生重大更改。
    </para>
   </listitem>
   <listitem>
    <para>
     是否需要对您的安装实施特殊预防措施。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   发行说明还提供未能及时编入手册中的信息。它们还包含有关已知问题的说明。
  </para>

  <para>
   安装包 <package>release-notes-ses</package>之后，可在本地的 <filename>/usr/share/doc/release-notes</filename> 目录中或 <link xlink:href="https://www.suse.com/releasenotes/"/> 网页上找到发行说明。
  </para>
 </sect1>
 <sect1 xml:id="deepsea-description">
  <title>DeepSea 简介</title>

  <para>
   DeepSea 旨在节省管理员的时间，让他们自信地对 Ceph 集群执行复杂操作。
  </para>

  <para>
   Ceph 是一款高度可配置的软件解决方案。它提高了系统管理员的自由度和职责履行能力。
  </para>

  <para>
   最低的 Ceph 设置能够很好地满足演示目的，但无法展示 Ceph 在处理大量节点时可体现的卓越功能。
  </para>

  <para>
   DeepSea 会收集并存储有关单台服务器的相关数据，例如地址和设备名称。对于诸如 Ceph 的分布式存储系统，可能需要收集并存储数百个这样的项目。收集信息并手动将数据输入到配置管理工具的过程非常耗费精力，并且容易出错。
  </para>

  <para>
   准备服务器、收集配置信息以及配置和部署 Ceph 所需执行的步骤大致相同。但是，这种做法无法解决管理独立功能的需求。在日常操作中，必须做到不厌其烦地将硬件添加到给定的功能，以及适当地删除硬件。
  </para>

  <para>
   DeepSea 通过以下策略解决了这些需求：DeepSea 可将管理员的多项决策合并到单个文件中。这些决策包括集群指定、角色指定和配置指定。此外，DeepSea 还会收集各组任务以组成一个简单的目标。每个目标就是一个<emphasis>阶段</emphasis>：
  </para>

  <itemizedlist xml:id="deepsea-stage-description">
   <title>DeepSea 阶段说明</title>
   <listitem>
    <para>
     <emphasis role="bold">阶段 0</emphasis> — <emphasis role="bold">准备</emphasis>：在此阶段，将应用全部所需的更新，并且可能会重引导您的系统。
    </para>
    <important>
     <title>重引导 Salt Master 后重新运行阶段 0</title>
     <para>
      如果在执行阶段 0 期间，Salt Master 重引导以加载新内核版本，则您需要再次运行阶段 0，否则将无法定位 Minion。
     </para>
    </important>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">阶段 1</emphasis> — <emphasis role="bold">发现</emphasis>：在此阶段，将检测集群中的所有硬件，并收集 Ceph 配置所需的信息。有关配置的详细信息，请参见<xref linkend="deepsea-pillar-salt-configuration"/>。
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">阶段 2</emphasis> — <emphasis role="bold">配置</emphasis>：您需要以特定的格式准备配置数据。
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">阶段 3</emphasis> — <emphasis role="bold">部署</emphasis>：创建包含必要 Ceph 服务的基本 Ceph 集群。有关必要服务的列表，请参见<xref linkend="storage-intro-core-nodes"/>。
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">阶段 4</emphasis> — <emphasis role="bold">服务</emphasis>：可在此阶段安装 Ceph 的其他功能，例如 iSCSI、对象网关和 CephFS。其中每个功能都是可选的。
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">阶段 5</emphasis> — 删除阶段：此阶段不是必需的，在初始设置期间，通常不需要此阶段。在此阶段，将会删除 Minion 的角色以及集群配置。如果您需要从集群中删除某个存储节点，则需要运行此阶段。有关详细信息，请参见<xref linkend="salt-node-removing"/>。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   有关 DeepSea 的更详细介绍，请访问 <link xlink:href="https://github.com/suse/deepsea/wiki"/>。
  </para>

  <sect2 xml:id="deepsea-organisation-locations">
   <title>组织和重要位置</title>
   <para>
    Salt 在 Master 节点上使用多个标准位置和多个命名约定：
   </para>
   <variablelist>
    <varlistentry>
     <term><filename>/srv/pillar</filename>
     </term>
     <listitem>
      <para>
       该目录存储集群 Minion 的配置数据。<emphasis>Pillar</emphasis> 是向所有集群 Minion 提供全局配置值的接口。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/srv/salt/</filename>
     </term>
     <listitem>
      <para>
       该目录存储 Salt 状态文件（也称为 <emphasis>sls</emphasis> 文件）。状态文件是集群应该所处的状态的带格式说明。有关详细信息，请参见 <link xlink:href="https://docs.saltstack.com/en/latest/topics/tutorials/starting_states.html">Salt 文档</link>。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/srv/module/runners</filename>
     </term>
     <listitem>
      <para>
       该目录存储称作运行程序的 Python 脚本。运行程序在 Master 节点上执行。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/srv/salt/_modules</filename>
     </term>
     <listitem>
      <para>
       该目录存储称作模块的 Python 脚本。这些模块将应用到集群中的所有 Minion。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/srv/pillar/ceph</filename>
     </term>
     <listitem>
      <para>
       该目录由 DeepSea 使用。收集的配置数据存储在此处。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/srv/salt/ceph</filename>
     </term>
     <listitem>
      <para>
       DeepSea 使用的目录。其中存储了可采用不同格式的 sls 文件，但 sls 文件包含在各子目录中。每个子目录仅包含一种类型的 sls 文件。例如，<filename>/srv/salt/ceph/stage</filename> 包含 <command>salt-run state.orchestrate</command> 执行的编制文件。
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ds-minion-targeting">
   <title>定位 Minion</title>
   <para>
    DeepSea 命令通过 Salt 基础架构执行。使用 <command>salt</command> 命令时，您需要指定一组将受到该命令影响的 Salt Minion。我们将该组 Minion 描述为 <command>salt</command> 命令的<emphasis>目标</emphasis>。以下各节说明定位 Minion 的可行方法。
   </para>
   <sect3 xml:id="ds-minion-targeting-name">
    <title>匹配 Minion 名称</title>
    <para>
     您可以通过名称匹配来定位一个或一组 Minion。Minion 的名称通常为运行该 Minion 的节点的短主机名。这是一种常规的 Salt 定位方法，与 DeepSea 无关。您可以使用通配、正则表达式或列表来限制 Minion 名称的范围。遵循的一般语法如下：
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> example.module</screen>
    <tip>
     <title>仅 Ceph 集群</title>
     <para>
      如果您环境中的所有 Salt Minion 均属于 Ceph 集群，则可以安全地使用 <literal>'*'</literal> 替换 <replaceable>target</replaceable>，以包含<emphasis>所有</emphasis>注册 Minion。
     </para>
    </tip>
    <para>
     匹配 example.net 域中的所有 Minion（假设 Minion 名称与其“完整”的主机名相同）：
    </para>
<screen><prompt>root@master # </prompt>salt '*.example.net' test.ping</screen>
    <para>
     将“web1”Minion 与“web5”Minion 匹配：
    </para>
<screen><prompt>root@master # </prompt>salt 'web[1-5]' test.ping</screen>
    <para>
     使用正则表达式匹配“web1-prod”和“web1-devel”Minion：
    </para>
<screen><prompt>root@master # </prompt>salt -E 'web1-(prod|devel)' test.ping</screen>
    <para>
     匹配简单的 Minion 列表：
    </para>
<screen><prompt>root@master # </prompt>salt -L 'web1,web2,web3' test.ping</screen>
    <para>
     匹配集群中的所有 Minion：
    </para>
<screen><prompt>root@master # </prompt>salt '*' test.ping</screen>
   </sect3>
   <sect3 xml:id="ds-minion-targeting-grain">
    <title>使用“deepsea”Grain 进行定位</title>
    <para>
     在一个异构受 Salt 管理环境（部分节点上部署了 SUSE Enterprise Storage 以及其他集群解决方案）中，建议将“deepsea”Grain 应用到相关 Minion 来加以“标记”。这样您便可以在无法通过 Minion 名称匹配的环境中轻松定位 DeepSea Minion。
    </para>
    <para>
     要将“deepse”Grain 应用到一组 Minion，请运行以下命令：
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.append deepsea default</screen>
    <para>
     要从一组 Minion 删除“deepse”Grain，请运行以下命令：
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.delval deepsea destructive=True</screen>
    <para>
     将“deepsea”Grain 应用到相关 Minion 后，您可以执行以下命令来进行定位：
    </para>
<screen><prompt>root@master # </prompt>salt -G 'deepsea:*' test.ping</screen>
    <para>
     或执行以下等效命令：
    </para>
<screen><prompt>root@master # </prompt>salt -C 'G@deepsea:*' test.ping</screen>
   </sect3>
   <sect3 xml:id="ds-minion-targeting-dsminions">
    <title>设置 <option>deepsea_minions</option> 选项</title>
    <para>
     设置 <option>deepsea_minions</option> 选项的目标是 DeepSea 部署所需。在阶段执行期间，DeepSea 会使用该选项指示 Minion（有关详细信息，请参见 <xref linkend="deepsea-stage-description"/>）。
    </para>
    <para>
     要设置或更改 <option>deepsea_minions</option> 选项，请编辑 Salt Master 上的 <filename>/srv/pillar/ceph/deepsea_minions.sls</filename> 文件，添加或替换下行：
    </para>
<screen>deepsea_minions: <replaceable>target</replaceable></screen>
    <tip>
     <title><option>deepsea_minions</option> 目标</title>
     <para>
      对于 <option>deepsea_minions</option> 选项的 <replaceable>target</replaceable>，您可以使用以下任何定位方法：<xref linkend="ds-minion-targeting-name" xrefstyle="select: title"/>和<xref linkend="ds-minion-targeting-grain" xrefstyle="select: title"/>。
     </para>
     <para>
      匹配集群中的所有 Salt Minion：
     </para>
<screen>deepsea_minions: '*'</screen>
     <para>
      使用“deepsea”Grain 匹配所有 Minion：
     </para>
<screen>deepsea_minions: 'G@deepsea:*'</screen>
    </tip>
   </sect3>
   <sect3>
    <title>更多信息</title>
    <para>
     您可以使用 Salt 基础架构以更高级的方式来定位 Minion。有关所有定位技术的说明，请参见 <link xlink:href="https://docs.saltstack.com/en/latest/topics/targeting/"/>。
    </para>
    <para>
     此外，还可从“deepsea-minions”手册页了解有关 DeepSea 定位的更多详细信息 (<command>man 7 deepsea_minions</command>)。
    </para>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-install-stack">
  <title>集群部署</title>

  <para>
   集群部署过程包括多个阶段。首先，需要通过配置 Salt 来准备集群的所有节点，然后部署并配置 Ceph。
  </para>

  <tip>
   <title>在未定义 OSD 配置的情况下部署监视器节点</title>
   <para>
    如果您需要跳过定义 OSD 配置，而先部署监视器节点，可以通过设置 <option>DEV_ENV</option> 变量来实现。该设置允许您在没有 <filename>profile/</filename> 目录的情况下部署监视器，以及部署至少包含<emphasis>一个</emphasis>存储、监视器和管理器节点的集群。
   </para>
   <para>
    要设置环境变量，请将其全局启用，方法是在 <filename>/srv/pillar/ceph/stack/global.yml</filename> 文件中进行设置，或者仅针对当前的外壳会话设置：
   </para>
<screen><prompt>root@master # </prompt>export DEV_ENV=true</screen>
  </tip>

  <para>
   下面详细说明了集群准备过程。
  </para>

  <procedure>
   <step>
    <para>
     在集群的每个节点上安装并注册 SUSE Linux Enterprise Server 12 SP3 以及 SUSE Enterprise Storage 扩展。
    </para>
   </step>
   <step>
    <para>
     列出现有的软件储存库，确认是否已安装并注册正确的产品。该列表与以下输出类似：
    </para>
<screen>
 <prompt>root@minion &gt; </prompt>zypper lr -E
#  | Alias   | Name                              | Enabled | GPG Check | Refresh
---+---------+-----------------------------------+---------+-----------+--------
 4 | [...]   | SUSE-Enterprise-Storage-5-Pool    | Yes     | (r ) Yes  | No
 6 | [...]   | SUSE-Enterprise-Storage-5-Updates | Yes     | (r ) Yes  | Yes
 9 | [...]   | SLES12-SP3-Pool                   | Yes     | (r ) Yes  | No
11 | [...]   | SLES12-SP3-Updates                | Yes     | (r ) Yes  | Yes
</screen>
   </step>
   <step>
    <para>
     在每个节点上配置网络设置，包括正确的 DNS 名称解析。Salt Master 和所有 Salt Minion 需要根据各自的主机名相互解析。有关配置网络的详细信息，请参见 <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_basicnet_yast.html"/>。有关配置 DNS 服务器的详细信息，请参见 <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_dns.html"/>。
    </para>
   </step>
   <step>
    <para>
     配置、启用并启动 NTP 时间同步服务器：
    </para>
<screen><prompt>root@master # </prompt>systemctl enable ntpd.service
<prompt>root@master # </prompt>systemctl start ntpd.service</screen>
    <para>
     在 <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_netz_xntp_yast.html"/> 中可以找到有关设置 NTP 的详细信息。
    </para>
   </step>
   <step>
    <para>
     检查 AppArmor 服务是否正在运行，并在每个集群节点上禁用该服务。启动 YaST AppArmor 模块，选择<guimenu>设置</guimenu>，然后取消选择<guimenu>启用 Apparmor</guimenu> 复选框。点击<guimenu>完成</guimenu>进行确认。
    </para>
    <para>
     请注意，在启用 AppArmor 的情况下，SUSE Enterprise Storage 将<emphasis>无法</emphasis>正常工作。
    </para>
   </step>
   <step>
    <para>
     在 Salt Master 节点上安装 <literal>salt-master</literal> 和 <literal>salt-minion</literal> 包：
    </para>
<screen><prompt>root@master # </prompt>zypper in salt-master salt-minion</screen>
    <para>
     检查 <systemitem>salt-master</systemitem> 服务是否已启用并启动，并根据需要将它启用并启动：
    </para>
<screen><prompt>root@master # </prompt>systemctl enable salt-master.service
<prompt>root@master # </prompt>systemctl start salt-master.service</screen>
   </step>
   <step>
    <para>
     如果要使用防火墙，请确认 Salt Master 节点是否为所有 Salt Minion 节点打开了端口 4505 和 4506。如果这些端口处于关闭状态，可以使用 <command>yast2 firewall</command> 命令并通过允许 <guimenu>SaltStack</guimenu> 服务来打开这些端口。
    </para>
    <warning>
     <title>使用防火墙时 DeepSea 阶段失败</title>
     <para>
      当防火墙处于活动状态（甚至只是配置了防火墙）时，DeepSea 部署阶段会失败。要正确通过该阶段，需要运行以下命令关闭防火墙
     </para>
<screen>
<prompt>root@master # </prompt>systemctl stop SuSEfirewall2.service
</screen>
     <para>
      或在 <filename>/srv/pillar/ceph/stack/global.yml</filename> 中将 <option>FAIL_ON_WARNING</option> 选项设为“False”：
     </para>
<screen>
FAIL_ON_WARNING: False
</screen>
    </warning>
   </step>
   <step>
    <para>
     在所有 Minion 节点上安装 <literal>salt-minion</literal> 包。
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper in salt-minion</screen>
    <para>
     请确保所有其他节点都可将每个节点的<emphasis>完全限定的域名</emphasis>解析为公共网络 IP 地址。
    </para>
   </step>
   <step>
    <para>
     将所有 Minion（包括 Master Minion）配置为连接到 Master。如果无法通过主机名 <literal>salt</literal> 访问 Salt Master，请编辑文件 <filename>/etc/salt/minion</filename>，或创建包含以下内容的新文件 <filename>/etc/salt/minion.d/master.conf</filename>：
    </para>
<screen>master: <replaceable>host_name_of_salt_master</replaceable></screen>
    <para>
     如果对上述配置文件执行了任何更改，请在所有 Salt Minion 上重启动 Salt 服务：
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <para>
     检查所有节点上是否已启用并启动 <systemitem>salt-minion</systemitem> 服务。根据需要启用并启动该服务：
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl enable salt-minion.service
<prompt>root@minion &gt; </prompt>systemctl start salt-minion.service</screen>
   </step>
   <step>
    <para>
     校验每个 Salt Minion 的指纹，如果指纹匹配，则接受 Salt Master 上的所有 Salt 密钥。
    </para>
    <para>
     查看每个 Minion 的指纹：
    </para>
<screen><prompt>root@minion &gt; </prompt>salt-call --local key.finger
local:
3f:a3:2f:3f:b4:d3:d9:24:49:ca:6b:2c:e1:6c:3f:c3:83:37:f0:aa:87:42:e8:ff...</screen>
    <para>
     收集到所有 Salt Minion 的指纹后，将列出 Salt Master 上所有未接受 Minion 密钥的指纹：
    </para>
<screen><prompt>root@master # </prompt>salt-key -F
[...]
Unaccepted Keys:
minion1:
3f:a3:2f:3f:b4:d3:d9:24:49:ca:6b:2c:e1:6c:3f:c3:83:37:f0:aa:87:42:e8:ff...</screen>
    <para>
     如果 Minion 的指纹匹配，则接受这些密钥：
    </para>
<screen><prompt>root@master # </prompt>salt-key --accept-all</screen>
   </step>
   <step>
    <para>
     校验是否已接受密钥：
    </para>
<screen><prompt>root@master # </prompt>salt-key --list-all</screen>
   </step>
   <step xml:id="deploy-wiping-disk">
    <para>
     在部署 SUSE Enterprise Storage 之前，请确保以前的集群用作 OSD 的所有磁盘均为空且不包含分区。为确保这一点，您需要手动擦除所有磁盘。请记得将“X”替换为正确的盘符：
    </para>
    <substeps>
     <step>
      <para>
       停止使用特定磁盘的所有进程。
      </para>
     </step>
     <step>
      <para>
       确认磁盘上是否装入任何分区，并视需要进行卸载。
      </para>
     </step>
     <step>
      <para>
       如果磁盘由 LVM 管理，请停用整个 LVM 基础架构并将其删除。有关更多详细信息，请参见<link xlink:href="https://www.suse.com/documentation/sles-12/stor_admin/data/cha_lvm.html"/>。
      </para>
     </step>
     <step>
      <para>
       如果磁盘是 MD RAID 的一部分，请停用 RAID。有关更多详细信息，请参见<link xlink:href="https://www.suse.com/documentation/sles-12/stor_admin/data/part_software_raid.html"/>。
      </para>
     </step>
     <step>
      <tip>
       <title>重引导服务器</title>
       <para>
        如果您在执行以下步骤时收到诸如“分区正在使用”或“无法使用新的分区表更新内核”之类的错误讯息，请重引导服务器。
       </para>
      </tip>
      <para>
       擦除每个分区的开头部分：
      </para>
<screen>for partition in /dev/sdX[0-9]*
do
  dd if=/dev/zero of=$partition bs=4096 count=1 oflag=direct
done</screen>
     </step>
     <step>
      <para>
       擦除分区表：
      </para>
<screen>sgdisk -Z --clear -g /dev/sdX</screen>
     </step>
     <step>
      <para>
       擦除备份分区表：
      </para>
<screen>size=`blockdev --getsz /dev/sdX`
position=$((size/4096 - 33))
dd if=/dev/zero of=/dev/sdX bs=4M count=33 seek=$position oflag=direct</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     在 Salt Master 节点上安装 DeepSea：
    </para>
<screen><prompt>root@master # </prompt>zypper in deepsea</screen>
   </step>
   <step>
    <para>
     检查 Salt Master 上的文件 <filename>/srv/pillar/ceph/master_minion.sls</filename> 是否指向您的 Salt Master。如果可以通过其他主机名访问您的 Salt Master，请使用存储集群适用的主机名。如果在 <emphasis>ses</emphasis> 域中使用了 Salt Master 的默认主机名 <emphasis>salt</emphasis>，则该文件如下所示：
    </para>
<screen>master_minion: salt.ses</screen>
   </step>
  </procedure>

  <para>
   现在部署并配置 Ceph。除非另有说明，否则必须执行所有步骤。
  </para>

  <note>
   <title>Salt 命令约定</title>
   <para>
    可通过两种方式运行 <command>salt-run state.orch</command>，一种方式是使用 <literal>stage.&lt;stage number&gt;</literal>，另一种方式是使用阶段的名称。这两种表示法会产生相同的效果，至于使用哪个命令，完全取决于您的偏好。
   </para>
  </note>

  <procedure xml:id="ds-depl-stages">
   <title>运行部署阶段</title>
   <step>
    <para>
     包含属于当前正在部署的 Ceph 集群的 Salt Minion。有关定位 Minion 的详细信息，请参见<xref linkend="ds-minion-targeting-name"/>。
    </para>
   </step>
   <step>
    <para>
     准备集群。有关更多详细信息，请参见<xref linkend="deepsea-stage-description"/>。
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
    <para>
     或者
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.prep</screen>
    <note>
     <title>使用 DeepSea CLI 运行或监视阶段</title>
     <para>
      使用 DeepSea CLI，可通过在监视模式下运行 DeepSea CLI，或者直接通过 DeepSea CLI 运行阶段，来实时跟踪阶段执行进度。有关详细信息，请参见<xref linkend="deepsea-cli"/>。
     </para>
    </note>
   </step>
   <step>
    <para>
     <emphasis>可选</emphasis>：为 <filename>/var/lib/ceph/</filename> 创建 Btrfs 子卷。只能在执行 DeepSea 的后续阶段之前执行此步骤。要迁移现有目录或了解更多详细信息，请参见<xref linkend="storage-tips-ceph-btrfs-subvol"/>。
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.subvolume</screen>
   </step>
   <step>
    <para>
     发现阶段会从所有 Minion 收集数据并创建配置分段，这些分段存储在 <filename>/srv/pillar/ceph/proposals</filename> 目录中。数据以 YAML 格式存储在 *.sls 或 *.yml 文件中。
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
    <para>
     或者
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.discovery</screen>
   </step>
   <step>
    <para>
     成功完成上述命令后，请在 <filename>/srv/pillar/ceph/proposals</filename> 中创建 <filename>policy.cfg</filename> 文件。有关详细信息，请参见<xref linkend="policy-configuration"/>。
    </para>
    <tip>
     <para>
      如果需要更改集群的网络设置，请编辑 <filename>/srv/pillar/ceph/stack/ceph/cluster.yml</filename>，调整以 <literal>cluster_network:</literal> 和 <literal>public_network:</literal> 开头的行。
     </para>
    </tip>
   </step>
   <step>
    <para>
     配置阶段将会分析 <filename>policy.cfg</filename> 文件，并将包含的文件合并成其最终形式。集群和角色相关的内容放置在 <filename>/srv/pillar/ceph/cluster</filename> 中，而 Ceph 特定的内容放置在 <filename>/srv/pillar/ceph/stack/default</filename> 中。
    </para>
    <para>
     运行以下命令以触发配置阶段：
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
    <para>
     或者
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.configure</screen>
    <para>
     配置步骤可能需要花几秒时间。命令完成后，您可以通过运行以下命令，查看指定 Minion（例如，名为 <literal>ceph_minion1</literal>、<literal>ceph_minion2</literal> 等的 Minion）的pillar 数据：
    </para>
<screen><prompt>root@master # </prompt>salt 'ceph_minion*' pillar.items</screen>
    <note>
     <title>重写默认值</title>
     <para>
      一旦命令完成，您便可查看默认配置并根据需要进行更改。有关详细信息，请参见<xref linkend="ceph-deploy-ds-custom"/>。
     </para>
    </note>
   </step>
   <step>
    <para>
     现在运行部署阶段。在此阶段，将会验证 pillar，并在存储节点上启动监视器和 OSD 守护进程。运行以下命令以启动该阶段：
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
    <para>
     或者
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.deploy
    </screen>
    <para>
     该命令可能需要花几分钟时间。如果该命令失败，则您需要解决问题，然后再次运行前面的阶段。该命令成功后，请运行以下命令来检查状态：
    </para>
<screen><prompt>root@master # </prompt>ceph -s</screen>
   </step>
   <step>
    <para>
     Ceph 集群部署过程的最后一个步骤是<emphasis>服务</emphasis>阶段。在此阶段，您要实例化当前支持的所有服务：iSCSI 网关、CephFS、对象网关、openATTIC 和 NFS Ganesha。此阶段将创建所需的存储池、授权密钥环和启动服务。要启动该阶段，请运行以下命令：
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
    <para>
     或者
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.services</screen>
    <para>
     根据具体的设置，该命令可能会运行几分钟时间。
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="deepsea-cli">
  <title>DeepSea CLI</title>

  <para>
   DeepSea 还提供了一个 CLI 工具，供用户监视或运行阶段，同时实时将执行进度可视化。
  </para>

  <para>
   支持使用以下两种模式来可视化阶段的执行进度：
  </para>

  <itemizedlist xml:id="deepsea-cli-modes">
   <title>DeepSea CLI 模式</title>
   <listitem>
    <para>
     <emphasis role="bold">监视模式</emphasis>：可视化另一个终端会话中发出的 <command>salt-run</command> 命令所触发 DeepSea 阶段的执行进度。
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">独立模式</emphasis>：运行 DeepSea 阶段，并在该阶段的构成步骤执行时提供相应的实时可视化效果。
    </para>
   </listitem>
  </itemizedlist>

  <important>
   <title>DeepSea CLI 命令</title>
   <para>
    只能使用 <systemitem class="username">root</systemitem> 特权在 Salt Master 节点中运行 DeepSea CLI 命令。
   </para>
  </important>

  <sect2 xml:id="deepsea-cli-monitor">
   <title>DeepSea CLI：监视模式</title>
   <para>
    进度监视器提供详细的实时可视化效果，显示在其他终端会话中使用 <command>salt-run state.orch</command> 命令执行阶段期间发生的情况。
   </para>
   <para>
    在运行任何 <command>salt-run state.orch</command> 命令之前，需要启动监视器，使其可以检测到阶段的执行已开始。
   </para>
   <para>
    如果在发出 <command>salt-run state.orch</command> 命令之后再启动监视器，将不会显示执行进度。
   </para>
   <para>
    可运行以下命令来启动监视模式：
   </para>
<screen><prompt>root@master # </prompt>deepsea monitor</screen>
   <para>
    有关 <command>deepsea monitor</command> 命令的可用命令行选项的详细信息，请查看该命令的手册页：
   </para>
<screen><prompt>root@master # </prompt>man deepsea-monitor</screen>
  </sect2>

  <sect2 xml:id="deepsea-cli-standalone">
   <title>DeepSea CLI：独立模式</title>
   <para>
    在独立模式下，可以使用 DeepSea CLI 来运行 DeepSea 阶段，并实时显示其执行进度。
   </para>
   <para>
    从 DeepSea CLI 中运行 DeepSea 阶段的命令的格式如下：
   </para>
<screen><prompt>root@master # </prompt>deepsea stage run <replaceable>stage-name</replaceable></screen>
   <para>
    其中，<replaceable>stage-name</replaceable> 对应于 Salt 编制状态文件的引用方式。例如，对应于 <emphasis role="bold">/srv/salt/ceph/stage/deploy</emphasis> 中目录的<filename>部署</filename>阶段以 <emphasis role="bold">ceph.stage.deploy</emphasis> 的形式引用。
   </para>
   <para>
    此命令可代替用于运行 DeepSea 阶段（或任何 DeepSea 编制状态文件）的基于 Salt 的命令。
   </para>
   <para>
    命令 <command>deepsea stage run ceph.stage.0</command> 与 <command>salt-run state.orch ceph.stage.0</command> 的效果相同。
   </para>
   <para>
    有关 <command>deepsea stage run</command> 命令接受的可用命令行选项的详细信息，请查看该命令的手册页：
   </para>
<screen><prompt>root@master # </prompt>man deepsea-stage run</screen>
   <para>
    下图显示了运行<emphasis role="underline">阶段 2</emphasis> 时，DeepSea CLI 的输出示例：
   </para>
   <figure>
    <title>DeepSea CLI 阶段执行进度输出</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="deepsea-cli-stage2-screenshot.png" width="70%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="deepsea-cli-stage2-screenshot.png" width="70%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
   <sect3 xml:id="deepsea-cli-run-alias">
    <title>DeepSea CLI <command>stage run</command> 别名</title>
    <para>
     针对 Salt 的高级用户，我们还支持使用别名来运行 DeepSea 阶段，采用运行阶段所用的 Salt 命令（例如 <command>salt-run state.orch <replaceable>stage-name</replaceable></command>）作为 DeepSea CLI 的命令。
    </para>
    <para>
     示例：
    </para>
<screen><prompt>root@master # </prompt>deepsea salt-run state.orch <replaceable>stage-name</replaceable></screen>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="deepsea-pillar-salt-configuration">
  <title>配置和自定义</title>

  <sect2 xml:id="policy-configuration">
   <title><filename>policy.cfg</filename> 文件</title>
   <para>
    <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> 配置文件用于确定单个集群节点的角色。例如，哪个节点充当 OSD，或哪个节点充当监视器节点。请编辑 <filename>policy.cfg</filename>，以反映所需的集群设置。段落采用任意顺序，但所包含行的内容将覆盖前面行的内容中匹配的密钥。
   </para>
   <tip>
    <title><filename>policy.cfg</filename> 的示例</title>
    <para>
     可以在 <filename>/usr/share/doc/packages/deepsea/examples/</filename> 目录中找到完整策略文件的多个示例。
    </para>
   </tip>
   <sect3 xml:id="policy-cluster-assignment">
    <title>集群指定</title>
    <para>
     在 <emphasis role="bold">cluster</emphasis> 段落选择集群的 Minion。可以选择所有 Minion，或者将 Minion 加入黑名单或白名单。下面显示了名为 <emphasis role="bold">ceph</emphasis> 的集群的示例。
    </para>
    <para>
     要包含<emphasis role="bold">所有</emphasis> Minion，请添加以下几行：
    </para>
<screen>cluster-ceph/cluster/*.sls</screen>
    <para>
     要将特定的 Minion 加入<emphasis role="bold">白名单</emphasis>，请运行以下命令：
    </para>
<screen>cluster-ceph/cluster/abc.domain.sls</screen>
    <para>
     要将一组 Minion 加入白名单，可以使用外壳通配符：
    </para>
<screen>cluster-ceph/cluster/mon*.sls</screen>
    <para>
     要将 Minion 加入<emphasis role="bold">黑名单</emphasis>，可将其设置为 <literal>unassigned</literal>：
    </para>
<screen>cluster-unassigned/cluster/client*.sls</screen>
   </sect3>
   <sect3 xml:id="policy-role-assignment">
    <title>角色指定</title>
    <para>
     本节详细介绍了如何为您的集群节点指定“角色”。在此上下文中，“角色”是指您需要在节点上运行的服务，例如 Ceph Monitor、对象网关、iSCSI 网关或 openATTIC。不会自动指定任何角色，只会部署已添加到 <command>policy.cfg</command> 中的角色。
    </para>
    <para>
     指定遵循以下模式：
    </para>
<screen>role-<replaceable>ROLE_NAME</replaceable>/<replaceable>PATH</replaceable>/<replaceable>FILES_TO_INCLUDE</replaceable></screen>
    <para>
     其中的项目具有以下含义和值：
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <replaceable>ROLE_NAME</replaceable> 为下列任何一项：“master”、“admin”、“mon”、“mgr”、“mds”、“igw”、“rgw”、“ganesha”或“openattic”。
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>PATH</replaceable> 是 .sls 或 .yml 文件的相对目录路径。对于 .sls 文件，该路径通常是 <filename>cluster</filename>；而 .yml 文件则位于 <filename>stack/default/ceph/minions</filename>。
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>FILES_TO_INCLUDE</replaceable> 是 Salt 状态文件或 YAML 配置文件。该文件通常包含 Salt Minion 主机名，例如 <filename>ses5min2.yml</filename>。可以使用外壳通配进行更具体的匹配。
      </para>
     </listitem>
    </itemizedlist>
    <para>
     每个角色的示例如下：
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <emphasis>master</emphasis> - 该节点具有所有 Ceph 集群的管理密钥环。目前仅支持一个 Ceph 集群。由于 <emphasis>master</emphasis> 角色是必需的，因此，请始终添加类似下方所示的行：
      </para>
<screen>role-master/cluster/master*.sls</screen>
     </listitem>
     <listitem>
      <para>
       <emphasis>admin</emphasis> - 该 Minion 将获得管理密钥环。可按如下方式定义角色：
      </para>
<screen>role-admin/cluster/abc*.sls</screen>
     </listitem>
     <listitem>
      <para>
       <emphasis>mon</emphasis> - 该 Minion 将向 Ceph 集群提供监视服务。此角色需要已指定 Minion 的地址。从 SUSE Enterprise Storage 5 开始，将以动态方式计算公用地址，并且 Salt Pillar 中不再需要该地址。
      </para>
<screen>role-mon/cluster/mon*.sls</screen>
      <para>
       该示例将监视角色指定给一组 Minion。
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis>mgr</emphasis> - 从整个集群收集所有状态信息的 Ceph Manager 守护进程。请将它部署在您打算在其上部署 Ceph Monitor 角色的所有 Minion 上。
      </para>
<screen>role-mgr/cluster/mgr*.sls</screen>
     </listitem>
     <listitem>
      <para>
       <emphasis>mds</emphasis> - 该 Minion 将提供元数据服务来支持 CephFS。
      </para>
<screen>role-mds/cluster/mds*.sls</screen>
     </listitem>
     <listitem>
      <para>
       <emphasis>igw</emphasis> - 该 Minion 将充当 iSCSI 网关。此角色需要所指定 Minion 的地址，因此，您还需要包含 <filename>stack</filename> 目录中的文件：
      </para>
<screen>role-igw/stack/default/ceph/minions/xyz.domain.yml
role-igw/cluster/*.sls</screen>
     </listitem>
     <listitem>
      <para>
       <emphasis>rgw</emphasis> - 该 Minion 将充当对象网关：
      </para>
<screen>role-rgw/cluster/rgw*.sls</screen>
     </listitem>
     <listitem>
      <para>
       <emphasis>openattic</emphasis> - 该 Minion 将充当 openATTIC 服务器：
      </para>
<screen>role-openattic/cluster/openattic*.sls</screen>
      <para>
       有关详细信息，请参见<xref linkend="ceph-oa"/>。
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis>ganesha</emphasis> - 该 Minion 将充当 NFS Ganesha 服务器。“ganesha”角色需要集群中的“rgw”或“mds”角色，否则，验证将于阶段 3 中失败。
      </para>
      <para>
       要成功安装 NFS Ganesha，需要进行额外的配置。如果您要使用 NFS Ganesha，请在执行阶段 2 和 4 之前阅读<xref linkend="cha-as-ganesha"/>。但是，可以稍后再安装 NFS Ganesha。
      </para>
      <para>
       在某些情况下，为 NFS Ganesha 节点定义自定义角色可能很有用。有关详细信息，请参见<xref linkend="ceph-nfsganesha-customrole"/>。
      </para>
     </listitem>
    </itemizedlist>
    <note>
     <title>集群节点的多个角色</title>
     <para>
      可将多个角色指定到一个节点。例如，可将 mds 角色指定到监视器节点：
     </para>
<screen>role-mds/cluster/mon[1,2]*.sls</screen>
    </note>
   </sect3>
   <sect3 xml:id="policy-common-configuration">
    <title>通用配置</title>
    <para>
     通用配置段落包括<emphasis>发现（阶段 1）</emphasis>期间生成的配置文件。这些配置文件存储 <literal>fsid</literal> 或 <literal>public_network</literal> 等参数。要包含所需的 Ceph 通用配置，请添加以下几行：
    </para>
<screen>config/stack/default/global.yml
config/stack/default/ceph/cluster.yml</screen>
   </sect3>
   <sect3 xml:id="policy-profile-assignment">
    <title>配置指定</title>
    <para>
     在 Ceph 中，单个存储角色并不足以描述同一硬件中可用的许多磁盘配置。DeepSea 阶段 1 将生成默认的存储配置建议。默认情况下，此建议是一个 <literal>bluestore</literal> 配置，它会尝试针对给定的硬件设置建议性能最高的配置。例如，外部日记优先于包含对象和元数据的单个磁盘。固态存储优先于旋转型磁盘。与角色类似，配置在 <filename>policy.cfg</filename> 中指定。
    </para>
    <para>
     可在 profile-default 目录树中找到默认建议。要包含这种指定，请将以下两行添加到 <filename>policy.cfg</filename>。
    </para>
<screen>profile-default/cluster/*.sls
profile-default/stack/default/ceph/minions/*.yml</screen>
    <para>
     您也可以使用建议运行程序，根据喜好创建自定义的存储配置。此运行程序提供三个方法：help、peek 和 populate。
    </para>
    <para>
     <command>salt-run proposal.help</command> 列显此运行程序接受的各个自变量的相关帮助文本。
    </para>
    <para>
     <command>salt-run proposal.peek</command> 根据传递的自变量显示生成的建议。
    </para>
    <para>
     <command>salt-run proposal.populate</command> 将建议写入 <filename>/srv/pillar/ceph/proposals</filename> 子目录。传递 <option>name=myprofile</option> 可为存储配置命名。这会生成 profile-myprofile 子目录。
    </para>
    <para>
     对于所有的其他自变量，请参见 <command>salt-run proposal.help</command> 的输出。
    </para>
   </sect3>
   <sect3 xml:id="ds-profile-osd-encrypted">
    <title>部署加密的 OSD</title>
    <para>
     从 SUSE Enterprise Storage 5 开始，默认会使用 BlueStore 而非 FileStore 来部署 OSD。虽然 BlueStore 支持加密，但默认以非加密模式部署 Ceph OSD。我们假设部署 OSD 时使用的数据和 WAL/DB 磁盘都是干净的，且没有分区。如果磁盘曾经使用，请执行<xref linkend="deploy-wiping-disk"/>中所述的过程进行擦除。
    </para>
    <para>
     要在您的新部署中使用加密的 OSD，请结合 <option>encryption=dmcrypt</option> 自变量使用 <literal>proposal.populate</literal> 运行程序：
    </para>
<screen>
<prompt>root@master # </prompt>salt-run proposal.populate encryption=dmcrypt
</screen>
   </sect3>
   <sect3 xml:id="deepsea-policy-filtering">
    <title>项目过滤</title>
    <para>
     有时，使用 *.sls 通配法无法包含给定目录中的所有文件。<filename>policy.cfg</filename> 文件分析器可识别以下过滤器：
    </para>
    <warning>
     <title>高级方法</title>
     <para>
      本节介绍供高级用户使用的过滤方法。如果使用不当，过滤可能会导致问题发生，例如，节点编号改变。
     </para>
    </warning>
    <variablelist>
     <varlistentry>
      <term>slice=[start:end]</term>
      <listitem>
       <para>
        使用 slice 过滤器可以仅包含从 <emphasis>start</emphasis> 到 <emphasis>end-1</emphasis> 的项目。请注意，给定目录中的项目将按字母数字顺序排序。下行包含 <filename>role-mon/cluster/</filename> 子目录中的第三到第五个文件：
       </para>
<screen>role-mon/cluster/*.sls slice[3:6]</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>re=regexp</term>
      <listitem>
       <para>
        使用正则表达式过滤器可以仅包含与给定表达式匹配的项目。例如：
       </para>
<screen>role-mon/cluster/mon*.sls re=.*1[135]\.subdomainX\.sls$</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="deepsea-example-policy-cfg">
    <title><filename>policy.cfg</filename> 文件示例</title>
    <para>
     下面是一个基本 <filename>policy.cfg</filename> 文件的示例：
    </para>
<screen>## Cluster Assignment
cluster-ceph/cluster/*.sls <co xml:id="co-policy-1"/>

## Roles
# ADMIN
role-master/cluster/examplesesadmin.sls <co xml:id="co-policy-2"/>
role-admin/cluster/sesclient*.sls <co xml:id="co-policy-3"/>

# MON
role-mon/cluster/ses-example-[123].sls <co xml:id="co-policy-5"/>

# MGR
role-mgr/cluster/ses-example-[123].sls <co xml:id="co-policy-mgr"/>

# MDS
role-mds/cluster/ses-example-4.sls <co xml:id="co-policy-6"/>

# IGW
role-igw/stack/default/ceph/minions/ses-example-4.yml <co xml:id="co-policy-7"/>
role-igw/cluster/ses-example-4.sls <co xml:id="co-policy-10"/>

# RGW
role-rgw/cluster/ses-example-4.sls <co xml:id="co-policy-11"/>

# openATTIC
role-openattic/cluster/openattic*.sls <co xml:id="co-policy-oa"/>

# COMMON
config/stack/default/global.yml <co xml:id="co-policy-8"/>
config/stack/default/ceph/cluster.yml <co xml:id="co-policy-13"/>

## Profiles
profile-default/cluster/*.sls <co xml:id="co-policy-9"/>
profile-default/stack/default/ceph/minions/*.yml <co xml:id="co-policy-12"/></screen>
    <calloutlist>
     <callout arearefs="co-policy-1">
      <para>
       指示在 Ceph 集群中包含所有 Minion。如果您不想在 Ceph 集群中包含某些 Minion，请使用：
      </para>
<screen>cluster-unassigned/cluster/*.sls
cluster-ceph/cluster/ses-example-*.sls</screen>
      <para>
       第一行将所有 Minion 标记为未指定。第二行覆盖与“ses-example-*.sls”匹配的 Minion，并将其指定到 Ceph 集群。
      </para>
     </callout>
     <callout arearefs="co-policy-2">
      <para>
       名为“examplesesadmin”的 Minion 具有“master”角色。顺便指出，这表示该 Minion 将获得集群的管理密钥。
      </para>
     </callout>
     <callout arearefs="co-policy-3">
      <para>
       与“sesclient*”匹配的所有 Minion 也将获得管理密钥。
      </para>
     </callout>
     <callout arearefs="co-policy-5">
      <para>
       与“ses-example-[123]”匹配的所有 Minion（应该是 ses-example-1、ses-example-2 和 ses-example-3 这三个 Minion）将设置为 MON 节点。
      </para>
     </callout>
     <callout arearefs="co-policy-mgr">
      <para>
       与“ses-example-[123]”匹配的所有 Minion（示例中的所有 MON 节点）将设置为 MGR 节点。
      </para>
     </callout>
     <callout arearefs="co-policy-6">
      <para>
       Minion“ses-example-4”将具有 MDS 角色。
      </para>
     </callout>
     <callout arearefs="co-policy-7">
      <para>
       确保 DeepSea 知道 IGW 节点的 IP 地址。
      </para>
     </callout>
     <callout arearefs="co-policy-10">
      <para>
       Minion“ses-example-4”将具有 IGW 角色。
      </para>
     </callout>
     <callout arearefs="co-policy-11">
      <para>
       Minion“ses-example-4”将具有 RGW 角色。
      </para>
     </callout>
     <callout arearefs="co-policy-oa">
      <para>
       指定要部署 openATTIC 用户界面来管理 Ceph 集群。有关详细信息，请参见<xref linkend="ceph-oa"/>。
      </para>
     </callout>
     <callout arearefs="co-policy-8">
      <para>
       表示我们接受 <option>fsid</option> 和 <option>public_network</option> 等通用配置参数的默认值。
      </para>
     </callout>
     <callout arearefs="co-policy-13">
      <para>
       表示我们接受 <option>fsid</option> 和 <option>public_network</option> 等通用配置参数的默认值。
      </para>
     </callout>
     <callout arearefs="co-policy-9">
      <para>
       告知 DeepSea 要为每个 Minion 使用默认的硬件配置。选择默认的硬件配置意味着我们要将所有附加磁盘（根磁盘除外）用作 OSD。
      </para>
     </callout>
     <callout arearefs="co-policy-12">
      <para>
       告知 DeepSea 要为每个 Minion 使用默认的硬件配置。选择默认的硬件配置意味着我们要将所有附加磁盘（根磁盘除外）用作 OSD。
      </para>
     </callout>
    </calloutlist>
   </sect3>
  </sect2>

  <sect2>
   <title>自定义 <filename>ceph.conf</filename> 文件</title>
   <para>
    如果需要将自定义设置放入 <filename>ceph.conf</filename> 配置文件，请参见<xref linkend="ds-custom-cephconf"/>了解更多详细信息。
   </para>
  </sect2>
 </sect1>
</chapter>
