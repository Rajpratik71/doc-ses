<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph-monitor">
 <title>クラスタの状態の判断</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>○</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  実行中のクラスタがある場合、<command>ceph</command>ツールを使用してクラスタを監視できます。一般的に、クラスタの状態の判断には、OSD、Monitor、配置グループ、およびMetadata Serverの状態を確認することが含まれます。<remark role="fixme">Maybe revert to old version of sentence: Determining the cluster state typically involves
  checking OSD status, monitor status, placement group status and metadata
  server status.</remark>
 </para>
 <tip>
  <title>インタラクティブモード</title>
  <para>
   <command>ceph</command>ツールをインタラクティブモードで実行するには、コマンドラインで引数を付けずに「<command>ceph</command>」と入力します。インタラクティブモードは、1行に多くの<command>ceph</command>コマンドを入力する場合に便利です。次に例を示します。
  </para>
<screen><prompt>cephadm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon_status</screen>
 </tip>
 <sect1 xml:id="monitor-health">
  <title>クラスタのヘルスの確認</title>

  <para>
   クラスタの起動後、データの読み込みや書き込みを開始する前に、クラスタのヘルスを確認します。
  </para>

<screen><prompt>root # </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <para>
   Cephクラスタは、次のいずれかのヘルスコードを返します。
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      1つ以上のOSDにダウン状態を示すマークが付いています。OSDデーモンが停止されているか、ピアOSDがネットワーク経由でOSDに接続できない可能性があります。一般的な原因として、デーモンの停止またはクラッシュ、ホストのダウン、ネットワークの停止などがあります。
     </para>
     <para>
      ホストが正常である場合、デーモンは起動していて、ネットワークは機能しています。デーモンがクラッシュした場合は、そのデーモンのログファイル(<filename>/var/log/ceph/ceph-osd.*</filename>)にデバッグ情報が記述されていることがあります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>crush type</replaceable>_DOWN (例: OSD_HOST_DOWN)</term>
    <listitem>
     <para>
      特定のCRUSHサブツリー内のすべてのOSD (たとえば、特定のホスト上のすべてのOSD)にダウン状態を示すマークが付いています。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      OSDがCRUSHマップ階層で参照されていますが、存在しません。次のコマンドを使用して、OSDをCRUSH階層から削除できます。
     </para>
<screen><prompt>root # </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      <emphasis>backfillfull</emphasis>、<emphasis>nearfull</emphasis>、<emphasis>full</emphasis>、または<emphasis>failsafe_full</emphasis>、あるいはこれらすべての使用量のしきい値が昇順になっていません。特に、<emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>、<emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis>、<emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis>となっている必要があります。次のコマンドを使用してしきい値を調整できます。
     </para>
<screen><prompt>root # </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      1つ以上のOSDが<emphasis>full</emphasis>のしきい値を超えており、クラスタは書き込みを実行できません。次のコマンドを使用して、プールごとの使用量を確認できます。
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
     <para>
      次のコマンドを使用して、現在定義されている<emphasis>full</emphasis>の比率を確認できます。
     </para>
<screen><prompt>root # </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      書き込み可用性を復元するための短期的な回避策は、fullのしきい値を少し高くすることです。
     </para>
<screen><prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      さらにOSDを展開してクラスタに新しいストレージを追加するか、既存のデータを削除して領域を解放します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      1つ以上のOSDが<emphasis>backfillfull</emphasis>のしきい値を超えており、データをこのデバイスにリバランスできません。これは、リバランスを完了できないこと、およびクラスタが満杯に近付いていることを示す早期警告です。次のコマンドを使用して、プールごとの使用量を確認できます。
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      1つ以上のOSDが<emphasis>nearfull</emphasis>のしきい値を超えています。これは、クラスタが満杯に近付いていることを示す早期警告です。次のコマンドを使用して、プールごとの使用量を確認できます。
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      関心のあるクラスタフラグが1つ以上設定されています。「full」<emphasis/>を除き、これらのフラグは次のコマンドを使用して設定またはクリアできます。
     </para>
<screen><prompt>root # </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>root # </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      次のようなフラグがあります。
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         クラスタにfullのフラグが付いており、書き込みを実行できません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd、pausewr </term>
       <listitem>
        <para>
         読み込みまたは書き込みを一時停止しました。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         OSDの起動が許可されていません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         OSD障害レポートが無視されているため、MonitorはOSDに「down」<emphasis/>のマークを付けません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         以前に「out」<emphasis/>のマークが付けられているOSDには、起動時に「in」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         設定した間隔が経過した後、「down」<emphasis/>状態のOSDに自動的に「out」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill、norecover、norebalance</term>
       <listitem>
        <para>
         回復またはデータリバランスは中断されます。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub、nodeep_scrub</term>
       <listitem>
        <para>
         スクラブ(<xref linkend="scrubbing"/>を参照)は無効化されます。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         キャッシュ階層化アクティビティは中断されます。
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      1つ以上のOSDに、関心のあるOSDごとのフラグが付いています。次のようなフラグがあります。
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         OSDの起動が許可されていません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         このOSD障害レポートは無視されます。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         障害後に、このOSDにすでに自動的に「out」<emphasis/>のマークが付けられている場合、起動時に「in」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         このOSDがダウンしている場合、設定した間隔が経過した後に自動的に「out」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      次のコマンドを使用して、OSDごとのフラグを設定およびクリアできます。
     </para>
<screen><prompt>root # </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>root # </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      CRUSHマップは非常に古い設定を使用しており、更新する必要があります。このヘルス警告をトリガさせることなく使用できる最も古い調整可能パラメータ(すなわち、クラスタに接続できる最も古いクライアントバージョン)は、<option>mon_crush_min_required_version</option>設定オプションで指定します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      CRUSHマップは、strawバケットの中間重み値の計算に、最適ではない古い手法を使用しています。新しい手法を使用するようCRUSHマップを更新する必要があります(<option>straw_calc_version</option>=1)。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      使用量を追跡するためのヒットセットが1つ以上のキャッシュプールに設定されておらず、階層化エージェントはキャッシュからフラッシュまたは削除するコールドオブジェクトを識別できません。次のコマンドを使用して、キャッシュプールにヒットセットを設定できます。
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      Luminous v12より前のOSDは実行されていませんが、<option>sortbitwise</option>フラグが付いていません。Luminous v12以上のOSDを起動する前に、<option>sortbitwise</option>フラグを設定する必要があります。
     </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      1つ以上のプールがクォータに達しており、書き込みをこれ以上許可していません。次のコマンドを使用して、プールのクォータと使用量を設定できます。
     </para>
<screen><prompt>root # </prompt>ceph df detail</screen>
     <para>
      次のコマンドを使用して、プールのクォータを増加できます。
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      または、既存のデータを削除して使用量を削減できます。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      データ可用性が低下しています。つまり、クラスタは、クラスタ内の一部のデータに対する潜在的な読み込みまたは書き込み要求を実行できません。具体的には、1つ以上のPGがIO要求の実行を許可していない状態です。問題があるPGの状態には、「peering」<emphasis/>、「stale」<emphasis/>、「incomplete」<emphasis/>、および「active」の欠如<emphasis/>などがあります(これらの状態がすぐにはクリアされない場合)。影響を受けるPGについての詳しい情報は、次のコマンドを使用して参照できます。
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      ほとんどの場合、根本原因は、現在1つ以上のOSDがダウンしていることです。次のコマンドを使用して、問題がある特定のPGの状態を問い合わせることができます。
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      一部のデータのデータ冗長性が低下しています。つまり、一部のデータについて必要な数のレプリカがクラスタにないか(複製プールの場合)、イレージャコードのフラグメントがクラスタにありません(イレージャコーディングプールの場合)。具体的には、1つ以上のPGに「degraded」<emphasis/>または「undersized」<emphasis/>のフラグが付いているか(クラスタ内にその配置グループの十分なインスタンスがありません)、またはしばらくの間「clean」<emphasis/>フラグが付いていません。影響を受けるPGについての詳しい情報は、次のコマンドを使用して参照できます。
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      ほとんどの場合、根本原因は、現在1つ以上のOSDがダウンしていることです。次のコマンドを使用して、問題がある特定のPGの状態を問い合わせることができます。
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      クラスタに空き領域がないため、一部のデータのデータ冗長性が低下しているか、危険な状態である可能性があります。具体的には、1つ以上のPGに「backfill_toofull」<emphasis/>または「recovery_toofull」<emphasis/>のフラグが付いています。つまり、1つ以上のOSDが<emphasis>backfillfull</emphasis>のしきい値を超えているため、クラスタはデータを移行または回復できません。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      データスクラブ(<xref linkend="scrubbing"/>を参照)によってクラスタのデータ整合性に問題が検出されました。具体的には、1つ以上のPGに「inconsistent」<emphasis/>または「snaptrim_error」<emphasis/>のフラグが付いています。これは、前のスクラブ操作で問題が見つかったか、「repair」<emphasis/>フラグが設定されていることを示しており、現在その不整合の修復が進行中であることを意味します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      最近のOSDスクラブで不整合が発見されました。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      キャッシュ層プールがほぼ満杯です。このコンテキストにおける「満杯」は、キャッシュプールの「target_max_bytes」<emphasis/>および「target_max_objects」<emphasis/>のプロパティによって判断されます。プールがターゲットしきい値に達した場合、データがキャッシュからフラッシュまたは削除される間、プールへの書き込み要求がブロックされることがあり、通常はレイテンシが非常に高くなり、パフォーマンスが低下する状態になります。次のコマンドを使用して、キャッシュプールのターゲットサイズを調整できます。
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      通常のキャッシュフラッシュおよび削除アクティビティは、基本層の可用性またはパフォーマンスの低下、あるいはクラスタ全体の負荷によっても低速になることがあります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      使用中のPGの数が、設定可能なしきい値である、OSDあたりの<option>mon_pg_warn_min_per_osd</option>のPG数未満です。このため、クラスタ内のOSDへのデータの分散とバランスが最適ではなくなり、全体的なパフォーマンスが低下します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      使用中のPGの数が、設定可能なしきい値である、OSDあたりの<option>mon_pg_warn_max_per_osd</option>のPG数を超えています。このため、OSDデーモンのメモリ使用量が増加する、クラスタの状態が変化(たとえば、OSDの再起動、追加、削除)した後にピアリングの速度が低下する、Ceph ManagerとCeph Monitorの負荷が増加するなどの可能性があります。
     </para>
     <para>
      既存のプールの<option>pg_num</option>の値を下げることはできませんが、<option>pgp_num</option>の値は下げることができます。これによって、同じOSDセットの複数のPGを効果的に一緒に配置して、前に説明した悪影響を多少緩和できます。次のコマンドを使用して、<option>pgp_num</option>の値を調整できます。
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      1つ以上のプールの<option>pgp_num</option>の値が<option>pg_num</option>未満です。これは通常、配置動作を同時に増やさずにPG数を増やしたことを示します。通常は、次のコマンドを使用して、<option>pgp_num</option>を<option>pg_num</option>に一致するよう設定し、データマイグレーションをトリガすることによって解決します。
     </para>
<screen>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      1つ以上のプールで、PGあたりの平均オブジェクト数がクラスタの全体の平均を大幅に超過しています。具体的なしきい値は、<option>mon_pg_warn_max_object_skew</option>の設定値で制御します。これは通常、クラスタ内のほとんどのデータを含むプールのPGが少なすぎるか、それほど多くのデータを含まない他のプールのPGが多すぎるか、またはその両方であることを示します。Monitorの<option>mon_pg_warn_max_object_skew</option>設定オプションを調整することによって、しきい値を上げてヘルス警告を停止できます。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED</term>
    <listitem>
     <para>
      1つ以上のオブジェクトが含まれるプールが存在しますが、特定のアプリケーション用のタグが付けられていません。この警告を解決するには、プールにアプリケーション用のラベルを付けます。たとえば、プールがRBDによって使用される場合は、次のコマンドを実行します。
     </para>
<screen><prompt>root # </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      プールがカスタムアプリケーション「foo」によって使用されている場合、次の低レベルのコマンドを使用してラベルを付けることもできます。
     </para>
<screen><prompt>root # </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      1つ以上のプールがクォータに達しています(またはクォータに非常に近付いています)。このエラー条件をトリガするためのしきい値は、<option>mon_pool_quota_crit_threshold</option>設定オプションで制御します。次のコマンドを使用して、プールクォータを増減(または削除)できます。
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      クォータの値を0に設定すると、クォータは無効になります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      1つ以上のプールがクォータに近付いています。この警告条件をトリガするためのしきい値は、<option>mon_pool_quota_warn_threshold</option>設定オプションで制御します。次のコマンドを使用して、プールクォータを増減(または削除)できます。
     </para>
<screen><prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      クォータの値を0に設定すると、クォータは無効になります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      クラスタ内の1つ以上のオブジェクトが、クラスタで保存場所に指定されているノードに保存されていません。これは、クラスタに最近加えられた変更によるデータマイグレーションがまだ完了していないことを示します。データの誤配置そのものは危険な状態ではありません。データ整合性は危険な状態ではなく、必要な数の新しいコピーが(必要な場所に)存在する限り、オブジェクトの古いコピーが削除されることはありません。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      クラスタ内の1つ以上のオブジェクトが見つかりません。具体的には、OSDはオブジェクトの新しいコピーまたはアップロードコピーが存在していることを認識していますが、現在オンラインであるOSD上にオブジェクトのそのバージョンのコピーが見つかりません。「見つからない」オブジェクトに対する読み込みまたは書き込み要求はブロックされます。理想的には、見つからないオブジェクトの最新のコピーがある、ダウン中のOSDをオンラインに戻すことができます。見つからないオブジェクトを受け持っているPGのピアリング状態から、候補のOSDを特定できます。
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      OSDの1つ以上の要求の処理に長い時間がかかっています。これは、極端な負荷、低速なストレージデバイス、またはソフトウェアのバグを示している可能性があります。OSDホストから次のコマンドを実行して、対象のOSDの要求キューを問い合わせることができます。
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      最も低速な最近の要求のサマリが表示されます。
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      次のコマンドを使用して、OSDの場所を特定できます。
     </para>
<screen><prompt>root # </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      OSDの1つ以上の要求がきわめて長時間ブロックされています。これは、クラスタが長時間にわたって正常でないか(たとえば、十分な数のOSDが実行されていない)、OSDに何らかの内部的な問題があることを示します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      最近、1つ以上のPGがスクラブ(<xref linkend="scrubbing"/>を参照)されていません。PGは通常、<option>mon_scrub_interval</option>の秒数ごとにスクラブされ、スクラブなしに<option>mon_warn_not_scrubbed</option>の間隔が経過した場合、この警告がトリガされます。cleanフラグが付いていない場合、PGはスクラブされません。これは、PGが誤配置されているか機能が低下している場合に発生することがあります(前のPG_AVAILABILITYおよびPG_DEGRADEDを参照してください)。次のコマンドを使用して、クリーンなPGのスクラブを手動で開始できます。
     </para>
<screen><prompt>root # </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      最近、1つ以上のPGが詳細スクラブ(<xref linkend="scrubbing"/>を参照)されていません。PGは通常、<option>osd_deep_mon_scrub_interval</option>の秒数ごとにスクラブされ、スクラブなしに<option>mon_warn_not_deep_scrubbed</option>の間隔が経過した場合、この警告がトリガされます。cleanフラグが付いていない場合、PGは詳細スクラブされません。これは、PGが誤配置されているか機能が低下している場合に発生することがあります(前のPG_AVAILABILITYおよびPG_DEGRADEDを参照してください)。次のコマンドを使用して、クリーンなPGのスクラブを手動で開始できます。
     </para>
<screen><prompt>root # </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    設定またはキーリングにデフォルト以外の場所を指定した場合、その場所を指定できます。
   </para>
<screen><prompt>root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-watch">
  <title>クラスタの監視</title>

  <para>
   <command>ceph -s</command>を使用して、クラスタの直近の状態を確認できます。たとえば、1つのMonitorと2つのOSDで構成される小規模なCephクラスタでは、ワークロードが実行中の場合、次の内容が出力される場合があります。
  </para>

<screen>cluster:
  id:     6586341d-4565-3755-a4fd-b50f51bee248
  health: HEALTH_OK

services:
  mon: 3 daemons, quorum blueshark1,blueshark2,blueshark3
  mgr: blueshark3(active), standbys: blueshark2, blueshark1
  osd: 15 osds: 15 up, 15 in

data:
  pools:   8 pools, 340 pgs
  objects: 537 objects, 1985 MB
  usage:   23881 MB used, 5571 GB / 5595 GB avail
  pgs:     340 active+clean

io:
  client:   100 MB/s rd, 26256 op/s rd, 0 op/s wr</screen>

  <para>
   出力に表示される情報は、次のとおりです。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     クラスタID
    </para>
   </listitem>
   <listitem>
    <para>
     クラスタのヘルス状態
    </para>
   </listitem>
   <listitem>
    <para>
     Monitorマップのエポック、およびMonitor定数の状態
    </para>
   </listitem>
   <listitem>
    <para>
     Monitorマップのエポック、およびOSDの状態
    </para>
   </listitem>
   <listitem>
    <para>
     配置グループのマップバージョン
    </para>
   </listitem>
   <listitem>
    <para>
     配置グループとプールの数
    </para>
   </listitem>
   <listitem>
    <para>
     保存データの「名目上」の<emphasis/>量と、保存オブジェクトの数
    </para>
   </listitem>
   <listitem>
    <para>
     保存データの合計量
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Cephによるデータ使用量の計算方法</title>
   <para>
    <literal>used</literal>の値は、未加工ストレージの実際の使用量を反映します。<literal>xxx GB / xxx GB</literal>の値は、クラスタの全体的なストレージ容量の利用可能な量(より少ない数)を意味します。名目上の数は、複製、クローン作成、またはスナップショット作成前の保存データのサイズを反映します。したがって、実際の保存データの量は名目上の量より大きくなるのが一般的です。Cephは、データのレプリカを作成し、クローンやスナップショットの作成にもストレージ容量を使用することがあるためです。
   </para>
  </tip>

  <para>
   直近の状態を表示するその他のコマンドは次のとおりです。
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   情報をリアルタイムで更新するには、これらの任意のコマンド(<command>ceph -s</command>を含む)を待ちループに入れます。次に例を示します。
  </para>

<screen><systemitem class="username">root</systemitem>while true ; do ceph -s ; sleep 10 ; done</screen>

  <para>
   監視を終了する場合は、<keycombo><keycap function="control"/><keycap>C</keycap></keycombo>キーを押します。
  </para>
 </sect1>
 <sect1 xml:id="monitor-stats">
  <title>クラスタの使用量統計の確認</title>

  <para>
   クラスタのデータ使用量とプール間でのデータの分散を確認するには、<command>df</command>オプションを使用できます。これはLinuxの<command>df</command>と同様です。次のコマンドを実行します。
  </para>

<screen><prompt>root # </prompt>ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    55886G     55826G       61731M          0.11
POOLS:
    NAME         ID     USED      %USED     MAX AVAIL     OBJECTS
    testpool     1          0         0        17676G           0
    ecpool       2      4077M      0.01        35352G        2102
    test1        3          0         0        17676G           0
    rbd          4         16         0        17676G           3
    rbd1         5         16         0        17676G           3
    ecpool1      6      5708M      0.02        35352G        2871</screen>

  <para>
   出力の<literal>GLOBAL</literal>セクションには、クラスタがデータに使用しているストレージの量の概要が表示されます。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>SIZE</literal>: クラスタの全体的なストレージ容量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal>: クラスタで利用可能な空き領域の量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal>: 使用済みの未加工ストレージの量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal>: 使用済みの未加工ストレージの割合。この数字を<literal>full ratio</literal>および<literal>near full ratio</literal>と組み合わせて使用して、クラスタの容量に達していないことを確認します。詳細については、「<link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/mon-config-ref#storage-capacit">Storage Capacity</link>」を参照してください。
    </para>
    <note>
     <title>クラスタの充足レベル</title>
     <para>
      未加工ストレージの充足レベルが70～80%になった場合、新しいストレージをクラスタに追加する必要があることを示しています。使用量がさらに多くなると、1つのOSDが満杯になり、クラスタのヘルスに問題が発生することがあります。
     </para>
     <para>
      すべてのOSDの充足レベルを一覧にするには、コマンド<command>ceph osd df tree</command>を使用します。
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   出力の<literal>POOLS</literal>セクションには、プールのリストと各プールの名目上の使用量が表示されます。このセクションの出力には、レプリカ、クローン、またはスナップショットは反映されて「いません」。<emphasis/>たとえば、1MBのデータを持つオブジェクトを保存した場合、名目上の使用量は1MBですが、実際の使用量は、レプリカ、クローン、およびスナップショットの数によっては2MB以上になることがあります。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>NAME</literal>: プールの名前。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal>: プールのID。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: 保存データの名目上の量(キロバイト単位)。ただし、メガバイトを表す場合はM、ギガバイトを表す場合はGがそれぞれ付加されます。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>%USED</literal>: プールごとの使用済みストレージの名目上の割合。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal>: 特定のプールで利用可能な最大領域。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal>: プールごとの保存オブジェクトの名目上の数。
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    POOLSセクションの数字は名目上の数字です。レプリカ、スナップショット、またはクローンの数は含まれません。そのため、USEDの量や%USEDの量を合計しても、出力の%GLOBALセクションのRAW USEDの量や%RAW USEDの量にはなりません。
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor-status">
  <title>クラスタの状態の確認</title>

  <para>
   クラスタの状態を確認するには、次のコマンドを実行します。
  </para>

<screen><prompt>root # </prompt>ceph status</screen>

  <para>
   または
  </para>

<screen><prompt>root # </prompt>ceph -s</screen>

  <para>
   インタラクティブモードで、「<command>status</command>」と入力して<keycap function="enter"/>キーを押します。
  </para>

<screen>ceph&gt; status</screen>

  <para>
   クラスタの状態が出力されます。たとえば、1つのMonitorと2つのOSDで構成される小規模なCephクラスタでは、次の内容が出力される場合があります。
  </para>

<screen>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</screen>
 </sect1>
 <sect1 xml:id="monitor-osdstatus">
  <title>OSDの状態の確認</title>

  <para>
   次のコマンドを実行して、OSDが動作中であることを確認します。
  </para>

<screen><prompt>root # </prompt>ceph osd stat</screen>

  <para>
   または
  </para>

<screen><prompt>root # </prompt>ceph osd dump</screen>

  <para>
   CRUSHマップ内での位置に従ってOSDを表示することもできます。
  </para>

<screen><prompt>root # </prompt>ceph osd tree</screen>

  <para>
   CRUSHツリーと共に、ホスト、そのOSD、動作中かどうか、および重みが出力されます。
  </para>

<screen># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</screen>
 </sect1>
 <sect1 xml:id="storage-bp-monitoring-fullosd">
  <title>満杯のOSDの確認</title>

  <para>
   Cephでは、データが失われないようにするため、満杯のOSDに書き込むことはできません。運用クラスタでは、クラスタが満杯率に近付くと警告が表示されます。<command>mon osd full ratio</command>のデフォルトは0.95です。すなわち、容量の95%に達すると、クライアントによるデータの書き込みが停止されます。<command>mon osd nearfull ratio</command>のデフォルトは0.85です。すなわち、容量の85%に達するとヘルス警告が生成されます。
  </para>

  <para>
   満杯のOSDノードは<command>ceph health</command>でレポートされます。
  </para>

<screen>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   または
  </para>

<screen>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   満杯のクラスタへの最適な対応方法は、新しいOSDノードを追加して、クラスタが新しく利用可能になったストレージにデータを再分散できるようにする方法です。
  </para>

  <para>
   満杯のためにOSDを起動できない場合は、満杯のOSDにある配置グループのディレクトリをいくつか削除することによって、一部のデータを削除できます。
  </para>

  <tip>
   <title>満杯のOSDの防止</title>
   <para>
    OSDが満杯になると(ディスク領域の100%を使用すると)、通常は警告なしにすぐにクラッシュします。次に、OSDノードを管理する際に覚えておくべきヒントをいくつか示します。
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      各OSDのディスク領域(通常は<filename>/var/lib/ceph/osd/osd-{1,2..}</filename>にマウント)は、基礎となる専用のディスクまたはパーティションに配置する必要があります。
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph設定ファイルを確認して、CephがOSD専用のディスク/パーティションにログファイルを保存しないようにします。
     </para>
    </listitem>
    <listitem>
     <para>
      他のプロセスがOSD専用のディスク/パーティションに書き込まないようにします。
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-monstatus">
  <title>Monitorの状態の確認</title>

  <para>
   クラスタに複数のMonitorがある場合(ほとんどの場合に当てはまります)、クラスタの起動後、データを読み書きする前に、Monitorの定数の状態を確認する必要があります。複数のMonitorが実行されている場合、定数が存在する必要があります。また、Monitorの状態を定期的にチェックして、Monitorが実行されていることを確認する必要もあります。
  </para>

  <para>
   Monitorマップを表示するには、次のコマンドを実行します。
  </para>

<screen><prompt>root # </prompt>ceph mon stat</screen>

  <para>
   または
  </para>

<screen><prompt>root # </prompt>ceph mon dump</screen>

  <para>
   Monitorクラスタの定数の状態を確認するには、次のコマンドを実行します。
  </para>

<screen><prompt>root # </prompt>ceph quorum_status</screen>

  <para>
   定数の状態が返されます。たとえば、3つのMonitorで構成されるCephクラスタは、次の状態を返す場合があります。
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "127.0.0.1:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "127.0.0.1:6790\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "127.0.0.1:6791\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor-pgroupstatus">
  <title>配置グループの状態の確認</title>

  <para>
   配置グループはオブジェクトをOSDにマップします。配置グループを監視する場合、配置グループが<literal>active</literal>および<literal>clean</literal>である必要があります。詳細については、「<link xlink:href="http://docs.ceph.com/docs/master/rados/operations/monitoring-osd-pg">Monitoring OSDs and Placement Groups</link>」を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="monitor-adminsocket">
  <title>管理ソケットの使用</title>

  <para>
   <remark role="fixme">Maybe give an example use case? No obvious difference to normal ceph command?!</remark>Ceph管理ソケットを使用すると、ソケットインタフェース経由でデーモンに問い合わせることができます。デフォルトでは、Cephソケットは<filename>/var/run/ceph</filename>にあります。管理ソケット経由でデーモンにアクセスするには、デーモンが実行されているホストにログインして、次のコマンドを使用します。
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable></screen>

  <para>
   利用可能な管理ソケットコマンドを表示するには、次のコマンドを実行します。
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable> help</screen>

  <para>
   管理ソケットコマンドでは、ランタイム時に設定を表示および設定できます。詳細については、「<link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf#ceph-runtime-config">Viewing a Configuration at Runtime</link>」を参照してください。
  </para>

  <para>
   さらに、ランタイム時に設定値を直接設定することもできます(管理ソケットは、<command>ceph tell</command>
   <replaceable>daemon-type</replaceable>.<replaceable>id</replaceable> injectargsとは異なり、Monitorをバイパスします。これは、Monitorに依存しますが、対象のホストに直接ログインする必要はありません)。
  </para>
 </sect1>
</chapter>
