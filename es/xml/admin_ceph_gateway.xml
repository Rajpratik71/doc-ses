<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_gateway.xml" version="5.0" xml:id="cha-ceph-gw">

 <title>Ceph Object Gateway</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>editar</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>sí</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  En este capítulo se presentan las tareas de administración relacionadas con Object Gateway, como la comprobación del estado del servicio, la gestión de cuentas, las pasarelas de varios sitios o la autenticación LDAP.
 </para>
 <sect1 xml:id="sec-ceph-rgw-limits">
  <title>Restricciones y limitaciones de denominación de Object Gateway</title>

  <para>
   A continuación encontrará una lista de limitaciones importantes de Object Gateway.
  </para>

  <sect2 xml:id="ogw-limits-bucket">
   <title>Limitaciones del depósito</title>
   <para>
    Cuando se accede a Object Gateway a través de la API de S3, los nombres de depósito deben ser nombres compatibles con DNS y solo se permite el carácter de guión "". Cuando se accede a Object Gateway a través de la API de Swift, puede utilizar cualquier combinación de caracteres UTF-8 compatibles, excepto el carácter de barra "/". La longitud máxima de los nombres de depósito es de 255 caracteres. Los nombres de depósitos deben ser exclusivos.
   </para>
   <tip>
    <title>uso de nombres de depósitos compatibles con DNS</title>
    <para>
     Aunque puede utilizar cualquier nombre de depósito basado en UTF-8 en la API de Swift, se recomienda respetar la limitación existente para los nombre en S3, a fin de evitar problemas al acceder al mismo depósito a través de la API de S3.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ogw-limits-object">
   <title>Limitaciones de objetos almacenados</title>
   <variablelist>
    <varlistentry>
     <term>Número máximo de objetos por usuario</term>
     <listitem>
      <para>
       No hay restricciones por defecto (limitado a ~2^63).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Número máximo de objetos por depósito</term>
     <listitem>
      <para>
       No hay restricciones por defecto (limitado a ~2^63).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Tamaño máximo de un objeto para cargar o almacenar</term>
     <listitem>
      <para>
       Las cargas sencillas están restringidas a 5 GB. Divida varias partes para objetos más grandes. El número máximo de porciones de varias partes es 10 000.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ogw-limits-http">
   <title>Limitaciones de los encabezados HTTP</title>
   <para>
    El encabezado HTTP y la limitación de la petición dependen de la interfaz Web que se utilice. En la opción por defecto, CivetWeb, se restringe el número de encabezados HTTP a 64 y el tamaño del encabezado HTTP a 16 kB.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-deploy">
  <title>Distribución de Object Gateway</title>

  <para>
   La forma recomendada de distribuir Ceph Object Gateway es a través de la infraestructura DeepSea añadiendo las líneas <literal>role-rgw [...]</literal> pertinentes en el archivo <filename>policy.cfg</filename> del master de Salt y, después, ejecutando las fases necesarias de DeepSea.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Para incluir Object Gateway durante el proceso de distribución del clúster de Ceph, consulte <xref linkend="ceph-install-stack"/> y <xref linkend="policy-configuration"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Para añadir la función de Object Gateway a un clúster ya distribuido, consulte la <xref linkend="salt-adding-services"/>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="ceph-rgw-operating">
  <title>Funcionamiento del servicio de Object Gateway</title>

  <para>
   El servicio de Object Gateway funciona con el comando <command>systemctl</command>. Debe tener privilegios de usuario <systemitem class="username">root</systemitem> para poder ejecutar el servicio de Object Gateway. Tenga en cuenta que el nombre de host del servidor cuya instancia de Object Gateway debe ejecutar es <replaceable>gateway_host</replaceable>.
  </para>

  <para>
   Se admiten los siguientes subcomandos para el servicio de Object Gateway:
  </para>

  <variablelist>
   <varlistentry>
    <term>systemctl status ceph-radosgw@rgw.<replaceable>host_de_pasarela</replaceable>
    </term>
    <listitem>
     <para>
      Imprime la información de estado del servicio.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl start ceph-radosgw@rgw.<replaceable>host_de_pasarela</replaceable>
    </term>
    <listitem>
     <para>
      Inicia el servicio en caso de que no se esté ejecutando.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl restart ceph-radosgw@rgw.<replaceable>host_de_pasarela</replaceable>
    </term>
    <listitem>
     <para>
      Reinicia el servicio.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl stop ceph-radosgw@rgw.<replaceable>host_de_pasarela</replaceable>
    </term>
    <listitem>
     <para>
      Detiene el servicio en ejecución.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl enable ceph-radosgw@rgw.<replaceable>host_de_pasarela</replaceable>
    </term>
    <listitem>
     <para>
      Habilita el servicio para que se inicie automáticamente al mismo tiempo que el sistema.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl disable ceph-radosgw@rgw.<replaceable>host_de_pasarela</replaceable>
    </term>
    <listitem>
     <para>
      Inhabilita el servicio para que no se inicie automáticamente al mismo tiempo que el sistema.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-ceph-rgw-configuration">
  <title>Parámetros de configuración</title>

  <para>
   El comportamiento de Object Gateway puede verse afectado por un gran número de opciones del archivo <filename>ceph.conf</filename>. A continuación encontrará una lista de los más importantes. Para obtener una lista completa, consulte <link xlink:href="http://docs.ceph.com/docs/master/radosgw/config-ref/"/>.
  </para>

  <variablelist>
   <varlistentry>
    <term>rgw_thread_pool_size</term>
    <listitem>
     <para>
      El número de hilos para el servidor de CivetWeb. Se incrementa a un valor superior si necesita atender más peticiones. Por defecto es 100 hilos.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>rgw_num_rados_handles</term>
    <listitem>
     <para>
      El número de referencias de clúster de RADOS (consulte <link xlink:href="http://docs.ceph.com/docs/master/rados/api/librados-intro/#step-2-configuring-a-cluster-handle"/>) para Object Gateway. Disponer de un número de referencias de RADOS configurable aumenta de forma significativa el rendimiento de todos los tipos de cargas de trabajo. Cada hilo de trabajo de Object Gateway debería elegir ahora una referencia de RADOS para toda su vida útil. El valor por defecto es 1.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>rgw_max_chunk_size</term>
    <listitem>
     <para>
      El tamaño máximo de una porción de datos que se leerá en una única operación. Si se aumenta el valor a 4 MB (4194304) se conseguirá un mejor rendimiento al procesar objetos grandes. El valor por defecto es 128 kB (131072).
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <sect2 xml:id="sec-ceph-rgw-configuration-notes">
   <title>Notas adicionales</title>
   <variablelist>
    <varlistentry>
     <term>rgw dns name</term>
     <listitem>
      <para>
       Si el parámetro <literal>rgw dns name</literal> se añade a <filename>ceph.conf</filename>, asegúrese de que el cliente de S3 está configurado para dirigir las peticiones al puesto final especificado por <literal>rgw dns name</literal>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-access">
  <title>Gestión del acceso a Object Gateway</title>

  <para>
   Es posible comunicarse con Object Gateway mediante una interfaz compatible con S3 o con Swift. La interfaz de S3 es compatible con un gran subconjunto de la API RESTful de Amazon S3. La interfaz de Swift es compatible con un gran subconjunto de la API de OpenStack Swift.
  </para>

  <para>
   Ambas interfaces requieren que cree un usuario específico y que instale el software cliente relevante para comunicarse con la pasarela mediante la clave de secreto del usuario.
  </para>

  <sect2 xml:id="accessing-ragos-gateway">
   <title>Acceso a Object Gateway</title>
   <sect3>
    <title>Acceso a la interfaz de S3</title>
    <para>
     Para acceder a la interfaz de S3, necesita un cliente de REST. <command>S3cmd</command> es un cliente de S3 de línea de comandos. Lo encontrará en <link xlink:href="https://build.opensuse.org/package/show/Cloud:Tools/s3cmd">OpenSUSE Build Service</link>. El repositorio contiene versiones tanto para SUSE Linux Enterprise como para distribuciones basadas en openSUSE.
    </para>
    <para>
     Si desea probar el acceso a la interfaz de S3, también puede escribir un pequeño guion de Python. El guion se conectará con Object Gateway, creará un depósito nuevo y mostrará todos los depósitos. Los valores de <option>aws_access_key_id</option> y <option>aws_secret_access_key</option> se toman de los valores de <option>access_key</option> y <option>secret_key</option> devueltos por el comando <command>radosgw_admin</command> de la <xref linkend="adding-s3-swift-users"/>.
    </para>
    <procedure>
     <step>
      <para>
       Instale el paquete <systemitem>python-boto</systemitem>:
      </para>
<screen>sudo zypper in python-boto</screen>
     </step>
     <step>
      <para>
       Cree un nuevo guion de Python denominado <filename>s3test.py</filename> con el siguiente contenido: <remark role="fixme">Provide script in RPM? Is it really necessary to create pool? This script is not necessary at all, remove it from documentation?</remark>
      </para>
<screen>import boto
import boto.s3.connection
access_key = '11BS02LGFB6AL6H1ADMW'
secret_key = 'vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY'
conn = boto.connect_s3(
aws_access_key_id = access_key,
aws_secret_access_key = secret_key,
host = '{hostname}',
is_secure=False,
calling_format = boto.s3.connection.OrdinaryCallingFormat(),
)
bucket = conn.create_bucket('my-new-bucket')
for bucket in conn.get_all_buckets():
  print "{name}\t{created}".format(
  name = bucket.name,
  created = bucket.creation_date,
  )</screen>
      <para>
       Sustituya <literal>{hostname}</literal> por el nombre del host donde haya configurado el servicio de Object Gateway; por ejemplo <literal>gateway_host</literal>.
      </para>
     </step>
     <step>
      <para>
       Ejecute el guion:
      </para>
<screen>python s3test.py</screen>
      <para>
       El guion da como resultado algo parecido a lo siguiente:
      </para>
<screen>my-new-bucket 2015-07-22T15:37:42.000Z</screen>
     </step>
    </procedure>
   </sect3>
   <sect3>
    <title>Acceso a la interfaz de Swift</title>
    <para>
     Para acceder a Object Gateway a través de una interfaz de Swift, necesita el cliente de línea de comandos <command>swift</command>. La página <command>man 1 swift</command> incluye más información sobre las opciones de la línea de comandos.
    </para>
    <para>
     El paquete se incluye en el módulo "Nube pública" de SUSE Linux Enterprise 12 SP3. Antes de instalar el paquete, debe activar el módulo y actualizar el repositorio de software:
    </para>
<screen>sudo SUSEConnect -p sle-module-public-cloud/12/x86_64
sudo zypper refresh</screen>
    <para>
     Para instalar el comando <command>swift</command>, ejecute lo siguiente:
    </para>
<screen>sudo zypper in python-swiftclient</screen>
    <para>
     El acceso swift utiliza la sintaxis siguiente:
    </para>
<screen>swift -A http://<replaceable>IP_ADDRESS</replaceable>/auth/1.0 \
-U example_user:swift -K '<replaceable>swift_secret_key</replaceable>' list</screen>
    <para>
     Sustituya <replaceable>IP_ADDRESS</replaceable> por la dirección IP del servidor de pasarela, y <replaceable>swift_secret_key</replaceable> por el valor de la clave de secreto de Swift que se obtiene al ejecutar el comando <command>radosgw-admin key create</command> para el usuario de <systemitem>swift</systemitem> en la <xref linkend="adding-s3-swift-users"/>.
    </para>
    <para>
     Por ejemplo:
    </para>
<screen>swift -A http://gateway.example.com/auth/1.0 -U example_user:swift \
-K 'r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h' list</screen>
    <para>
     El resultado es:
    </para>
<screen>my-new-bucket</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="s3-swift-accounts-managment">
   <title>Gestión de cuentas de S3 y Swift</title>
   <sect3 xml:id="adding-s3-swift-users">
    <title>Adición de usuarios de S3 y Swift</title>
    <para>
     Debe crear un usuario, una clave de acceso y un secreto para permitir que los usuarios finales puedan interactuar con la pasarela. Existen dos tipos de usuarios: <emphasis>usuario</emphasis> y <emphasis>subusuario</emphasis>. Los <emphasis>usuarios</emphasis> se utilizan cuando se interactúa con la interfaz de S3, mientras que los <emphasis>subusuarios</emphasis> son usuarios de la interfaz de Swift. Cada subusuario está asociado a un usuario.
    </para>
    <para>
     También se pueden añadir usuarios a través del archivo <filename>rgw.sls</filename> de DeepSea. Si desea ver un ejemplo, consulte la <xref linkend="ceph-nfsganesha-customrole-rgw-multiusers"/>.
    </para>
    <para>
     Para crear un usuario de Swift, siga estos pasos:
    </para>
    <procedure>
     <step>
      <para>
       Para crear un usuario de Swift, que es un <emphasis>subusuario</emphasis> en nuestra terminología, debe crear primero el <emphasis>usuario</emphasis> asociado.
      </para>
<screen>sudo radosgw-admin user create --uid=<replaceable>username</replaceable> \
 --display-name="<replaceable>display-name</replaceable>" --email=<replaceable>email</replaceable></screen>
      <para>
       Por ejemplo:
      </para>
<screen>sudo radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</screen>
     </step>
     <step>
      <para>
       Para crear un subusuario (interfaz de Swift) para el usuario, debe especificar el ID de usuario (--uid=<replaceable>nombre de usuario</replaceable>), el ID de subusuario y el nivel de acceso para el subusuario.
      </para>
<screen>sudo radosgw-admin subuser create --uid=<replaceable>uid</replaceable> \
 --subuser=<replaceable>uid</replaceable> \
 --access=[ <replaceable>read | write | readwrite | full</replaceable> ]</screen>
      <para>
       Por ejemplo:
      </para>
<screen>sudo radosgw-admin subuser create --uid=example_user \
 --subuser=example_user:swift --access=full</screen>
     </step>
     <step>
      <para>
       Genere una clave de secreto para el usuario.
      </para>
<screen>sudo radosgw-admin key create \
   --gen-secret \
   --subuser=example_user:swift \
   --key-type=swift</screen>
     </step>
     <step>
      <para>
       Ambos comandos darán como resultado datos con formato JSON que muestran el estado del usuario. Fíjese en las siguientes líneas y recuerde el valor de <literal>secret_key</literal>:
      </para>
<screen>"swift_keys": [
   { "user": "example_user:swift",
     "secret_key": "r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h"}],</screen>
     </step>
    </procedure>
    <para/>
    <para>
     Cuando acceda a Object Gateway a través de la interfaz de S3, deberá crear un usuario de S3 ejecutando:
    </para>
<screen>sudo radosgw-admin user create --uid=<replaceable>username</replaceable> \
 --display-name="<replaceable>display-name</replaceable>" --email=<replaceable>email</replaceable></screen>
    <para>
     Por ejemplo:
    </para>
<screen>sudo radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</screen>
    <para>
     El comando también crea la clave de acceso y la clave de secreto del usuario. Compruebe el resultado de las palabras clave <literal>access_key</literal> y <literal>secret_key</literal> y sus valores correspondientes:
    </para>
<screen>[...]
 "keys": [
       { "user": "example_user",
         "access_key": "11BS02LGFB6AL6H1ADMW",
         "secret_key": "vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY"}],
 [...]</screen>
   </sect3>
   <sect3 xml:id="removing-s3-swift-users">
    <title>Eliminación de usuarios de S3 y Swift</title>
    <para>
     El procedimiento para suprimir usuarios es similar para los usuarios de S3 y de Swift. Pero en el caso de los usuarios de Swift, puede ser necesario suprimir el usuario incluyendo sus subusuarios.
    </para>
    <para>
     Para eliminar un usuario de S3 o Swift (incluidos todos sus subusuarios), especifique <option>user rm</option> y el ID de usuario en el siguiente comando:
    </para>
<screen>sudo radosgw-admin user rm --uid=example_user</screen>
    <para>
     Para eliminar un subusuario, especifique <option>subuser rm</option> y el ID de subusuario.
    </para>
<screen>sudo radosgw-admin subuser rm --uid=example_user:swift</screen>
    <para>
     Puede usar las siguientes opciones:
    </para>
    <variablelist>
     <varlistentry>
      <term>--purge-data</term>
      <listitem>
       <para>
        Limpia todos los datos asociados al ID de usuario.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>--purge-keys</term>
      <listitem>
       <para>
        Limpia todas las claves asociadas al ID de usuario.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <tip>
     <title>eliminación de un subusuario</title>
     <para>
      Cuando se elimina un subusuario, se elimina el acceso a la interfaz de Swift. El usuario permanecerá en el sistema.
     </para>
    </tip>
   </sect3>
   <sect3 xml:id="changing-s3-swift-users-password">
    <title>Cambio del acceso de usuario y las claves de secreto de S3 y Swift</title>
    <para>
     Los parámetros <literal>access_key</literal> y <literal>secret_key</literal> identifican al usuario de Object Gateway cuando se accede a la pasarela. Cambiar las claves de usuario existentes es igual a crear otras nuevas, ya que las claves antiguas se sobrescriben.
    </para>
    <para>
     Para los usuarios de S3, ejecute lo siguiente:
    </para>
<screen>sudo radosgw-admin key create --uid=<replaceable>example_user</replaceable> --key-type=s3 --gen-access-key --gen-secret</screen>
    <para>
     Para los usuarios de Swift, ejecute lo siguiente:
    </para>
<screen>sudo radosgw-admin key create --subuser=<replaceable>example_user</replaceable>:swift --key-type=swift --gen-secret</screen>
    <variablelist>
     <varlistentry>
      <term><option>--key-type=<replaceable>tipo</replaceable></option>
      </term>
      <listitem>
       <para>
        Especifica el tipo de clave. Puede ser <literal>swift</literal> o <literal>s3</literal>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--gen-access-key</option>
      </term>
      <listitem>
       <para>
        Genera una clave de acceso aleatoria (por defecto, para el usuario de S3).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--gen-secret</option>
      </term>
      <listitem>
       <para>
        Genera una clave de secreto aleatoria.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--secret=<replaceable>clave</replaceable></option>
      </term>
      <listitem>
       <para>
        Especifica una clave de secreto; por ejemplo, una generada manualmente.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="user-quota-managment">
    <title>Gestión de cuotas de usuario</title>
    <para>
     Ceph Object Gateway permite definir cuotas en usuarios y depósitos que pertenezcan a los usuarios. Las cuotas incluyen el número máximo de objetos de un depósito y el tamaño de almacenamiento máximo en megabytes.
    </para>
    <para>
     Antes de habilitar una cuota de usuario, debe definir los parámetros correspondientes:
    </para>
<screen>sudo radosgw-admin quota set --quota-scope=user --uid=<replaceable>example_user</replaceable> \
 --max-objects=1024 --max-size=1024</screen>
    <variablelist>
     <varlistentry>
      <term><option>--max-objects</option>
      </term>
      <listitem>
       <para>
        Especifica el número máximo de objetos. Un valor negativo inhabilita la comprobación.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--max-size</option>
      </term>
      <listitem>
       <para>
        Especifica el número máximo de bytes. Un valor negativo inhabilita la comprobación.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--quota-scope</option>
      </term>
      <listitem>
       <para>
        Define el ámbito para la cuota. Las opciones son <literal>depósito</literal> y <literal>usuario</literal>. Las cuotas de depósito se aplican a los depósitos que posee un usuario. Las cuotas de usuario se aplican a un usuario.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Una vez definida una cuota de usuario, se puede habilitar:
    </para>
<screen>sudo radosgw-admin quota enable --quota-scope=user --uid=<replaceable>example_user</replaceable></screen>
    <para>
     Para inhabilitar una cuota:
    </para>
<screen>sudo radosgw-admin quota disable --quota-scope=user --uid=<replaceable>example_user</replaceable></screen>
    <para>
     Para mostrar la configuración de la cuota:
    </para>
<screen>sudo radosgw-admin user info --uid=<replaceable>example_user</replaceable></screen>
    <para>
     Para actualizar las estadísticas de la cuota:
    </para>
<screen>sudo radosgw-admin user stats --uid=<replaceable>example_user</replaceable> --sync-stats</screen>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-https">
  <title>Habilitación de HTTPS/SSL para pasarelas Object Gateway</title>

  <para>
   Para habilitar la función de Object Gateway por defecto para comunicarse de forma segura mediante SSL, debe tener un certificado emitido por una CA o crear uno autofirmado. Existen dos formas de configurar Object Gateway con HTTPS habilitado: una forma sencilla donde se usan los ajustes por defecto y otra avanzada que permite configurar con más detalles los valores relacionados con HTTPS.
  </para>

  <sect2 xml:id="ogw-selfcert">
   <title>Creación de un certificado autofirmado</title>
   <tip>
    <para>
     Omita esta sección si ya dispone de un certificado válido firmado por una CA.
    </para>
   </tip>
   <para>
    Por defecto, DeepSea espera que el archivo de certificado esté en <filename>/srv/salt/ceph/rgw/cert/rgw.pem</filename> en el master de Salt. A continuación, distribuirá el certificado a <filename>/etc/ceph/rgw.pem</filename> en el minion de Salt con la función de Object Gateway, donde Ceph lo lee.
   </para>
   <para>
    El siguiente procedimiento describe cómo generar un certificado SSL autofirmado en el nodo master de Salt.
   </para>
   <procedure>
    <step>
     <para>
      Añada la opción <option>subjectAltName</option> a la sección <literal>[v3_req]</literal> del archivo <filename>/etc/ssl/openssl.cnf</filename> para todos los nombres de host que desee que conozcan su pasarela Object Gateway:
     </para>
<screen>
[...]
[ v3_req ]
subjectAltName = ${ENV::SAN}
[...]
</screen>
    </step>
    <step>
     <para>
      Cree la clave y el certificado con <command>openssl</command>. Añada a <command>openssl</command> el prefijo <literal>env SAN=DNS:fqdn</literal>. Introduzca todos los datos que necesite incluir en el certificado. Es recomendable introducir el nombre completo como nombre común. Antes de firmar el certificado, verifique que en las extensiones pedidas se incluye "X509v3 Subject Alternative Name:" y que el certificado resultante tiene definido "X509v3 Subject Alternative Name:".
     </para>
<screen>
<prompt>root@master # </prompt>env SAN=DNS:fqdn openssl req -x509 -nodes -days 1095 \
 -newkey rsa:4096 -keyout rgw.key -out /srv/salt/ceph/rgw/cert/rgw.pem
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw-ssl-simple">
   <title>Configuración básica de HTTPS</title>
   <para>
    Por defecto, la instancia de Ceph del nodo de Object Gateway lee el certificado <filename>/etc/ceph/rgw.pem</filename> y utiliza el puerto 443 para la comunicación SSL segura. Si no necesita cambiar estos valores, siga estos pasos:
   </para>
   <procedure>
    <step>
     <para>
      Edite <filename>/srv/pillar/ceph/stack/global.yml</filename> y añada la línea siguiente:
     </para>
<screen>
rgw_configurations: rgw-ssl
rgw_init: default-ssl
</screen>
    </step>
    <step>
     <para>
      Ejecute las fases 2, 3 y 4 de DeepSea para aplicar los cambios:
     </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw-ssl-advanced">
   <title>Configuración avanzada de HTTPS</title>
   <para>
    Si necesita cambiar los valores por defecto de la configuración de SSL de Object Gateway, siga estos pasos:
   </para>
   <procedure>
    <step>
     <para>
      Copie la configuración por defecto de SSL de Object Gateway en el subdirectorio <filename>ceph.conf.d</filename>:
     </para>
<screen>
<prompt>root@master # </prompt>cp /srv/salt/ceph/configuration/files/rgw-ssl.conf \
 /srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf
</screen>
    </step>
    <step>
     <para>
      Edite <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf</filename> y cambie las opciones por defecto, como el número de puerto o la vía al certificado SSL para reflejar su configuración.
     </para>
    </step>
    <step>
     <para>
      Ejecute las fases 3 y 4 de DeepSea para aplicar los cambios:
     </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
    </step>
   </procedure>
   <tip xml:id="rgw-civetweb-multiport">
    <title>vinculación con varios puertos</title>
    <para>
     El servidor de CivetWeb puede vincularse a varios puertos. Esto resulta útil si necesita acceder a una única instancia de Object Gateway mediante conexiones tanto SSL como no SSL. Al especificar los puertos, separe sus números de un signo más "+". A continuación se muestra un ejemplo de la línea de configuración de dos puertos:
    </para>
<screen>[client.{{ client }}]
rgw_frontends = civetweb port=80+443s ssl_certificate=/etc/ceph/rgw.pem</screen>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-sync">
  <title>Módulos de sincronización</title>

  <para>
   La funcionalidad de <emphasis>varios sitios</emphasis> de Object Gateway, introducida en la versión Jewel, permite crear varias zonas y duplicar datos y metadatos entre ellas. Los <emphasis>módulos de sincronización</emphasis> se crean sobre la infraestructura de varios sitios y permiten el envío de datos y metadatos a un nivel externo diferente. Con un módulo de sincronización es posible realizar un conjunto de acciones siempre que se produzca un cambio en los datos (los operadores de metadatos, como la creación de depósitos o usuarios también se consideran cambios de los datos). Como los cambios en varios sitios de rgw al final acaban siendo consistentes en los sitios remotos, estos cambios se propagan de forma asíncrona. Esto permite situaciones de uso como realizar una copia de seguridad del almacenamiento de objetos en un clúster de nube externa o una solución de copia de seguridad personalizada mediante unidades de cinta; o también indexar metadatos en Elasticsearch, etc.
  </para>

  <sect2 xml:id="ceph-rgw-sync-zones">
   <title>Sincronización de zonas</title>
   <para>
    La configuración del módulo de sincronización es local en una zona. El módulo de sincronización determina si la zona exporta los datos o si solo puede utilizar los datos que se ha modificado en otra zona. A partir de la versión Luminous, los complementos de sincronización compatibles son <literal>elasticsearch</literal>, <literal>rgw</literal> (el complemento por defecto que sincroniza los datos entre las zonas) y <literal>log</literal>, un complemento de sincronización trivial que registra la operación de metadatos que se produce en las zonas remotas. Las secciones siguientes muestran como ejemplo una zona con el módulo de sincronización <literal>elasticsearch</literal>. El proceso será similar para configurar cualquier otro complemento de sincronización.
   </para>
   <note>
    <title>complemento de sincronización por defecto</title>
    <para>
     El complemento de sincronización por defecto es <literal>rgw</literal> y no es necesario configurarlo de forma explícita.
    </para>
   </note>
   <sect3 xml:id="ceph-rgw-sync-zones-req">
    <title>Requisitos y supuestos</title>
    <para>
     Supongamos que tenemos una configuración sencilla de varios sitios descrita en la <xref linkend="ceph-rgw-fed"/>, formada por 2 zonas <literal>us-east</literal> y <literal>us-west</literal>. Se añade una tercera zona <literal>us-east-es</literal>, que es una zona que solo procesa metadatos de los otros sitios. Esta zona puede estar en el mismo clúster de Ceph o en uno distinto a <literal>us-east</literal>. Esta zona solo consumirá metadatos de otras zonas y la pasarela Object Gateway de esta zona no atenderá directamente a ninguna petición del usuario final.
    </para>
   </sect3>
   <sect3 xml:id="ceph-rgw-sync-zones-configure">
    <title>Configuración de módulos de sincronización</title>
    <procedure>
     <step>
      <para>
       Cree una tercera zona similar a la que se describe en la <xref linkend="ceph-rgw-fed"/>, por ejemplo:
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone create --rgw-zonegroup=us --rgw-zone=us-east-es \
--access-key={system-key} --secret={secret} --endpoints=http://rgw-es:80
      </screen>
     </step>
     <step>
      <para>
       Puede configurar un módulo de sincronización para esta zona mediante lo siguiente:
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --tier-type={tier-type} \
--tier-config={set of key=value pairs}
      </screen>
     </step>
     <step>
      <para>
       Por ejemplo, en el módulo de sincronización <literal>elasticsearch</literal>:
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --tier-type=elasticsearch \
--tier-config=endpoint=http://localhost:9200,num_shards=10,num_replicas=1
      </screen>
      <para>
       Para las distintas opciones de configuración de niveles admitidas, consulte la <xref linkend="ceph-rgw-sync-elastic"/>.
      </para>
     </step>
     <step>
      <para>
       Por último, actualice el período:
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
      </screen>
     </step>
     <step>
      <para>
       Inicie ahora radosgw en la zona:
      </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> start ceph-radosgw@rgw.`hostname -s`
<prompt>root # </prompt><command>systemctl</command> enable ceph-radosgw@rgw.`hostname -s`
      </screen>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-sync-elastic">
   <title>Almacenamiento de metadatos en Elasticsearch</title>
   <para>
    Este módulo de sincronización escribe los metadatos de otras zonas en Elasticsearch. A partir de la versión Luminous, este es el código JSON de campos de datos que se almacenan en Elasticsearch.
   </para>
<screen>
{
  "_index" : "rgw-gold-ee5863d6",
  "_type" : "object",
  "_id" : "34137443-8592-48d9-8ca7-160255d52ade.34137.1:object1:null",
  "_score" : 1.0,
  "_source" : {
    "bucket" : "testbucket123",
    "name" : "object1",
    "instance" : "null",
    "versioned_epoch" : 0,
    "owner" : {
      "id" : "user1",
      "display_name" : "user1"
    },
    "permissions" : [
      "user1"
    ],
    "meta" : {
      "size" : 712354,
      "mtime" : "2017-05-04T12:54:16.462Z",
      "etag" : "7ac66c0f148de9519b8bd264312c4d64"
    }
  }
}
   </screen>
   <sect3 xml:id="ceph-rgw-sync-elastic-config">
    <title>Parámetros de configuración de tipo de nivel de Elasticsearch</title>
    <variablelist>
     <varlistentry>
      <term>endpoint</term>
      <listitem>
       <para>
        Especifica el puesto final del servidor de Elasticsearch al que se accede.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>num_shards</term>
      <listitem>
       <para>
        <emphasis>(número entero)</emphasis> El número de particiones con las que se configurará Elasticsearch al inicializar la sincronización de datos. Tenga en cuenta que este valor no se puede cambiar después de la inicialización. Cualquier cambio que se haga aquí requiere que se vuelva a crear el índice de Elasticsearch y se reinicialice el proceso de sincronización de datos.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>num_replicas</term>
      <listitem>
       <para>
        <emphasis>(número entero)</emphasis> El número de réplicas con las que se configurará Elasticsearch al inicializar la sincronización de datos.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>explicit_custom_meta</term>
      <listitem>
       <para>
        <emphasis>(true | false)</emphasis> Especifica si se indexarán todos los metadatos personalizados del usuario, o si el usuario deberá configurar (en el nivel de depósitos) las entradas de metadatos del cliente que se deben indexar. La opción por defecto es "false" (falso).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>index_buckets_list</term>
      <listitem>
       <para>
        <emphasis>(lista de cadenas separadas por comas)</emphasis> Si está vacío, todos los depósitos se indexarán. De lo contrario, solo se indexarán los depósitos que se especifiquen aquí. Es posible proporcionar prefijos de depósito (por ejemplo, "foo*") o sufijos de depósito (por ejemplo, "*bar").
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>approved_owners_list</term>
      <listitem>
       <para>
        <emphasis>(lista de cadenas separadas por comas)</emphasis> Si está vacío, se indexarán los depósitos de todos los propietarios (esto está sujeto a otras restricciones). En caso contrario, se indexarán solo los depósitos de los propietarios especificados. También es posible proporcionar prefijos y sufijos.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>override_index_path</term>
      <listitem>
       <para>
        <emphasis>(cadena) </emphasis> Si no está vacío, esta cadena se utilizará como la vía de índice de elasticsearch. De lo contrario, la vía de índice se determinará y se generará durante la inicialización de la sincronización.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-rgw-sync-elastic-query">
    <title>Consultas de metadatos</title>
    <para>
     Dado que el clúster de Elasticsearch almacena ahora metadatos de objeto, es importante que el puesto final de Elasticsearch no esté expuesto al público y solo puedan acceder los administradores de clúster. Exponer las consultas de metadatos a los usuarios finales plantea un problema, ya que queremos que los usuarios solo puedan consultar sus propios metadatos y no los de otros usuarios. Esto último requeriría que el clúster de Elasticsearch autenticara a los usuarios de forma similar a como lo hace RGW, lo que supone un problema .
    </para>
    <para>
     A partir de la versión Luminous, la instancia de RGW de la zona principal de metadatos puede atender a las peticiones del usuario final. De este modo, no se expone el puesto final de Elasticsearch al público y también se resuelve el problema de la autenticación y la autorización, ya que RGW realiza estas labores para las peticiones del usuario final. Por este motivo, RGW presenta una nueva consulta en las API de depósito que pueden atender las peticiones de Elasticsearch. Todas estas peticiones deben enviarse a la zona principal de metadatos.
    </para>
    <variablelist>
     <varlistentry>
      <term>Cómo obtener una consulta de Elasticsearch</term>
      <listitem>
<screen>
GET /<replaceable>BUCKET</replaceable>?query={query-expr}
       </screen>
       <para>
        Parámetros de la petición:
       </para>
       <itemizedlist>
        <listitem>
         <para>
          max-keys: el número máximo de entradas que se deben devolver.
         </para>
        </listitem>
        <listitem>
         <para>
          marker: el marcador de paginación.
         </para>
        </listitem>
       </itemizedlist>
<screen>
expression := [(]&lt;arg&gt; &lt;op&gt; &lt;value&gt; [)][&lt;and|or&gt; ...]
       </screen>
       <para>
        El operador "op" es uno de los siguientes: &lt;, &lt;=, ==, &gt;=, &gt;
       </para>
       <para>
        Por ejemplo:
       </para>
<screen>
GET /?query=name==foo
       </screen>
       <para>
        devolverá todas las claves indexadas para las que el usuario tiene permiso de lectura y que tienen como nombre "foo". El resultado será una lista de claves en formato XML similar a la respuesta de lista de depósitos de S3.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Cómo configurar campos de metadatos personalizados</term>
      <listitem>
       <para>
        Defina las entradas de metadatos personalizados que se deben indexar (en el depósito especificado) y cuáles son los tipos de estas claves. Si se ha configurado el indexado explícito de metadatos personalizados, esto es obligatorio para que rgw indexe los valores de los metadatos personalizados especificados. También es necesario en casos en los que las claves de metadatos indexadas sean de un tipo distinto a cadena.
       </para>
<screen>
POST /<replaceable>BUCKET</replaceable>?mdsearch
x-amz-meta-search: &lt;key [; type]&gt; [, ...]
       </screen>
       <para>
        Si hay varios campos de metadatos, deben separarse con comas. Es posible aplicar un tipo para un campo con punto y coma ";". Los tipos permitidos actualmente son cadenas (opción por defecto), números enteros y fechas; es decir, si desea indexar el metadato de objeto personalizado x-amz-meta-year como número entero, x-amz-meta-date como fecha y x-amz-meta-title como cadena, debe hacer lo siguiente:
       </para>
<screen>
POST /mybooks?mdsearch
x-amz-meta-search: x-amz-meta-year;int, x-amz-meta-release-date;date, x-amz-meta-title;string
       </screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Cómo suprimir una configuración personalizada de metadatos</term>
      <listitem>
       <para>
        Puede suprimir una configuración personalizada de metadatos.
       </para>
<screen>
DELETE /<replaceable>BUCKET</replaceable>?mdsearch
       </screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Cómo obtener una configuración personalizada de metadatos</term>
      <listitem>
       <para>
        Puede recuperar una configuración personalizada de metadatos.
       </para>
<screen>
GET /<replaceable>BUCKET</replaceable>?mdsearch
       </screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-ldap">
  <title>Autenticación LDAP</title>

  <para>
   Aparte de la autenticación de usuario local por defecto, Object Gateway también puede utilizar servicios del servidor LDAP para autenticar a los usuarios.
  </para>

  <sect2 xml:id="ceph-rgw-ldap-how-works">
   <title>Mecanismo de autenticación</title>
   <para>
    Object Gateway extrae las credenciales LDAP del usuario de un testigo. Se construye un filtro de búsqueda a partir del nombre de usuario. Object Gateway utiliza la cuenta del servicio configurado para buscar una entrada que coincida en el directorio. Si se encuentra una entrada, Object Gateway intenta vincularse al nombre completo encontrado con la contraseña del testigo. Si las credenciales son válidas, la vinculación se realizará correctamente y Object Gateway otorgará acceso.
   </para>
   <para>
    Puede limitar los usuarios permitidos estableciendo como base para la búsqueda una unidad organizativa específica o especificando un filtro de búsqueda personalizado; por ejemplo, un filtro que requiera la pertenencia a un grupo específico, clases de objetos personalizados o atributos.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-reqs">
   <title>Requisitos</title>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis>LDAP o Active Directory:</emphasis> una instancia de LDAP en ejecución a la que Object Gateway pueda acceder.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Cuenta de servicio:</emphasis> credenciales LDAP que utilizará Object Gateway con los permisos de búsqueda.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Cuenta de usuario:</emphasis> al menos una cuenta de usuario en el directorio LDAP.
     </para>
    </listitem>
   </itemizedlist>
   <important>
    <title>LDAP y los usuarios locales no se deben solapar</title>
    <para>
     No debe utilizar los mismos nombres de usuario para los usuarios locales y los usuarios que se van a autenticar mediante LDAP. Object Gateway no puede distinguirlos y los trata como el mismo usuario.
    </para>
   </important>
   <tip>
    <title>comprobaciones de estado</title>
    <para>
     Emplee la utilidad <command>ldapsearch</command> para verificar la cuenta de servicio o la conexión LDAP. Por ejemplo:
    </para>
<screen>ldapsearch -x -D "uid=ceph,ou=system,dc=example,dc=com" -W \
-H ldaps://example.com -b "ou=users,dc=example,dc=com" 'uid=*' dn</screen>
    <para>
     Asegúrese de utilizar los mismos parámetros LDAP del archivo de configuración de Ceph para eliminar posibles problemas.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-config">
   <title>Configuración de Object Gateway para utilizar la autenticación LDAP</title>
   <para>
    Los siguientes parámetros del archivo de configuración <filename>/etc/ceph/ceph.conf</filename> están relacionados con la autenticación LDAP:
   </para>
   <variablelist>
    <varlistentry>
     <term><option>rgw_ldap_uri</option>
     </term>
     <listitem>
      <para>
       Especifica el servidor LDAP que se debe usar. Asegúrese de usar el parámetro <literal>ldaps://<replaceable>fqdn</replaceable>:<replaceable>puerto</replaceable></literal> para evitar la transmisión de credenciales de forma abierta en formato de texto sin cifrar.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_binddn</option>
     </term>
     <listitem>
      <para>
       El nombre completo (DN) de la cuenta de servicio que utiliza Object Gateway.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_secret</option>
     </term>
     <listitem>
      <para>
       La contraseña de la cuenta de servicio.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>rgw_ldap_searchdn</term>
     <listitem>
      <para>
       Especifica la base en el árbol de información del directorio para buscar usuarios. Puede tratarse de la unidad organizativa de los usuarios o alguna unidad organizativa (OU) más específica.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_dnattr</option>
     </term>
     <listitem>
      <para>
       El atributo que se utiliza en el filtro de búsqueda construido para que coincida con un nombre de usuario. Dependiendo de su árbol de información de directorio (DIT), probablemente será <literal>uid</literal> o <literal>cn</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_search_filter</option>
     </term>
     <listitem>
      <para>
       Si no se especifica, Object Gateway crea automáticamente el filtro de búsqueda con el valor <option>rgw_ldap_dnattr</option>. Este parámetro se puede usar para restringir la lista de usuarios permitidos de formas muy flexibles. Consulte la <xref linkend="ceph-rgw-ldap-filter"/> para obtener más información.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-filter">
   <title>Uso de un filtro de búsqueda personalizado para limitar el acceso de usuario</title>
   <para>
    Existen dos formas de utilizar el parámetro <option>rgw_search_filter</option>.
   </para>
   <sect3>
    <title>Filtro parcial para restringir aún más el filtro de búsqueda construido</title>
    <para>
     Un ejemplo de un filtro parcial:
    </para>
<screen>"objectclass=inetorgperson"</screen>
    <para>
     Object Gateway generará el filtro de búsqueda de la forma habitual con el nombre de usuario tomado del testigo y el valor de <option>rgw_ldap_dnattr</option>. El filtro construido se combina a continuación con el filtro parcial del atributo <option>rgw_search_filter</option>. Según el nombre de usuario y la configuración, el filtro de búsqueda final puede ser:
    </para>
<screen>"(&amp;(uid=hari)(objectclass=inetorgperson))"</screen>
    <para>
     En este caso, solo se otorgará acceso al usuario "hari" si se encuentra en el directorio LDAP, tiene la clase de objeto "inetorgperson" y ha especificado una contraseña válida.
    </para>
   </sect3>
   <sect3>
    <title>Filtro completo</title>
    <para>
     Un filtro completo debe contener un testigo <option>USERNAME</option> que se sustituirá por el nombre de usuario durante el intento de autenticación. El parámetro <option>rgw_ldap_dnattr</option> ya no se usa en este caso. Por ejemplo, para limitar los usuarios válidos a un grupo específico, utilice el filtro siguiente:
    </para>
<screen>"(&amp;(uid=USERNAME)(memberOf=cn=ceph-users,ou=groups,dc=mycompany,dc=com))"</screen>
    <note>
     <title>atributo <literal>memberOf</literal></title>
     <para>
      Para poder usar el atributo <literal>memberOf</literal> en las búsquedas LDAP se requiere compatibilidad en el servidor LDAP específico implementado.
     </para>
    </note>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-token">
   <title>Generación de un testigo de acceso para la autenticación LDAP</title>
   <para>
    La utilidad <command>radosgw-token</command> genera el testigo de acceso en función del nombre de usuario y la contraseña LDAP. Cree una cadena codificada en base 64 que es el testigo de acceso real. Utilice su cliente de S3 favorito (consulte la <xref linkend="accessing-ragos-gateway"/>) y especifique el testigo como clave de acceso y utilice una clave de secreto vacía.
   </para>
<screen><prompt>root@minion &gt; </prompt>export RGW_ACCESS_KEY_ID="<replaceable>username</replaceable>"
<prompt>root@minion &gt; </prompt>export RGW_SECRET_ACCESS_KEY="<replaceable>password</replaceable>"
<prompt>root@minion &gt; </prompt>radosgw-token --encode --ttype=ldap</screen>
   <important>
    <title>credenciales en texto no cifrado</title>
    <para>
     El testigo de acceso es una estructura JSON codificada en base 64 y contiene las credenciales LDAP en texto sin cifrar.
    </para>
   </important>
   <note>
    <title>Active Directory </title>
    <para>
     Para Active Directory, utilice el parámetro <option>--type=ad</option>.
    </para>
   </note>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-bucket-sharding">
  <title>Partición del índice de depósito</title>

  <para>
   Object Gateway almacena los datos del índice de depósito en un repositorio de índice, que usa por defecto <literal>.rgw.buckets.index</literal>. Si coloca demasiados objetos (cientos de miles) en un único depósito y no se define la cuota del número máximo de objetos por depósito (<option>rgw bucket default quota max objects</option>), el rendimiento del repositorio de índice se puede degradar. La <emphasis>partición del índice de depósito</emphasis> evita esa disminución del rendimiento y permite un número elevado de objetos por depósito.
  </para>

  <sect2 xml:id="ogw-bucket-reshard">
   <title>Nueva partición del índice de depósito</title>
   <para>
    Si un depósito ha crecido mucho y su configuración inicial ya no es suficiente, es preciso volver a partir el repositorio de índice del depósito. Se puede usar la partición de índice de depósito en línea automática (consulte la <xref linkend="ogw-bucket-sharding-dyn"/>, o partir el índice de depósito manualmente sin conexión (consulte la <xref linkend="ogw-bucket-sharding-re"/>).
   </para>
   <sect3 xml:id="ogw-bucket-sharding-dyn">
    <title>Partición dinámica</title>
    <para>
     Desde SUSE Enterprise Storage 5, se admite la partición de depósito en línea. Detecta si el número de objetos por depósito alcanza un umbral determinado y aumenta automáticamente el número de particiones utilizado por el índice de depósito. Este proceso reduce el número de entradas de cada partición de índice de depósito.
    </para>
    <para>
     El proceso de detección se ejecuta en estos casos:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Cuando se añaden nuevos objetos al depósito.
      </para>
     </listitem>
     <listitem>
      <para>
       En un proceso en segundo plano que explora periódicamente todos los depósitos. Esto es necesario para tratar con los depósitos existentes que no se van a actualizar.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Si un depósito requiere partición, se añade a la cola <option>reshard_log</option> y se programa para su partición más tarde. Los hilos de partición se ejecutan en segundo plano y ejecutan la partición programada de una en una.
    </para>
    <variablelist>
     <title>Configuración de la partición dinámica</title>
     <varlistentry>
      <term><option>rgw_dynamic_resharding</option>
      </term>
      <listitem>
       <para>
        Habilita o inhabilita la partición del índice de depósito dinámica. Los valores válidos son "true" (verdadero) o "false" (falso). Por defecto es "true" (verdadero).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_num_logs</option>
      </term>
      <listitem>
       <para>
        El número de particiones para el registro. Se usa el valor por defecto de 16.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_bucket_lock_duration</option>
      </term>
      <listitem>
       <para>
        Duración del bloqueo en el objeto de depósito durante la partición. Se usa el valor por defecto de 120 segundos.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_max_objs_per_shard</option>
      </term>
      <listitem>
       <para>
        El número máximo de objetos por partición de índice de depósito. Por defecto es 100 000 objetos.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_thread_interval</option>
      </term>
      <listitem>
       <para>
        El tiempo máximo entre las rondas de procesamiento de hilos de partición. Se usa el valor por defecto de 600 segundos.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <important>
     <title>configuraciones de varios sitios</title>
     <para>
      La partición dinámica no se admite en entornos de varios sitios. Está inhabilitada por defecto desde Ceph 12.2.2, pero se recomienda volver a comprobar el ajuste.
     </para>
    </important>
    <variablelist>
     <title>Comandos para administrar el proceso de partición</title>
     <varlistentry>
      <term>Añadir un depósito a la cola de partición:</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard add \
 --bucket <replaceable>BUCKET_NAME</replaceable> \
 --num-shards <replaceable>NEW_NUMBER_OF_SHARDS</replaceable>
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Mostrar la cola de partición:</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard list
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Procesar o programar una partición de depósito:</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard process
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Mostrar el estado de partición del depósito:</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard status --bucket <replaceable>BUCKET_NAME</replaceable>
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Cancelar las particiones de depósito pendientes:</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard cancel --bucket <replaceable>BUCKET_NAME</replaceable>
</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ogw-bucket-sharding-re">
    <title>Partición manual</title>
    <para>
     La partición dinámica mencionada en la <xref linkend="ogw-bucket-sharding-dyn"/> solo se admite en configuraciones sencilla de Object Gateway. Para las configuraciones de varios sitios, utilice la partición manual que se describe en esta sección.
    </para>
    <para>
     Para particionar manualmente el índice de depósito sin conexión, utilice el comando siguiente:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin bucket reshard
</screen>
    <para>
     El comando <command>bucket reshard</command> realiza las acciones siguientes:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Crea un nuevo conjunto de objetos de índice de depósito para el objeto especificado.
      </para>
     </listitem>
     <listitem>
      <para>
       Distribuye todas las entradas de objetos de estos objetos de índice.
      </para>
     </listitem>
     <listitem>
      <para>
       Crea una nueva instancia del depósito.
      </para>
     </listitem>
     <listitem>
      <para>
       Enlaza la nueva instancia del depósito con el depósito para que todas las operaciones de índice nuevas pasen por los nuevos índices de depósito.
      </para>
     </listitem>
     <listitem>
      <para>
       Imprime el ID de depósito antiguo y el nuevo en una salida estándar.
      </para>
     </listitem>
    </itemizedlist>
    <procedure>
     <title>Partición del repositorio de índice de depósito</title>
     <step>
      <para>
       Asegúrese de que se han detenido todas las operaciones dirigidas al depósito.
      </para>
     </step>
     <step>
      <para>
       Realice una copia de seguridad del índice de depósito original:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin bi list \
 --bucket=<replaceable>BUCKET_NAME</replaceable> \
 &gt; <replaceable>BUCKET_NAME</replaceable>.list.backup
</screen>
     </step>
     <step>
      <para>
       Vuelva a particionar el índice de depósito:
      </para>
<screen>
 <prompt>root@minion &gt; </prompt>radosgw-admin reshard \
 --bucket=<replaceable>BUCKET_NAME</replaceable> \
 --num-shards=<replaceable>NEW_SHARDS_NUMBER</replaceable>
</screen>
      <tip>
       <title>ID de depósito antiguo</title>
       <para>
        Como parte del resultado, este comando también imprime los ID nuevo y antiguo. Anote el ID de depósito antiguo: lo necesitará para limpiar los objetos de índice de depósito antiguos.
       </para>
      </tip>
     </step>
     <step>
      <para>
       Verifique que los objetos se muestran correctamente comparando la lista del índice de depósito antiguo con la nueva. A continuación, limpie los objetos de índice de depósito antiguos:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin bi purge
 --bucket=<replaceable>BUCKET_NAME</replaceable>
 --bucket-id=<replaceable>OLD_BUCKET_ID</replaceable>
</screen>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="ogw-bucket-sharding-new">
   <title>Partición de índice de depósito para depósitos nuevo</title>
   <para>
    Existen dos opciones que afectan a la partición de índice de depósito:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Utilice la opción <option>rgw_override_bucket_index_max_shards</option> para las configuraciones sencillas.
     </para>
    </listitem>
    <listitem>
     <para>
      Utilice la opción <option>bucket_index_max_shards</option> para las configuraciones de varios sitios.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Si se define el valor <literal>0</literal> en las opciones, se inhabilita la partición de índice de depósito. Un valor mayor que <literal>0</literal> permite la partición de índice de depósito y establece el número máximo de particiones.
   </para>
   <para>
    La fórmula siguiente le permitirá calcular el número recomendado de particiones:
   </para>
<screen>
number_of_objects_expected_in_a_bucket / 100000
</screen>
   <para>
    Tenga en cuenta que el número máximo de particiones es de 7877.
   </para>
   <sect3>
    <title>Configuraciones sencillas</title>
    <procedure>
     <step>
      <para>
       Abra el archivo de configuración de Ceph y añada o modifique la siguiente opción:
      </para>
<screen>
rgw_override_bucket_index_max_shards = 12
</screen>
      <tip>
       <title>todas las instancias de Object Gateway o solo una</title>
       <para>
        Para configurar la partición de índice de depósito para todas las instancias de Object Gateway, incluya <option>rgw_override_bucket_index_max_shards</option> en la sección <literal>[global]</literal>.
       </para>
       <para>
        Para configurar la partición de índice de depósito solo para una instancia concreta de Object Gateway, incluya <option>rgw_override_bucket_index_max_shards</option> en la sección oportuna de la instancia.
       </para>
      </tip>
     </step>
     <step>
      <para>
       Reinicie Object Gateway. Consulte la <xref linkend="ceph-rgw-operating"/> para obtener más información.
      </para>
     </step>
    </procedure>
   </sect3>
   <sect3>
    <title>Configuraciones de varios sitios</title>
    <para>
     Las configuraciones de varios sitios pueden tener un repositorio de índice diferente para gestionar el failover. Para configurar un número de particiones coherente para las zonas de un grupo de zonas, defina la opción <option>bucket_index_max_shards</option> en la configuración del grupo de zonas:
    </para>
    <procedure>
     <step>
      <para>
       Exporte la configuración del grupo de zonas al archivo <filename>zonegroup.json</filename>:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin zonegroup get &gt; zonegroup.json
</screen>
     </step>
     <step>
      <para>
       Edite el archivo <filename>zonegroup.json</filename> y defina la opción <option>bucket_index_max_shards</option> para cada zona con nombre.
      </para>
     </step>
     <step>
      <para>
       Restablezca el grupo de zonas:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin zonegroup set &lt; zonegroup.json
</screen>
     </step>
     <step>
      <para>
       Actualice el período:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin period update --commit
</screen>
     </step>
    </procedure>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-keystone">
  <title>Integración de OpenStack Keystone</title>

  <para>
   OpenStack Keystone es un servicio de identidad para el producto OpenStack. Puede integrar Object Gateway con Keystone a fin de configurar una pasarela que acepte un testigo de autenticación de Keystone. Un usuario autorizado por Keystone para acceder a la pasarela se verificará en Ceph Object Gateway y, si fuera necesario, se creará automáticamente. Object Gateway pide periódicamente a Keystone una lista de los testigos revocados.
  </para>

  <sect2 xml:id="ogw-keystone-ostack">
   <title>Configuración de OpenStack</title>
   <para>
    Antes de configurar Ceph Object Gateway, debe configurar OpenStack Keystone para habilitar el servicio de Swift y dirigirlo a Ceph Object Gateway:
   </para>
   <procedure>
    <step>
     <para>
      <emphasis>Defina el servicio de Swift.</emphasis>Para utilizar OpenStack a fin de validar usuarios de Swift, cree primero el servicio de Swift:
     </para>
<screen>
<prompt>root # </prompt>openstack service create \
 --name=swift \
 --description="Swift Service" \
 object-store
</screen>
    </step>
    <step>
     <para>
      <emphasis>Defina los puestos finales.</emphasis>Después de crear el servicio de Swift, diríjalo a Ceph Object Gateway. Sustituya <replaceable>REGION_NAME</replaceable> por el nombre del grupo de zonas o el nombre de la región de la pasarela.
     </para>
<screen>
<prompt>root # </prompt>openstack endpoint create --region <replaceable>REGION_NAME</replaceable> \
 --publicurl   "http://radosgw.example.com:8080/swift/v1" \
 --adminurl    "http://radosgw.example.com:8080/swift/v1" \
 --internalurl "http://radosgw.example.com:8080/swift/v1" \
 swift
</screen>
    </step>
    <step>
     <para>
      <emphasis>Verifique los ajustes.</emphasis>Después de crear el servicio de Swift y definir los puestos finales, muestre los puestos finales para verificar que todos los valores son correctos.
     </para>
<screen>
<prompt>root # </prompt>openstack endpoint show object-store
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw-keystone-ogw">
   <title>Configuración de Ceph Object Gateway</title>
   <sect3>
    <title>Configuración de certificados SSL</title>
    <para>
     Ceph Object Gateway pide periódicamente a Keystone una lista de los testigos revocados. Estas peticiones están codificadas y firmadas. Keystone también puede configurarse para que proporcione testigos autofirmados, que también están codificados y firmados. Debe configurar la pasarela para que pueda descodificar y verificar estos mensajes firmados. Por lo tanto, los certificados OpenSSL que Keystone utiliza para crear las peticiones deben convertirse al formato "nss db":
    </para>
<screen>
<prompt>root # </prompt>mkdir /var/ceph/nss
<prompt>root # </prompt>openssl x509 -in /etc/keystone/ssl/certs/ca.pem \
 -pubkey | certutil -d /var/ceph/nss -A -n ca -t "TCu,Cu,Tuw"
<systemitem class="username">root</systemitem>openssl x509 -in /etc/keystone/ssl/certs/signing_cert.pem \
 -pubkey | certutil -A -d /var/ceph/nss -n signing_cert -t "P,P,P"
</screen>
    <para>
     OpenStack Keystone también se puede interrumpir con un certificado SSL autofirmado, a fin de que Ceph Object Gateway pueda interactuar con Keystone. Instale el certificado SSL de Keystone en el nodo donde se ejecuta Ceph Object Gateway o, de forma alternativa, defina el valor de la opción <option>rgw keystone verify ssl</option> como "false" (falso). Si define <option>rgw keystone verify ssl</option> como "false", la pasarela no intentará verificar el certificado.
    </para>
   </sect3>
   <sect3>
    <title>Configuración de las opciones de Object Gateway</title>
    <para>
     Puede configurar la integración de Keystone utilizando las siguientes opciones:
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone api version</option>
      </term>
      <listitem>
       <para>
        Versión de la API de Keystone. Las opciones válidas son 2 o 3. Se usa el valor por defecto de 2.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone url</option>
      </term>
      <listitem>
       <para>
        La URL y el número de puerto de la API RESTful administrativa en el servidor de Keystone. Sigue el patrón <replaceable>URL_SERVIDOR:NÚMERO_PUERTO</replaceable>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin token</option>
      </term>
      <listitem>
       <para>
        El testigo o secreto compartido que se configura internamente en Keystone para las peticiones administrativas.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone accepted roles</option>
      </term>
      <listitem>
       <para>
        Las funciones necesarias para atender las peticiones. Por defecto es "Member, admin".
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone accepted admin roles</option>
      </term>
      <listitem>
       <para>
        La lista de funciones que permiten a un usuario obtener privilegios administrativos.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone token cache size</option>
      </term>
      <listitem>
       <para>
        El número máximo de entradas en el caché de testigo de Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone revocation interval</option>
      </term>
      <listitem>
       <para>
        El número de segundos antes de comprobar los testigos revocados. Por defecto es 15 * 60.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone implicit tenants</option>
      </term>
      <listitem>
       <para>
        Crea nuevos usuarios en sus propios inquilinos del mismo nombre. Se usa el valor por defecto, "false" (falso).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw s3 auth use keystone</option>
      </term>
      <listitem>
       <para>
        Si se establece como "true" (verdadero), Ceph Object Gateway autenticará a los usuarios mediante Keystone. Se usa el valor por defecto, "false" (falso).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>nss db path</option>
      </term>
      <listitem>
       <para>
        La vía a la base de datos NSS.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     También es posible configurar el inquilino del servicio de Keystone, el usuario y la contraseña para Keystone (para la versión 2.0 de la API de identidades de OpenStack), de modo similar a cómo se suelen configurar los servicios de OpenStack. De este modo, puede evitar establecer el secreto compartido <option>rgw keystone admin token</option> en el archivo de configuración, que se debe inhabilitar en entornos de producción. Las credenciales del inquilino del servicio deberían tener privilegios de administrador. Para obtener más información, consulte la <link xlink:href="https://docs.openstack.org/keystone/latest/#setting-up-projects-users-and-roles">documentación oficial de OpenStack Keystone</link>. A continuación se muestran las opciones de configuración relacionadas:
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone admin user</option>
      </term>
      <listitem>
       <para>
        El nombre de usuario del administrador de Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin password</option>
      </term>
      <listitem>
       <para>
        La contraseña del usuario administrador de Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin tenant</option>
      </term>
      <listitem>
       <para>
        El inquilino del usuario administrador de Keystone versión 2.0.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Se asigna un usuario de Ceph Object Gateway a un inquilino de Keystone. Un usuario de Keystone tiene diferentes funciones asignadas, posiblemente en más de un único inquilino. Cuando Ceph Object Gateway obtiene el ticket, busca en las funciones de inquilino y usuario que se han asignado a dicho ticket y acepta o rechaza la petición de acuerdo con el valor de la opción <option>rgw keystone accepted roles</option>.
    </para>
    <tip>
     <title>asignación a inquilinos de OpenStack</title>
     <para>
      Aunque los inquilinos de Swift se asignan por defecto al usuario de Object Gateway, también pueden asignarse a inquilinos de OpenStack mediante la opción <option>rgw keystone implicit tenants</option>. Esto hará que los contenedores usen el espacio de nombres del inquilino en lugar del espacio de nombres global de S3, que es la opción por defecto de Object Gateway. Se recomienda decidir de antemano el método de asignación en la fase de planificación para evitar confusiones. La razón es que si se cambia la opción más tarde, solo se verán afectadas las peticiones nuevas que se asignen bajo un inquilino, mientras que los depósitos antiguos creados anteriormente seguirán en el espacio de nombres global.
     </para>
    </tip>
    <para>
     En la versión 3 de la API de identidades de OpenStack, deber sustituir la opción <option>rgw keystone admin tenant</option> por:
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone admin domain</option>
      </term>
      <listitem>
       <para>
        El dominio de usuario administrador de Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin project</option>
      </term>
      <listitem>
       <para>
        El proyecto de usuario administrador de Keystone.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-fed">


  <title>Pasarelas Object Gateway de varios sitios</title>

  <variablelist>
   <varlistentry>
    <term>Zona</term>
    <listitem>
     <para>
      Una agrupación lógica de una o varias instancias de Object Gateway. Debe haber una zona designada como zona <emphasis>principal</emphasis> en un <emphasis>grupo de zonas</emphasis> que gestionará toda la creación de depósitos y usuarios.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Grupo de zonas</term>
    <listitem>
     <para>
      Un grupo de zonas es un conjunto de varias zonas. Debe haber un grupo de zonas principal que gestionará los cambios de la configuración del sistema.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Mapa de grupo de zonas</term>
    <listitem>
     <para>
      Una estructura de configuración que contiene el mapa de todo el sistema; por ejemplo, qué grupo de zonas es el principal, las relaciones entre distintos grupos de zonas y ciertas opciones de configuración, como las directivas de almacenamiento.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Dominio</term>
    <listitem>
     <para>
      Un contenedor para grupos de zonas. Esto permite la separación de grupos de zonas entre los clústeres. Es posible crear varios dominios para que sea más fácil ejecutar configuraciones completamente distintas en el mismo clúster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Período</term>
    <listitem>
     <para>
      Un período guarda la estructura de configuración para el estado actual del dominio. Cada período contiene un ID único y una época. Cada dominio tiene un período actual asociado, que contiene el estado actual de la configuración de los grupos de zonas y las directivas de almacenamiento. Cualquier cambio de configuración para una zona principal incrementará la época del período. Si se cambia la zona principal a una zona diferente, se activan los siguientes cambios:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Se genera un nuevo período con un nuevo ID de período y la época 1.
       </para>
      </listitem>
      <listitem>
       <para>
        El período actual del dominio se actualiza para que señale al ID de período recién generado.
       </para>
      </listitem>
      <listitem>
       <para>
        La época del dominio se incrementa.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Puede configurar cada Object Gateway para que participe en una arquitectura federada, en la que trabaja en una configuración de zona activa y permite la escritura en zonas no principales.
  </para>

  <sect2 xml:id="ceph-rgw-fed-term">
   <title>Terminología</title>
   <para>
    A continuación se muestra una descripción de los términos específicos de una arquitectura federada:
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-intro">
   <title>Configuración de clúster de ejemplo</title>
   <para>
    En este ejemplo nos centraremos en la creación de un único grupo de zonas con tres zonas independiente que sincronizan sus datos de forma activa. Dos zonas pertenecen al mismo clúster, mientras que la tercera pertenece a otro diferente. No hay ningún agente de sincronización implicado en la duplicación de los cambios de datos entre las pasarelas Object Gateway. Esto permite un esquema de configuración mucho más sencillo y configuraciones de tipo activa-activa. Tenga en cuenta que las operaciones de metadatos, como crear un usuario nuevo, aún deben realizarse a través de la zona principal. Sin embargo, las operaciones de datos, como la creación de depósitos y objetos, se pueden gestionar en cualquiera de las zonas.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-keys">
   <title>Claves del sistema</title>
   <para>
    Durante la configuración de las zonas, Object Gateway espera que se cree un usuario de sistema compatible con S3 junto con sus claves de acceso y de secreto. Esto permite a otra instancia de Object Gateway extraer la configuración de forma remota con las claves de acceso y de secreto. Para obtener más información sobre cómo crear usuarios de S3, consulte la <xref linkend="adding-s3-swift-users"/>.
   </para>
   <tip>
    <para>
     Resulta útil para generar las claves de acceso y de secreto antes de crear la propia zona, ya que se facilita la creación de guiones y el uso de herramientas de gestión de configuraciones más adelante.
    </para>
   </tip>
   <para>
    Para este ejemplo, supongamos que las claves de acceso y de secreto están definidas en las variables de entorno:
   </para>
<screen># SYSTEM_ACCESS_KEY=1555b35654ad1656d805
# SYSTEM_SECRET_KEY=h7GhxuBLTrlhVUyxSPUKUV8r/2EI4ngqJxD7iBdBYLhwluN30JaT3Q==</screen>
   <para>
    Por lo general, las claves de acceso están formadas por 20 caracteres alfanuméricos, mientras que las claves de secreto constan de 40 caracteres alfanuméricos (pueden contener también los caracteres +/=). Estas claves se pueden generar en la línea de comandos:
   </para>
<screen># SYSTEM_ACCESS_KEY=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 20 | head -n 1)
# SYSTEM_SECRET_KEY=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 40 | head -n 1)</screen>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-naming">
   <title>Convenciones de denominación</title>
   <para>
    Este ejemplo describe el proceso de configuración de una zona principal. Partiremos de un grupo de zonas denominado <literal>us</literal> que abarca los Estados Unidos, que serán nuestro grupo de zonas principal. Contendrá dos zonas con el formato <replaceable>grupodezonas</replaceable>-<replaceable>zona</replaceable>. Esto es simplemente una convención que se usa para este ejemplo, pero puede elegir el formato que prefiera. En resumen:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Grupo de zonas principal: Estados Unidos <literal>us</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      Zona principal: Estados Unidos, región Este 1: <literal>us-east-1</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      Zona secundaria: Estados Unidos, región Este 2: <literal>us-east-2</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      Zona secundaria: Estados Unidos, región Oeste: <literal>us-west</literal>
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Todo esto formará parte de un dominio mayor denominado <literal>gold</literal>. Las zonas <literal>us-east-1</literal> y <literal>us-east-2</literal> forman parte del mismo clúster de Ceph, <literal>us-east-1</literal> es la principal. <literal>us-west</literal> está en un clúster de Ceph diferente.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-pools">
   <title>Repositorios por defecto</title>
   <para>
    Si se ha configurado con los permisos apropiados, Object Gateway crea repositorios por defecto por sí misma. Los valores <literal>pg_num</literal> y <literal>pgp_num</literal> se toman del archivo de configuración <filename>ceph.conf</filename>. Los repositorios relacionados con una zona, siguen por defecto la convención <replaceable>nombre-zona</replaceable>.<replaceable>nombre-repositorio</replaceable>. Por ejemplo para la zona <literal>us-east-1</literal>, serán los repositorios siguientes:
   </para>
<screen>.rgw.root
us-east-1.rgw.control
us-east-1.rgw.data.root
us-east-1.rgw.gc
us-east-1.rgw.log
us-east-1.rgw.intent-log
us-east-1.rgw.usage
us-east-1.rgw.users.keys
us-east-1.rgw.users.email
us-east-1.rgw.users.swift
us-east-1.rgw.users.uid
us-east-1.rgw.buckets.index
us-east-1.rgw.buckets.data
us-east-1.rgw.meta</screen>
   <para>
    Estos repositorios se pueden crear también en otras zonas; basta con sustituir <literal>us-east-1</literal> por el nombre de zona correspondiente.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-realm">
   <title>Creación de un dominio</title>
   <para>
    Configure un dominio denominado <literal>gold</literal> y conviértalo en el dominio por defecto:
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin realm create --rgw-realm=gold --default
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "epoch": 1
}</screen>
   <para>
    Tenga en cuenta que cada dominio tiene un ID, lo que aporta flexibilidad, por ejemplo si hay que cambiar el nombre del dominio más tarde. El valor de <literal>current_period</literal> cambia cada vez que se modifica algo en la zona principal. El valor de <literal>epoch</literal> aumenta cuando se produce un cambio en la configuración de la zona principal que provoque un cambio del periodo actual.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-deldefzonegrp">
   <title>Supresión del grupo de zonas por defecto</title>
   <para>
    La instalación por defecto de Object Gateway crea el grupo de zonas por defecto denominado <literal>default</literal>. Dado que ya no se necesita el grupo de zonas por defecto, elimínelo.
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup delete --rgw-zonegroup=default</screen>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-createmasterzonegrp">
   <title>Creación de un grupo de zonas principal</title>
   <para>
    Cree un grupo de zonas principal denominado <literal>us</literal>. Este grupo de zonas gestionará el mapa del grupo de zonas y propagará los cambios al resto del sistema. Si se marca el grupo de zonas como grupo por defecto, se permite explícitamente que se mencione el parámetro rgw-zonagroup en comandos posteriores.
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup create --rgw-zonegroup=us \
--endpoints=http://rgw1:80 --master --default
{
  "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "name": "us",
  "api_name": "us",
  "is_master": "true",
  "endpoints": [
      "http:\/\/rgw1:80"
  ],
  "hostnames": [],
  "hostnames_s3website": [],
  "master_zone": "",
  "zones": [],
  "placement_targets": [],
  "default_placement": "",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   <para>
    Si lo prefiere, puede marcar un grupo de zonas como grupo por defecto con el comando siguiente:
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup default --rgw-zonegroup=us</screen>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-masterzone">
   <title>Creación de una zona principal</title>
   <para>
    Cree ahora una zona por defecto y añádala al grupo de zonas por defecto. Tenga en cuenta que utilizará esta zona para las operaciones de metadatos, como la creación de usuarios:
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-1 \
--endpoints=http://rgw1:80 --access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable>
{
  "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "name": "us-east-1",
  "domain_root": "us-east-1/gc.rgw.data.root",
  "control_pool": "us-east-1/gc.rgw.control",
  "gc_pool": "us-east-1/gc.rgw.gc",
  "log_pool": "us-east-1/gc.rgw.log",
  "intent_log_pool": "us-east-1/gc.rgw.intent-log",
  "usage_log_pool": "us-east-1/gc.rgw.usage",
  "user_keys_pool": "us-east-1/gc.rgw.users.keys",
  "user_email_pool": "us-east-1/gc.rgw.users.email",
  "user_swift_pool": "us-east-1/gc.rgw.users.swift",
  "user_uid_pool": "us-east-1/gc.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-1/gc.rgw.buckets.index",
              "data_pool": "us-east-1/gc.rgw.buckets.data",
              "data_extra_pool": "us-east-1/gc.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-1/gc.rgw.meta",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   <para>
    Recuerde también que los parámetros <option>--rgw-zonagroup</option> y <option>--default</option> añaden la zona a un grupo de zonas y la convierten en la zona por defecto. Como alternativa, se puede hacer lo mismo con los comandos siguientes:
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone default --rgw-zone=us-east-1
<prompt>cephadm &gt; </prompt>radosgw-admin zonegroup add --rgw-zonegroup=us --rgw-zone=us-east-1</screen>
   <sect3 xml:id="ceph-rgw-fed-masterzone-createuser">
    <title>Creación de usuarios del sistema</title>
    <para>
     Para acceder a los repositorios de zona, debe crear un usuario del sistema. Tenga en cuenta que también necesitará estas claves cuando configure las zonas secundarias.
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin user create --uid=zone.user \
--display-name="Zone User" --access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> \
--secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable> --system</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-masterzone-updateperiod">
    <title>Actualización del período</title>
    <para>
     Puesto que ha cambiado la configuración de la zona principal, debe confirmar los cambios para que surtan efecto en la estructura de configuración del dominio. Inicialmente, el período tiene este aspecto:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period get
{
  "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "epoch": 1, "predecessor_uuid": "", "sync_status": [], "period_map":
  {
    "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "zonegroups": [], "short_zone_ids": []
  }, "master_zonegroup": "", "master_zone": "", "period_config":
  {
     "bucket_quota": {
     "enabled": false, "max_size_kb": -1, "max_objects": -1
     }, "user_quota": {
       "enabled": false, "max_size_kb": -1, "max_objects": -1
     }
  }, "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7", "realm_name": "gold", "realm_epoch": 1
}</screen>
    <para>
     Actualice el período y confirme los cambios:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 1,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }
              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          }
      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-masterzone-startrgw">
    <title>Inicio de Object Gateway</title>
    <para>
     Es necesario mencionar las opciones de zona y puerto de Object Gateway en el archivo de configuración antes de iniciar Object Gateway. Para obtener más información sobre Object Gateway y su configuración, consulte el <xref linkend="cha-ceph-gw"/>. La sección de configuración de Object Gateway debe ser parecida a esto:
    </para>
<screen>[client.rgw.us-east-1]
rgw_frontends="civetweb port=80"
rgw_zone=us-east-1</screen>
    <para>
     Inicie Object Gateway:
    </para>
<screen>sudo systemctl start ceph-radosgw@rgw.us-east-1</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-secondaryzone">
   <title>Creación de una zona secundaria</title>
   <para>
    En el mismo clúster, cree y configure la zona secundaria denominada <literal>us-east-2</literal>. Puede ejecutar los comandos siguientes en el nodo que aloja la zona principal.
   </para>
   <para>
    Para crear la zona secundaria, utilice el mismo comando que usó al crear la zona principal, pero no incluya el parámetro master:
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --endpoints=http://rgw2:80 \
--rgw-zone=us-east-2 --access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable>
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-east-2",
  "domain_root": "us-east-2.rgw.data.root",
  "control_pool": "us-east-2.rgw.control",
  "gc_pool": "us-east-2.rgw.gc",
  "log_pool": "us-east-2.rgw.log",
  "intent_log_pool": "us-east-2.rgw.intent-log",
  "usage_log_pool": "us-east-2.rgw.usage",
  "user_keys_pool": "us-east-2.rgw.users.keys",
  "user_email_pool": "us-east-2.rgw.users.email",
  "user_swift_pool": "us-east-2.rgw.users.swift",
  "user_uid_pool": "us-east-2.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-2.rgw.buckets.index",
              "data_pool": "us-east-2.rgw.buckets.data",
              "data_extra_pool": "us-east-2.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-2.rgw.meta",
  "realm_id": "815d74c2-80d6-4e63-8cfc-232037f7ff5c"
}</screen>
   <sect3 xml:id="ceph-rgw-fed-secondzone-updateperiod">
    <title>Actualización del período</title>
    <para>
     Informe a todas las pasarelas del nuevo cambio del mapa del sistema realizando una actualización del período y confirmando los cambios:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }

              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          }

      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-secondzone-startrgw">
    <title>Inicio de Object Gateway</title>
    <para>
     Ajuste la configuración de Object Gateway para la zona secundaria e iníciela:
    </para>
<screen>[client.rgw.us-east-2]
rgw_frontends="civetweb port=80"
rgw_zone=us-east-2</screen>
<screen><prompt>cephadm &gt; </prompt>sudo systemctl start ceph-radosgw@rgw.us-east-2</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-seccluster">
   <title>Adición de Object Gateway al segundo clúster</title>
   <para>
    El segundo clúster de Ceph pertenece al mismo grupo de zonas que el inicial, pero puede que esté ubicado en otro lugar geográfico.
   </para>
   <sect3 xml:id="ceph-rgw-fed-seccluster-realm">
    <title>Dominio y zona de grupos por defecto</title>
    <para>
     Dado que ya ha creado el dominio para la primera pasarela, extraiga el dominio aquí y conviértalo en el dominio por defecto:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin realm pull --url=http://rgw1:80 \
--access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable>
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2
}
<prompt>cephadm &gt; </prompt>radosgw-admin realm default --rgw-realm=gold</screen>
    <para>
     Obtenga la configuración de la zona principal extrayendo el período:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period pull --url=http://rgw1:80 \
--access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable></screen>
    <para>
     Defina el grupo de zonas por defecto en el grupo de zonas <literal>us</literal> existente:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup default --rgw-zonegroup=us</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-seccluster-seczone">
    <title>Configuración de la zona secundaria</title>
    <para>
     Cree una zona nueva denominada <literal>us-west</literal> con las mismas claves del sistema:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-west \
--access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable> \
--endpoints=http://rgw3:80 --default
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-west",
  "domain_root": "us-west.rgw.data.root",
  "control_pool": "us-west.rgw.control",
  "gc_pool": "us-west.rgw.gc",
  "log_pool": "us-west.rgw.log",
  "intent_log_pool": "us-west.rgw.intent-log",
  "usage_log_pool": "us-west.rgw.usage",
  "user_keys_pool": "us-west.rgw.users.keys",
  "user_email_pool": "us-west.rgw.users.email",
  "user_swift_pool": "us-west.rgw.users.swift",
  "user_uid_pool": "us-west.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-west.rgw.buckets.index",
              "data_pool": "us-west.rgw.buckets.data",
              "data_extra_pool": "us-west.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-west.rgw.meta",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-seccluster-period">
    <title>Actualización del período</title>
    <para>
     Para propagar los cambios del mapa de grupo de zonas, se actualiza y se confirma el período:
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period update --commit --rgw-zone=us-west
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 3,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [
      "", # truncated
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "d9522067-cb7b-4129-8751-591e45815b16",
                      "name": "us-west",
                      "endpoints": [
                          "http:\/\/rgw3:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }
              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          },
          {
              "key": "d9522067-cb7b-4129-8751-591e45815b16",
              "val": 329470157
          }
      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
    <para>
     Tenga en cuenta que el número de época del período ha aumentado, lo que indica un cambio en la configuración.
    </para>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-seccluster-rgwstart">
    <title>Inicio de Object Gateway</title>
    <para>
     Esto es similar a iniciar Object Gateway en la primera zona. La única diferencia es que la configuración de la zona de Object Gateway debe reflejar el nombre de zona <literal>us-west</literal>:
    </para>
<screen>[client.rgw.us-west]
rgw_frontends="civetweb port=80"
rgw_zone=us-west</screen>
    <para>
     Inicie la segunda pasarela Object Gateway:
    </para>
<screen>sudo systemctl start ceph-radosgw@rgw.us-west</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-fed-failover">
   <title>Failover y recuperación tras fallo</title>
   <para>
    Si la zona principal fallara, realice un failover a la zona secundaria para recuperarse tras los fallos.
   </para>
   <procedure>
    <step>
     <para>
      Convierta la zona secundaria en la zona principal y por defecto. Por ejemplo:
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --master --default
     </screen>
     <para>
      Por defecto, Ceph Object Gateway ejecuta una configuración activa-activa. Si el clúster se ha configurado para ejecutarse en una configuración activa-pasiva, la zona secundaria será una zona de solo lectura. Elimine el estado --read-only para permitir que la zona reciba operaciones de escritura. Por ejemplo:
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --master --default \
--read-only=False
     </screen>
    </step>
    <step>
     <para>
      Actualice el período para que los cambios surtan efecto.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
     </screen>
    </step>
    <step>
     <para>
      Por último, reinicie Ceph Object Gateway.
     </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> restart ceph-radosgw@rgw.`hostname -s`
     </screen>
    </step>
   </procedure>
   <para>
    Si la zona principal anterior se recupera, revierta la operación.
   </para>
   <procedure>
    <step>
     <para>
      Desde la zona recuperada, extraiga el período de la zona principal actual.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period pull --url={url-to-master-zone-gateway} \
--access-key={access-key} --secret={secret}
     </screen>
    </step>
    <step>
     <para>
      Convierta la zona recuperada en la zona principal y por defecto.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --master --default
     </screen>
    </step>
    <step>
     <para>
      Actualice el período para que los cambios surtan efecto.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
     </screen>
    </step>
    <step>
     <para>
      A continuación, reinicie Ceph Object Gateway en la zona recuperada.
     </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> restart ceph-radosgw@rgw.`hostname -s`
     </screen>
    </step>
    <step>
     <para>
      Si la zona secundaria debe tener una configuración de solo lectura, actualice la zona secundaria.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --read-only
     </screen>
    </step>
    <step>
     <para>
      Actualice el período para que los cambios surtan efecto.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
     </screen>
    </step>
    <step>
     <para>
      Por último, reinicie Ceph Object Gateway en la zona secundaria.
     </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> restart ceph-radosgw@rgw.`hostname -s`
     </screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-haproxy">
  <title>Equilibrio de carga de los servidores de Object Gateway con HAProxy</title>

  <para>
   Puede utilizar el mecanismo de equilibrio de carga HAProxy para distribuir todas las peticiones entre varios servidores de procesador final de Object Gateway. Consulte <link xlink:href="https://www.suse.com/documentation/sle-ha-12/book_sleha/data/sec_ha_lb_haproxy.html"/> para obtener más información sobre cómo configurar HAProxy.
  </para>

  <para>
   A continuación se muestra una configuración sencilla de HAProxy para equilibrar nodos de Object Gateway mediante carga rotativa como algoritmo de equilibrio:
  </para>

<screen>
<prompt>root # </prompt>cat /etc/haproxy/haproxy.cfg
[...]
frontend <replaceable>https_frontend</replaceable>
bind *:443 crt <replaceable>path-to-cert.pem</replaceable> [ciphers: ... ]
default_backend rgw

backend rgw
mode http
balance roundrobin
server rgw_server1 <replaceable>rgw-endpoint1</replaceable> weight 1 maxconn 100 check
server rgw_server2 <replaceable>rgw-endpoint2</replaceable> weight 1 maxconn 100 check
[...]
</screen>
 </sect1>
</chapter>
