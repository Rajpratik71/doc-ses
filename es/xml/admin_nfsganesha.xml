<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_nfsganesha.xml" version="5.0" xml:id="cha-ceph-nfsganesha">

 <title>NFS Ganesha: exportación de datos de Ceph a través de NFS</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>editar</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>sí</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    
 <para>
  NFS Ganesha es un servidor NFS (consulte <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_nfs.html">Uso compartido de sistemas de archivos con NFS</link>) que se ejecuta en un espacio de dirección de usuario, en lugar de hacerlo como parte del kernel del sistema operativo. Con NFS Ganesha, puede poner en marcha su propio mecanismo de almacenamiento, como Ceph, y acceder a él desde cualquier cliente NFS.
 </para>
 <para>
  Los depósitos S3 se exportan a NFS en base a cada usuario; por ejemplo, mediante la vía <filename><replaceable>GANESHA_NODE:</replaceable>/<replaceable>USERNAME</replaceable>/<replaceable>BUCKETNAME</replaceable></filename>.
 </para>
 <para>
  CephFS se exporta por defecto a través de la vía <filename><replaceable>GANESHA_NODE:</replaceable>/cephfs</filename>.
 </para>
 <sect1 xml:id="ceph-nfsganesha-install">
  <title>Instalación</title>

  <para>
   Para obtener instrucciones sobre la instalación, consulte <xref linkend="cha-as-ganesha"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-config">
  <title>Configuración</title>

  <para>
   Para obtener una lista de todos los parámetros disponibles en el archivo de configuración, consulte:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>man ganesha-config</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-ceph-config</command> para las opciones de capa de abstracción del sistema de archivos (FSAL) CephFS.
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-rgw-config</command> para las opciones de FSAL de Object Gateway.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Esta sección incluye información que le ayudará a configurar el servidor NFS Ganesha a fin de exportar los datos del clúster a los que se puede acceder a través de Object Gateway y CephFS.
  </para>

  <para>
   La configuración de NFS Ganesha se controlada mediante <filename>/etc/ganesha/ganesha.conf</filename>. Tenga en cuenta que los cambios que realice en este archivo se sobrescribirán cuando se ejecute la fase 4 de DeepSea. Para cambiar de forma persistente los valores, edite el archivo <filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename> ubicado en el master de Salt.
  </para>

  <sect2 xml:id="ceph-nfsganesha-config-general">
   <title>Sección Export</title>
   <para>
    En esta sección se describe cómo configurar las secciones <literal>EXPORT</literal> del archivo <filename>ganesha.conf</filename>.
   </para>
<screen>EXPORT
{
  Export_Id = 1;
  Path = "/";
  Pseudo = "/";
  Access_Type = RW;
  Squash = No_Root_Squash;
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
   <sect3 xml:id="ceph-nfsganesha-config-general-export">
    <title>Sección Export principal</title>
    <variablelist>
     <varlistentry>
      <term>Export_Id</term>
      <listitem>
       <para>
        Cada exportación debe tener un valor "Export_Id" exclusivo (obligatorio).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Path</term>
      <listitem>
       <para>
        La vía de exportación en el repositorio de CephFS relacionado (obligatorio). Esto permite exportar los subdirectorios desde CephFS.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Pseudo</term>
      <listitem>
       <para>
        Vía de exportación de NFS de destino (obligatorio para NFSv4). Define en qué vía de exportación de NFS estarán disponibles los datos exportados.
       </para>
       <para>
        Ejemplo: con el valor <literal>/cephfs/</literal> y después de ejecutar
       </para>
<screen>
<prompt>root # </prompt>mount <replaceable>GANESHA_IP</replaceable>:/cephfs/ /mnt/
</screen>
       <para>
        Los datos de CephFS están disponibles en el directorio <filename>/mnt/cephfs/</filename> del cliente.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Access_Type</term>
      <listitem>
       <para>
        "RO" para el acceso de solo lectura. Por defecto es "None" (Ninguno).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Squash</term>
      <listitem>
       <para>
        Opción squash de NFS.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>FSAL</term>
      <listitem>
       <para>
        Exportación de la "Capa de abstracción del sistema de archivos". Consulte la <xref linkend="ceph-nfsganesha-config-general-fsal"/>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-nfsganesha-config-general-fsal">
    <title>Subsección FSAL</title>
<screen>EXPORT
{
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
    <variablelist>
     <varlistentry>
      <term>Name</term>
      <listitem>
       <para>
        Define qué procesador final utiliza NFS Ganesha. Los valores permitidos son <literal>CEPH</literal> para CephFS o <literal>RGW</literal> para Object Gateway. Dependiendo de lo que elija, habrá que definir un valor para <literal>role-mds</literal> o <literal>role-rgw</literal> en <filename>policy.cfg</filename>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-config-rgw">
   <title>Sección RGW</title>
<screen>RGW {
  ceph_conf = "/etc/ceph/ceph.conf";
  name = "name";
  cluster = "ceph";
}</screen>
   <variablelist>
    <varlistentry>
     <term>ceph_conf</term>
     <listitem>
      <para>
       Señala al archivo <filename>ceph.conf</filename>. Si se distribuye con DeepSea, no es necesario cambiar este valor.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>name</term>
     <listitem>
      <para>
       El nombre del usuario del cliente de Ceph que utiliza NFS Ganesha.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cluster</term>
     <listitem>
      <para>
       El nombre del clúster de Ceph. SUSE Enterprise Storage 5 solo admite actualmente un nombre de clúster, que es <literal>ceph</literal> por defecto.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ganesha-nfsport">
   <title>Cambio de los puertos por defecto de NFS Ganesha</title>
   <para>
    NFS Ganesha usa por defecto el puerto 2049 para NFS y el 875 para la compatibilidad con rquota. Para cambiar los números de puerto por defecto, utilice las opciones <option>NFS_Port</option> y <option>RQUOTA_Port</option> dentro de la sección <literal>NFS_CORE_PARAM</literal>, por ejemplo:
   </para>
<screen>
NFS_CORE_PARAM
{
 NFS_Port = 2060;
 RQUOTA_Port = 876;
}
</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-customrole">
  <title>Funciones personalizadas de NFS Ganesha</title>

  <para>
   Es posible definir funciones personalizadas de NFS Ganesha para los nodos del clúster. Estas funciones se asignan posteriormente a los nodos en <filename>policy.cfg</filename>. Las funciones permiten:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Nodos de NFS Ganesha separados para acceder a Object Gateway y CephFS.
    </para>
   </listitem>
   <listitem>
    <para>
     Asignar distintos usuarios de Object Gateway a nodos de NFS Ganesha.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Contar con usuarios de Object Gateway distintos permite a los nodos de NFS Ganesha acceder a distintos depósitos S3. Los depósitos S3 se pueden utilizar para controlar el acceso. Nota: los depósitos S3 no se deben confundir con los depósitos de Ceph utilizados en el mapa de CRUSH.
  </para>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-multiusers">
   <title>Usuarios distintos de Object Gateway para NFS Ganesha</title>
   <para>
    El siguiente procedimiento de ejemplo para el master de Salt muestra cómo crear dos funciones de NFS Ganesha con diferentes usuarios de Object Gateway. En este ejemplo se utilizan las funciones <literal>gold</literal> y <literal>silver</literal>. DeepSea ya proporciona archivos de configuración de ejemplo para ellas.
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-rgw-multiusers">
    <step>
     <para>
      Abra el archivo <filename>/srv/pillar/ceph/stack/global.yml</filename> con el editor que quiera. Cree el archivo si no existe.
     </para>
    </step>
    <step>
     <para>
      El archivo debe contener las siguientes líneas:
     </para>
<screen>rgw_configurations:
  - rgw
  - silver
  - gold
ganesha_configurations:
  - silver
  - gold</screen>
     <para>
      Estas funciones se pueden asignar más tarde en <filename>policy.cfg</filename>.
     </para>
    </step>
    <step>
     <para>
      Cree un archivo <filename>/srv/salt/ceph/rgw/users/users.d/gold.yml</filename> y añada el siguiente contenido:
     </para>
<screen>- { uid: "gold1", name: "gold1", email: "gold1@demo.nil" }</screen>
     <para>
      Cree un archivo <filename>/srv/salt/ceph/rgw/users/users.d/silver.yml</filename> y añada el siguiente contenido:
     </para>
<screen>- { uid: "silver1", name: "silver1", email: "silver1@demo.nil" }</screen>
    </step>
    <step>
     <para>
      Ahora, hay que crear plantillas para <filename>ganesha.conf</filename> para cada función. La plantilla original de DeepSea es un buen punto de partida. Cree dos copias:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 silver.conf.j2
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 gold.conf.j2</screen>
    </step>
    <step>
     <para>
      Las nuevas funciones requieren anillos de claves para acceder al clúster. Para proporcionar el acceso, copie la línea <filename>ganesha.j2</filename>:
     </para>
<screen><prompt>root # </prompt><command>cp</command> ganesha.j2 silver.j2
<prompt>root # </prompt><command>cp</command> ganesha.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Copie el anillo de claves para Object Gateway:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/rgw/files/
<prompt>root # </prompt><command>cp</command> rgw.j2 silver.j2
<prompt>root # </prompt><command>cp</command> rgw.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Object Gateway también necesita la configuración de las distintas funciones:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/configuration/files/
<prompt>root # </prompt><command>cp</command> ceph.conf.rgw silver.conf
<prompt>root # </prompt><command>cp</command> ceph.conf.rgw gold.conf</screen>
    </step>
    <step>
     <para>
      Asigne las funciones recién creadas a los nodos del clúster en <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>:
     </para>
<screen>role-silver/cluster/<replaceable>NODE1</replaceable>.sls
role-gold/cluster/<replaceable>NODE2</replaceable>.sls
 </screen>
     <para>
      Sustituya <replaceable>NODE1</replaceable> y <replaceable>NODE2</replaceable> por los nombres de los nodos a los que desea asignar las funciones.
     </para>
    </step>
    <step>
     <para>
      Ejecute las fases 0 a 4 de DeepSea.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-cephfs">
   <title>Separación de FSAL de CephFS y Object Gateway</title>
   <para>
    El siguiente procedimiento de ejemplo para el master de Salt muestra cómo crear dos funciones distintas nuevas que utilizan CephFS y Object Gateway:
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-customrole">
    <step>
     <para>
      Abra el archivo <filename>/srv/pillar/ceph/rgw.sls</filename> con el editor que quiera. Cree el archivo si no existe.
     </para>
    </step>
    <step>
     <para>
      El archivo debe contener las siguientes líneas:
     </para>
<screen>rgw_configurations:
  ganesha_cfs:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }
  ganesha_rgw:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }

ganesha_configurations:
  - ganesha_cfs
  - ganesha_rgw</screen>
     <para>
      Estas funciones se pueden asignar más tarde en <filename>policy.cfg</filename>.
     </para>
    </step>
    <step>
     <para>
      Ahora, hay que crear plantillas para <filename>ganesha.conf</filename> para cada función. La plantilla original de DeepSea es un buen punto de partida. Cree dos copias:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 ganesha_rgw.conf.j2
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 ganesha_cfs.conf.j2</screen>
    </step>
    <step>
     <para>
      Edite <filename>ganesha_rgw.conf.j2</filename> y elimine la sección:
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles='mds') != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      Edite <filename>ganesha_cfs.conf.j2</filename> y elimine la sección:
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles=role) != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      Las nuevas funciones requieren anillos de claves para acceder al clúster. Para proporcionar el acceso, copie la línea <filename>ganesha.j2</filename>:
     </para>
<screen><prompt>root # </prompt><command>cp</command> ganesha.j2 ganesha_rgw.j2
<prompt>root # </prompt><command>cp</command> ganesha.j2 ganesha_cfs.j2</screen>
     <para>
      La línea <literal>caps mds = "allow *"</literal> se puede eliminar de <filename>ganesha_rgw.j2</filename>.
     </para>
    </step>
    <step>
     <para>
      Copie el anillo de claves para Object Gateway:
     </para>
<screen><prompt>root # </prompt><command>cp</command> /srv/salt/ceph/rgw/files/rgw.j2 \
/srv/salt/ceph/rgw/files/ganesha_rgw.j2</screen>
    </step>
    <step>
     <para>
      Object Gateway necesita la configuración de la nueva función:
     </para>
<screen><prompt>root # </prompt><command>cp</command> /srv/salt/ceph/configuration/files/ceph.conf.rgw \
/srv/salt/ceph/configuration/files/ceph.conf.ganesha_rgw</screen>
    </step>
    <step>
     <para>
      Asigne las funciones recién creadas a los nodos del clúster en <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>:
     </para>
<screen>role-ganesha_rgw/cluster/<replaceable>NODE1</replaceable>.sls
role-ganesha_cfs/cluster/<replaceable>NODE1</replaceable>.sls
 </screen>
     <para>
      Sustituya <replaceable>NODE1</replaceable> y <replaceable>NODE2</replaceable> por los nombres de los nodos a los que desea asignar las funciones.
     </para>
    </step>
    <step>
     <para>
      Ejecute las fases 0 a 4 de DeepSea.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-services">
  <title>Inicio o reinicio de NFS Ganesha</title>

  <para>
   Para habilitar e iniciar el servicio de NFS Ganesha, ejecute:
  </para>

<screen><prompt>root # </prompt><command>systemctl</command> enable nfs-ganesha
<prompt>root # </prompt><command>systemctl</command> start nfs-ganesha</screen>

  <para>
   Reinicie NFS Ganesha con:
  </para>

<screen><prompt>root # </prompt><command>systemctl</command> restart nfs-ganesha</screen>

  <para>
   Cuando se inicia o se reinicia NFS Ganesha, tiene un tiempo límite de gracia de 90 segundos para NFS v4. Durante el período de gracia, las peticiones nuevas de los clientes se rechazan de forma activa. Por lo tanto, los clientes pueden observar una ralentización de las peticiones cuando NFS se encuentra en período de gracia.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-loglevel">
  <title>Definición del nivel de registro</title>

  <para>
   Para cambiar el nivel de depuración por defecto <literal>NIV_EVENT</literal>, debe editar el archivo <filename>/etc/sysconfig/nfs-ganesha</filename>. Sustituya <literal>NIV_EVENT</literal> por <literal>NIV_DEBUG</literal> o <literal>NIV_FULL_DEBUG</literal>. Si se aumenta el nivel de detalle del registro, se pueden producir grandes cantidades de datos en los archivos de registro.
  </para>

<screen>OPTIONS="-L /var/log/ganesha/ganesha.log -f /etc/ganesha/ganesha.conf -N NIV_EVENT"</screen>

  <para>
   Es preciso reiniciar el servicio cuando se cambia el nivel del registro.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-verify">
  <title>Verificación del recurso compartido NFS exportado</title>

  <para>
   Cuando se utiliza NFS v3, puede verificar si los recursos compartidos NFS se exportan en el nodo del servidor NFS Ganesha:
  </para>

<screen><prompt>root # </prompt><command>showmount</command> -e
/ (everything)</screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-mount">
  <title>Montaje del recurso compartido NFS exportado</title>

  <para>
   Para montar el recurso compartido de NFS exportado (según se haya configurado en la <xref linkend="ceph-nfsganesha-config"/>) en un host de cliente, ejecute:
  </para>

<screen><prompt>root # </prompt><command>mount</command> -t nfs -o rw,noatime,sync \
 <replaceable>nfs_ganesha_server_hostname:/ /path/to/local/mountpoint</replaceable></screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-more">
  <title>Recursos adicionales</title>

  <para>
   Encontrará la documentación original de NFS Ganesha en <link xlink:href="https://github.com/nfs-ganesha/nfs-ganesha/wiki/Docs"/>.
  </para>
 </sect1>
</chapter>
