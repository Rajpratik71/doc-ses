<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Upgrade von vorigen Versionen</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>Bearbeiten</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>Ja</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  In diesem Kapitel werden die Schritte zum Upgrade älterer Versionen von SUSE Enterprise Storage zur aktuellen Version vorgestellt.
 </para>
 <sect1 xml:id="ceph-upgrade-relnotes">
  <title>Lesen Sie die Versionshinweise</title>

  <para>
   In den Versionshinweisen finden Sie zusätzliche Informationen zu den Änderungen, die seit der vorigen Version von SUSE Enterprise Storage vorgenommen wurden. Informieren Sie sich in den Versionshinweisen über Folgendes:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Sind bei der Hardware besondere Überlegungen zu beachten?
    </para>
   </listitem>
   <listitem>
    <para>
     Wurden erhebliche Änderungen an den verwendeten Software-Paketen vorgenommen?
    </para>
   </listitem>
   <listitem>
    <para>
     Gelten besondere Vorsichtsmaßnahmen für die vorliegende Installation?
    </para>
   </listitem>
  </itemizedlist>

  <para>
   In den Versionshinweisen finden Sie auch Informationen, die erst nach der Fertigstellung des Handbuchs bekannt wurden. Auch bekannte Probleme werden beschrieben.
  </para>

  <para>
   Nach Installation des Pakets <package>release-notes-ses</package> finden Sie die Versionshinweise lokal im Verzeichnis <filename>/usr/share/doc/release-notes</filename> oder online unter <link xlink:href="https://www.suse.com/releasenotes/"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-upgrade-general">
  <title>Allgemeiner Upgrade-Vorgang</title>

  <para>
   Beachten Sie vor Beginn des Upgrade-Vorgangs die folgenden Punkte:
  </para>

  <variablelist>
   <varlistentry>
    <term>Upgrade-Reihenfolge</term>
    <listitem>
     <para>
      Vor dem Upgrade des Ceph Clusters müssen Sie den zugrundeliegenden SUSE Linux Enterprise Server und SUSE Enterprise Storage korrekt bei SCC oder SMT registrieren. Es ist möglich, ein Upgrade der Daemons im Cluster durchzuführen, wenn der Cluster online und in Betrieb ist. Bestimmte Arten von Daemons hängen von anderen ab. Beispielsweise hängen Ceph Object Gateways von Ceph Monitors und Ceph OSD Daemons ab. Wir empfehlen für das Upgrade die folgende Reihenfolge:
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        Ceph Monitors
       </para>
      </listitem>
      <listitem>
       <para>
        Ceph Manager
       </para>
      </listitem>
      <listitem>
       <para>
        Ceph OSDs
       </para>
      </listitem>
      <listitem>
       <para>
        Metadata Server
       </para>
      </listitem>
      <listitem>
       <para>
        Object Gateways
       </para>
      </listitem>
      <listitem>
       <para>
        iSCSI Gateways
       </para>
      </listitem>
      <listitem>
       <para>
        NFS Ganesha
       </para>
      </listitem>
     </orderedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Unnötige Betriebssystem-Snapshots löschen</term>
    <listitem>
     <para>
      Entfernen Sie nicht benötigte Dateisystem-Snapshots auf den Betriebssystempartitionen der Nodes. Dadurch wird ausreichend Speicherplatz für das Upgrade sichergestellt.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Cluster-Zustand überprüfen</term>
    <listitem>
     <para>
      Wir empfehlen, vor Beginn des Upgrade-Vorgangs den Cluster-Zustand zu überprüfen.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Upgrade einzeln und nacheinander durchführen</term>
    <listitem>
     <para>
      Wir empfehlen, jeden Daemon eines bestimmten Typs, wie zum Beispiel alle Monitor Daemons oder alle OSD Daemons, einzeln und nacheinander upzugraden. So wird sichergestellt, dass alle dieselbe Version aufweisen. Wir empfehlen außerdem, zunächst ein Upgrade aller Daemons im Cluster durchzuführen, bevor Sie versuchen, eine neue Funktionalität in einer Version auszuprobieren.
     </para>
     <para>
      Nach dem Upgrade aller Daemons eines bestimmten Typs müssen Sie deren Zustand überprüfen.
     </para>
     <para>
      Vergewissern Sie sich, dass jeder Monitor nach dem Upgrade aller Monitors wieder im Quorum vorhanden ist:
     </para>
<screen><prompt>root # </prompt>ceph mon stat</screen>
     <para>
      Vergewissern Sie sich, dass jeder Ceph OSD Daemon nach dem Upgrade aller OSDs wieder im Cluster vorhanden ist:
     </para>
<screen><prompt>root # </prompt>ceph osd stat</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>
     Flagge <option>require-osd-release luminous</option> setzen
    </term>
    <listitem>
     <para>
      Wenn das Upgrade des letzten OSD auf SUSE Enterprise Storage 5 abgeschlossen ist, erkennen die Monitor Nodes, dass alle OSDs die "luminous"-Version von Ceph ausführen. Möglicherweise monieren sie daraufhin, dass die osdmap-Flagge <option>require-osd-release luminous</option> nicht gesetzt ist. In diesem Fall müssen Sie die betreffende Flagge manuell setzen, um zu bestätigen, dass – nachdem nun ein Upgrade auf "luminous" für den Cluster durchgeführt wurde – kein Downgrade auf Ceph "jewel" mehr möglich ist. Führen Sie zum Setzen der Flagge das folgende Kommando aus:
     </para>
<screen><prompt>root@minion &gt; </prompt>sudo ceph osd require-osd-release luminous</screen>
     <para>
      Nach Ausführung des Kommandos wird die Warnung nicht mehr angezeigt.
     </para>
     <para>
      Bei Neuinstallation von SUSE Enterprise Storage 5 wird diese Flagge automatisch gesetzt, wenn die Ceph Monitors die erste osdmap erstellen. Der Endbenutzer muss daher nicht eingreifen.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="ds-migrate-osd-encrypted">
  <title>Verschlüsseln der OSDs beim Upgrade</title>

  <para>
   Ab SUSE Enterprise Storage 5 werden OSDs standardmäßig mit BlueStore statt mit FileStore bereitgestellt. Obwohl BlueStore eine Verschlüsselung unterstützt, werden Ceph OSDs standardmäßig unverschlüsselt bereitgestellt. Das folgende Verfahren beschreibt die Schritte zur Verschlüsselung von OSDs während des Upgrade-Vorgangs. Nehmen wir an, dass sowohl die Daten-Festplatten als auch die WAL/DB-Festplatten, die für die OSD-Bereitstellung verwendet werden sollen, leer und nicht partitioniert sind. Falls die Festplatten vorher bereits verwendet wurden, löschen Sie sie vollständig anhand des in <xref linkend="deploy-wiping-disk"/> beschriebenen Verfahrens.
  </para>

  <important>
   <title>Nur jeweils ein OSD</title>
   <para>
    Verschlüsselte OSDs müssen nacheinander bereitgestellt werden, nicht gleichzeitig. Der Grund dafür besteht darin, dass die Daten der OSDs entfernt werden und der Cluster mehrere wiederholte Ausgleichsvorgänge durchläuft.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Ermitteln Sie die Werte <option>bluestore block db size</option> und <option>bluestore block wal size</option> für Ihre Bereitstellung und fügen Sie sie auf dem Salt Master zur Datei <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename> hinzu. Die Werte müssen in Byte angegeben werden.
    </para>
<screen>
[global]
bluestore block db size = 48318382080
bluestore block wal size = 2147483648
</screen>
    <para>
     Weitere Informationen zur Anpassung der Datei <filename>ceph.conf</filename> finden Sie im <xref linkend="ds-custom-cephconf"/>.
    </para>
   </step>
   <step>
    <para>
     Führen Sie DeepSea-Phase 3 aus, um die Änderungen zu verteilen:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass die Datei <filename>ceph.conf</filename> auf den entsprechenden OSD-Nodes aktualisiert ist:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>cat /etc/ceph/ceph.conf
</screen>
   </step>
   <step>
    <para>
     Bearbeiten Sie die YML-Dateien im Verzeichnis <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions</filename>, die für die zu verschlüsselnden OSDs relevant sind. Prüfen Sie deren Pfad gegen den in Datei <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> definierten Pfad, um sicherzustellen, dass Sie die richtigen YML-Dateien bearbeiten.
    </para>
    <important>
     <title>Lange Datenträgerkennungen</title>
     <para>
      Verwenden Sie lange Datenträgerkennungen, wenn Sie <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/*.yml</filename>-Dateien kennzeichnen.
     </para>
    </important>
    <para>
     Nachfolgend sehen Sie ein Beispiel einer OSD-Konfiguration. Beachten Sie, dass wegen der erforderlichen Verschlüsselung die Optionen <option>db_size</option> und <option>wal_size</option> entfernt wurden:
    </para>
<screen>
ceph:
 storage:
   osds:
     /dev/disk/by-id/scsi-SDELL_PERC_H730_Mini_007027b1065faa972100d34d7aa06d86:
       format: bluestore
       encryption: dmcrypt
       db: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
       wal: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
     /dev/disk/by-id/scsi-SDELL_PERC_H730_Mini_00d146b1065faa972100d34d7aa06d86:
       format: bluestore
       encryption: dmcrypt
       db: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
       wal: /dev/disk/by-id/nvme-INTEL_SSDPEDMD020T4D_HHHL_NVMe_2000GB_PHFT642400HV2P0EGN
</screen>
   </step>
   <step>
    <para>
     Stellen Sie die neuen Blockspeicher-OSDs mit Verschlüsselung bereit, indem Sie die DeepSea-Phasen 2 und 3 ausführen:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
    <para>
     Sie können den Fortschritt mit <command>ceph -s</command> oder <command>ceph osd tree</command> beobachten. Es ist sehr wichtig, den Ausgleich des Clusters abzuwarten, bevor Sie den Vorgang am nächsten OSD-Node wiederholen.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5">
  <title>Upgrade von SUSE Enterprise Storage 4 (DeepSea Bereitstellung) auf Version 5</title>

  <important xml:id="u4to5-softreq">
   <title>Softwareanforderungen</title>
   <para>
    Auf allen Ceph Nodes, auf denen das Upgrade durchgeführt werden soll, muss vor Beginn des Upgrade-Vorgangs die folgende Software installiert und auf die neueste Paketversion aktualisiert werden:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Außerdem müssen Sie vor Beginn des Upgrade-Vorgangs ein Upgrade des Salt Master Node auf SUSE Linux Enterprise Server 12 SP3 und SUSE Enterprise Storage 5 durchführen. Führen Sie dazu <command>zypper migration</command> aus (oder Ihre bevorzugte Upgrade-Methode).
   </para>
  </important>

  <warning>
   <title>Vor dem Upgrade zu beachtende Punkte</title>
   <itemizedlist>
    <listitem>
     <para>
      Prüfen Sie, ob der AppArmor Service ausgeführt wird und deaktivieren Sie ihn auf jedem Cluster Node. Starten Sie das YaST AppArmor-Modul, wählen Sie <guimenu>Einstellungen</guimenu> aus und deaktivieren Sie dann das Kontrollkästchen für <guimenu>AppArmor aktivieren</guimenu>. Bestätigen Sie den Vorgang mit <guimenu>Fertig</guimenu>.
     </para>
     <para>
      Beachten Sie, dass SUSE Enterprise Storage <emphasis>nicht</emphasis> funktioniert, wenn AppArmor aktiviert ist.
     </para>
    </listitem>
    <listitem>
     <para>
      Obwohl der Cluster während des Upgrade-Vorgangs voll funktionsfähig ist, setzt DeepSea die "noout"-Flagge. Sie verhindert, dass Ceph während der Ausfallzeit Daten ausgleicht und somit unnötige Datenübertragungen.
     </para>
    </listitem>
    <listitem>
     <para>
      Zur Optimierung des Upgrade-Vorgangs führt DeepSea die Upgrades Ihrer Nodes in der folgenden Reihenfolge aus, basierend auf der zugewiesenen Rolle wie vom Ceph Upstream empfohlen: MONs, MGRs, OSDs, MDS, RGW, IGW und NFS Ganesha.
     </para>
     <para>
      Beachten Sie, dass DeepSea nicht verhindern kann, dass die Reihenfolge nicht eingehalten wird, wenn auf einem Node mehrere Services ausgeführt werden.
     </para>
    </listitem>
    <listitem>
     <para>
      Obwohl der Ceph Cluster während des Upgrade-Vorgangs aktiv ist, werden manche Nodes möglicherweise neugestartet, um beispielsweise neue Kernel-Versionen anzuwenden. Um die Anzahl der E/A-Operationen in der Warteschlange zu verringern, empfehlen wir, eingehende Anforderungen für die Dauer des Upgrade-Vorgangs abzulehnen.
     </para>
    </listitem>
    <listitem>
     <para>
      Das Cluster-Upgrade kann sehr lange dauern, nämlich in etwa so lange, wie es dauert, ein Upgrade eines Computers multipliziert mit der Anzahl der Cluster Nodes durchzuführen.
     </para>
    </listitem>
    <listitem>
     <para>
      Ab Ceph Luminous wird die Konfigurationsoption <option>osd crush location</option> nicht mehr unterstützt. Aktualisieren Sie vor dem Upgrade Ihre DeepSea-Konfigurationsdaten, damit <command>crush location</command> verwendet wird.
     </para>
    </listitem>
   </itemizedlist>
  </warning>

  <para>
   Führen Sie zum Upgrade des SUSE Enterprise Storage 4-Clusters auf Version 5 die folgenden Schritte aus:
  </para>

  <procedure>
   <step>
    <para>
     Legen Sie die neue interne Objekt-Sortierreihenfolge fest und führen Sie folgendes Kommando aus:
    </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    <tip>
     <para>
      Wir empfehlen, das folgende Kommando auszuführen, um zu verifizieren, dass das vorige Kommando erfolgreich war:
     </para>
<screen><prompt>root # </prompt>ceph osd dump --format json-pretty | grep sortbitwise
 "flags": "sortbitwise,recovery_deletes,purged_snapdirs",</screen>
    </tip>
   </step>
   <step>
    <para>
     Verifizieren Sie mit <command>rpm -q deepsea</command>, dass die Version des DeepSea-Pakets am Salt Master Node mit mindestens <literal>0.7</literal> beginnt. Beispiel:
    </para>
<screen><prompt>root # </prompt>rpm -q deepsea
deepsea-0.7.27+git.0.274c55d-5.1</screen>
    <para>
     Wenn die Versionsnummer des DeepSea-Pakets mit 0.6 beginnt, prüfen Sie nach, ob Sie den Salt Master Node erfolgreich zu SUSE Linux Enterprise Server 12 SP3 und SUSE Enterprise Storage 5 migriert haben (lesen Sie dazu <xref linkend="u4to5-softreq"/> am Anfang dieses Abschnitts). Diese Voraussetzung muss erfüllt sein, bevor Sie mit dem Upgrade-Vorgang beginnen.
    </para>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Wenn Sie Ihr System bei SUSEConnect registriert haben und SCC/SMT verwenden, müssen Sie nichts weiter tun. Fahren Sie mit <xref linkend="step-updatepillar"/> fort.
      </para>
     </step>
     <step>
      <para>
       Wenn Sie SCC/SMT <emphasis role="bold">nicht</emphasis> verwenden, sondern eine Media-ISO oder eine andere Paketquelle, fügen Sie die folgenden Repositorys manuell hinzu: SLE12-SP3 Basis, SLE12-SP3 Update, SES5 Basis und SES5 Update. Verwenden Sie dazu das <command>zypper</command>-Kommando. Entfernen Sie zunächst alle vorhandenen Software-Repositorys. Fügen Sie dann die erforderlichen neuen Repositorys hinzu und aktualisieren Sie schließlich die Quellen der Repositorys:
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
      <para>
       Ändern Sie anschließend Ihre Pillar-Daten, um eine andere Strategie anzuwenden. Bearbeiten
      </para>
<screen>/srv/pillar/ceph/stack/<replaceable>name_of_cluster</replaceable>/cluster.yml</screen>
      <para>
       und fügen Sie die folgende Zeile hinzu:
      </para>
<screen>upgrade_init: zypper-dup</screen>
      <tip>
       <para>
        Für die <literal>zypper-dup</literal>-Strategie müssen Sie die neuesten Software-Repositorys hinzufügen. Die standardmäßige <literal>zypper-migration</literal>-Strategie dagegen verlässt sich auf die von SCC/SMT bereitgestellten Repositorys.
       </para>
      </tip>
     </step>
    </substeps>
   </step>
   <step xml:id="step-updatepillar">
    <para>
     Führen Sie ein Update für Ihre Pillar-Schnittstelle durch:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> saltutil.sync_all</screen>
    <para>
     In <xref linkend="ds-minion-targeting"/> finden Sie weitere Details zur Behandlung von Salt Minions.
    </para>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass das Schreiben an Pillar erfolgreich war:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.get upgrade_init</screen>
    <para>
     Die Ausgabe des Kommandos sollte die hinzugefügte Eingabe spiegeln.
    </para>
   </step>
   <step>
    <para>
     Führen Sie ein Upgrade der Salt Minions durch:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> state.apply ceph.updates.salt</screen>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass das Upgrade für alle Salt Minions durchgeführt wurde:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> test.version</screen>
   </step>
   <step>
    <para>
     Beziehen Sie die Salt Minions des Clusters mit ein. Weitere Informationen finden Sie in <xref linkend="ds-minion-targeting"/> zu <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Starten Sie das Upgrade von SUSE Linux Enterprise Server und Ceph:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.maintenance.upgrade</screen>
    <tip>
     <title>Kommando beim Neustart erneut ausführen</title>
     <para>
      Wenn durch den Vorgang ein Neustart des Salt Master ausgelöst wird, führen Sie das Kommando erneut aus, um den Upgrade-Vorgang für die Salt Minions erneut zu starten.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Vergewissern Sie sich nach dem Upgrade, dass AppArmor deaktiviert und auf allen Nodes gestoppt ist:
    </para>
<screen><prompt>root # </prompt>systemctl disable apparmor.service
systemctl stop apparmor.service</screen>
   </step>
   <step>
    <para>
     Nach dem Upgrade sind die Ceph Manager noch nicht installiert. Gehen Sie folgendermaßen vor, um einen fehlerfreien Cluster-Zustand zu erreichen:
    </para>
    <substeps>
     <step>
      <para>
       Führen Sie Phase 0 aus, um die Salt REST API zu aktivieren:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
     </step>
     <step>
      <para>
       Führen Sie Phase 1 aus, um das Unterverzeichnis <filename>role-mgr/</filename> zu erstellen:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
     </step>
     <step>
      <para>
       Bearbeiten Sie <guimenu>policy.cfg</guimenu> wie in <xref linkend="policy-configuration"/> beschrieben und fügen Sie eine Ceph Manager-Rolle zu den Nodes hinzu, auf denen Ceph Monitors bereitgestellt werden. Fügen Sie außerdem die openATTIC-Rolle zu einem der Cluster Nodes hinzu. Weitere Informationen finden Sie im <xref linkend="ceph-oa"/>.
      </para>
     </step>
     <step>
      <para>
       Führen Sie Phase 2 für das Update des Pillar aus:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
     </step>
     <step>
      <para>
       DeepSea generiert die <filename>ceph.conf</filename>-Konfigurationsdateien nun anders. Weitere Informationen finden Sie im <xref linkend="ds-custom-cephconf"/>.
      </para>
     </step>
     <step>
      <para>
       Führen Sie Phase 3 aus, um Ceph Manager bereitzustellen:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     </step>
     <step>
      <para>
       Führen Sie Phase 4 aus, um openATTIC ordnungsgemäß zu konfigurieren:
      </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
     </step>
    </substeps>
    <note>
     <title>Inkongruenz der Ceph Schlüsselfunktionen</title>
     <para>
      Wenn <literal>ceph.stage.3</literal> mit der Fehlermeldung "Error EINVAL: entity client.bootstrap-osd exists but caps do not match" abbricht, bedeutet dies, dass die Schlüsselfunktionen (key capabilities; kurz: caps) für den <literal>client.bootstrap.osd</literal>-Schlüssel des bestehenden Clusters nicht mit den Funktionen übereinstimmt, die DeepSea festzulegen versucht. Oberhalb der Fehlermeldung sehen Sie in Rot einen Dump des Kommandos <command>ceph auth</command>, der nicht ausgeführt wurde. Sehen Sie sich dieses Kommando an und prüfen Sie die verwendete Schlüssel-ID und Datei. Im Fall von <literal>client.bootstrap-osd</literal> sieht das Kommando folgendermaßen aus:
     </para>
<screen><prompt>root # </prompt>ceph auth add client.bootstrap-osd \
 -i /srv/salt/ceph/osd/cache/bootstrap.keyring</screen>
     <para>
      Prüfen Sie zur Behebung von Fehlern bei Schlüsselfunktionen den Inhalt der Schlüsselbunddatei, die DeepSea bereitzustellen versucht. Beispiel:
     </para>
<screen><prompt>cephadm &gt; </prompt>cat /srv/salt/ceph/osd/cache/bootstrap.keyring
[client.bootstrap-osd]
     key = AQD6BpVZgqVwHBAAQerW3atANeQhia8m5xaigw==
     caps mgr = "allow r"
     caps mon = "allow profile bootstrap-osd"</screen>
     <para>
      Vergleichen Sie dies mit der Ausgabe von <command>ceph auth get client.bootstrap-osd</command>:
     </para>
<screen><prompt>root # </prompt>ceph auth get client.bootstrap-osd
exported keyring for client.bootstrap-osd
[client.bootstrap-osd]
     key = AQD6BpVZgqVwHBAAQerW3atANeQhia8m5xaigw==
     caps mon = "allow profile bootstrap-osd"</screen>
     <para>
      Beachten Sie, dass bei dem zweiten Schlüssel <literal>caps mgr = "allow r"</literal> fehlt. Führen Sie zur Fehlerbehebung folgendes Kommando aus:
     </para>
<screen><prompt>root # </prompt>ceph auth caps client.bootstrap-osd mgr \
 "allow r" mon "allow profile bootstrap-osd"</screen>
     <para>
      Die Ausführung von <literal>ceph.stage.3</literal> sollte nun gelingen.
     </para>
     <para>
      Dasselbe Problem kann bei Ausführung von <literal>ceph.stage.4</literal> bei Metadatenserver- und Object Gateway-Schlüsselbunden auftreten. Gehen Sie dann genauso vor wie oben beschrieben: Prüfen Sie das Kommando, das nicht ausgeführt wurde, die Schlüsselbunddatei, die bereitgestellt werden soll sowie die Funktionen des bestehenden Schlüssels. Führen Sie dann <command>ceph auth caps</command> aus, um die bestehenden Schlüsselfunktionen zu aktualisieren, damit diese mit den von DeepSea bereitgestellten Funktionen übereinstimmen.
     </para>
    </note>
   </step>
  </procedure>

  <important>
   <title>Upgrade-Fehler</title>
   <para>
    Wenn sich der Cluster länger als 300 Sekunden im Zustand "HEALTH_ERR" befindet oder einer der Services für jede zugewiesene Rolle länger als 900 Sekunden ausfällt, ist beim Upgrade ein Fehler aufgetreten. Versuchen Sie in diesem Fall das Problem zu finden, es zu beheben und den Upgrade-Vorgang erneut durchzuführen. Beachten Sie, dass die Zeitüberschreitungszeiträume bei virtualisierten Umgebungen kürzer sind.
   </para>
  </important>

  <important>
   <title>Neustarten der OSDs</title>
   <para>
    Nach dem Upgrade auf SUSE Enterprise Storage 5 brauchen FileStore OSDs ungefähr fünf Minuten länger für den Start, weil der OSD eine einmalige Konvertierung seiner Dateien auf der Festplatte vornimmt.
   </para>
  </important>

  <tip>
   <title>Version der Cluster-Komponenten/Nodes prüfen</title>
   <para>
    Führen Sie das folgende Kommando aus, wenn Sie die Versionen der einzelnen Cluster-Komponenten und Nodes herausfinden müssen, beispielsweise um zu prüfen, ob nach dem Upgrade alle Nodes tatsächlich dieselbe Patch-Stufe aufweisen:
   </para>
<screen><prompt>root@master # </prompt>salt-run status.report</screen>
   <para>
    Das Kommando geht durch die verbundenen Salt Minions und fragt die Versionsnummern von Ceph, Salt und SUSE Linux Enterprise Server ab. Danach wird ein Bericht mit der Versionsnummer der meisten Nodes angezeigt sowie die Nodes, die eine andere Version als die Mehrheit aufweisen.
   </para>
  </tip>

  <sect2 xml:id="filestore2bluestore">
   <title>OSD-Migration zu BlueStore</title>
   <para>
    OSD BlueStore ist ein neues Backend für die OSD Daemons. Ab SUSE Enterprise Storage 5 ist dies die Standardoption. Verglichen mit FileStore, das Objekte als Dateien in einem XFS-Dateisystem speichert, kann BlueStore eine höhere Leistung bereitstellen, weil es Objekte direkt auf dem zugrundeliegenden Blockgerät speichert. BlueStore ermöglicht außerdem weitere Funktionen, wie integrierte Komprimierung und EC-Überschreibungen, die bei FileStore nicht zur Verfügung stehen.
   </para>
   <para>
    Für BlueStore spezifisch umfasst ein OSD ein "wal" (Write Ahead-Protokoll)-Gerät und ein "db" (RocksDB-Datenbank)-Gerät. Die RocksDB-Datenbank enthält die Metadaten für einen BlueStore OSD. Diese beiden Geräte befinden sich standardmäßig auf dem selben Gerät wie ein OSD, doch jedes der beiden kann auf schnellere/andere Medien platziert werden.
   </para>
   <para>
    In SES5 werden sowohl FileStore als auch BlueStore unterstützt und FileStore und BlueStore OSDs können gemeinsam in einem einzelnen Cluster vorhanden sein. Während des Upgrade-Vorgangs für SUSE Enterprise Storage werden FileStore OSDs nicht automatisch zu BlueStore konvertiert. Beachten Sie, dass die BlueStore-spezifischen Funktionen nicht auf OSDs verfügbar sind, die nicht zu BlueStore migriert wurden.
   </para>
   <para>
    Vor der Konvertierung zu BlueStore müssen die OSDs SUSE Enterprise Storage 5 ausführen. Der Konvertierungsvorgang ist langsam, weil alle Daten zweimal umgeschrieben werden. Obwohl der Migrationsvorgang möglicherweise lange dauert, fällt der Cluster nicht aus und alle Clients können währenddessen weiterhin auf den Cluster zugreifen. Rechnen Sie für die Dauer der Migration jedoch mit einer geringeren Leistung. Der Grund dafür besteht in einem Ausgleich und Abgleich der Cluster-Daten.
   </para>
   <para>
    Gehen Sie bei der Migration von FileStore OSDs zu BlueStore folgendermaßen vor:
   </para>
   <tip>
    <title>Sicherheitsmaßnahmen ausschalten</title>
    <para>
     Salt-Kommandos, die zur Ausführung der Migration erforderlich sind, werden durch Sicherheitsmaßnahmen blockiert. Führen Sie folgendes Kommando aus, um diese Vorsichtsmaßnahmen auszuschalten:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disengage.safety
</screen>
   </tip>
   <procedure>
    <step>
     <para>
      Migrieren Sie die Hardwareprofile:
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.policy</screen>
     <para>
      Durch dieses Ausführungsprogramm werden Profile migriert, die aktuell von der <filename>policy.cfg</filename>-Datei verwendet werden. Es verarbeitet <filename>policy.cfg</filename>, findet jedes Hardwareprofil anhand der ursprünglichen Datenstruktur und konvertiert es zur neuen Datenstruktur. Das Ergebnis ist ein neues Hardwareprofil namens "migrated-<replaceable>ursprünglicher_Name</replaceable>". <filename>policy.cfg</filename> wird ebenfalls aktualisiert.
     </para>
     <para>
      Wenn die ursprüngliche Konfiguration verschiedene Journale umfasste, verwendet BlueStore dasselbe Gerät für das "wal" und "db" für diesen OSD.
     </para>
    </step>
    <step>
     <para>
      DeepSea migriert OSDs dadurch, dass es ihr Gewicht auf 0 festlegt. Dadurch werden die Daten so lange "abgesaugt" bis der OSD leer ist. Sie können OSDs entweder einzeln nacheinander oder alle auf einmal migrieren. In beiden Fällen wird der geleerte OSD von der Orchestrierung entfernt und anschließend mit der neuen Konfiguration neu erstellt.
     </para>
     <tip>
      <title>Empfohlene Methode</title>
      <para>
       Verwenden Sie <command>ceph.migrate.nodes</command>, wenn Sie eine große Anzahl von physischen Speicher-Nodes oder fast keine Daten haben. Wenn ein Node weniger als 10 % Ihrer Kapazität belegt, dann ist <command>ceph.migrate.nodes</command> möglicherweise geringfügig schneller, weil alle Daten dieser OSDs gleichzeitig verschoben werden.
      </para>
      <para>
       Wenn Sie sich nicht sicher sind, welche Methode Sie anwenden sollen, oder wenn am Standort nur wenig Speicher-Nodes vorhanden sind (wenn beispielsweise jeder Node mehr als 10 % der Cluster-Daten enthält), dann wählen Sie <command>ceph.migrate.osds</command> aus.
      </para>
     </tip>
     <substeps>
      <step>
       <para>
        Führen Sie folgendes Kommando aus, um OSDs einzeln nacheinander zu migrieren:
       </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.osds</screen>
      </step>
      <step>
       <para>
        Führen Sie folgendes Kommando aus, um alle OSDs auf jedem Node gleichzeitig zu migrieren:
       </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.migrate.nodes</screen>
      </step>
     </substeps>
     <tip>
      <para>
       Da die Orchestrierung kein Feedback zum Migrationsvorgang gibt, verwenden Sie
      </para>
<screen><prompt>root # </prompt>ceph osd tree</screen>
      <para>
       um zu sehen, welche OSDs periodisch ein Gewicht von Null haben.
      </para>
     </tip>
    </step>
   </procedure>
   <para>
    Nach der Migration zu BlueStore bleibt die Anzahl der Objekte gleich und die Datenträgerauslastung ist nahezu dieselbe.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5cephdeloy">
  <title>Upgrade von SUSE Enterprise Storage 4 (<command>ceph-deploy</command> Bereitstellung) auf Version 5</title>

  <important>
   <title>Softwareanforderungen</title>
   <para>
    Auf allen Ceph Nodes, auf denen das Upgrade durchgeführt werden soll, muss vor Beginn des Upgrade-Vorgangs die folgende Software installiert und auf die neueste Paketversion aktualisiert werden:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Wählen Sie den Salt Master für Ihren Cluster. Wenn in Ihrem Cluster Calamari bereitgestellt ist, dann <emphasis>ist</emphasis> der Calamari Node bereits der Salt Master. Alternativ wird der Admin Node, von dem aus Sie das Kommando <command>ceph-deploy</command> ausgeführt haben, zum Salt Master.
   </para>
   <para>
    Sie müssen vor Beginn des folgenden Vorgangs ein Upgrade des Salt Master Node auf SUSE Linux Enterprise Server 12 SP3 und SUSE Enterprise Storage 5 durchführen. Führen Sie dazu <command>zypper migration</command> aus (oder Ihre bevorzugte Upgrade-Methode).
   </para>
  </important>

  <para>
   Führen Sie für ein Upgrade des SUSE Enterprise Storage 4-Clusters, der mit <command>ceph-deploy</command> bereitgestellt wurde, auf Version 5 die folgenden Schritte aus:
  </para>

  <procedure xml:id="upgrade4to5cephdeploy-all">
   <title>Schritte, die auf alle Cluster Nodes (einschließlich Calamari Node) angewendet werden sollen</title>
   <step>
    <para>
     Installieren Sie das <systemitem>salt</systemitem>-Paket von SLE-12-SP2/SES4:
    </para>
<screen><prompt>root # </prompt>zypper install salt</screen>
   </step>
   <step>
    <para>
     Installieren Sie das <systemitem>salt-minion</systemitem>-Paket von SLE-12-SP2/SES4. Aktivieren und starten Sie dann den entsprechenden Service:
    </para>
<screen><prompt>root # </prompt>zypper install salt-minion
<prompt>root # </prompt>systemctl enable salt-minion
<prompt>root # </prompt>systemctl start salt-minion</screen>
   </step>
   <step>
    <para>
     Vergewissern Sie sich, dass der Hostname "salt" zur IP-Adresse des Salt Master Node aufgelöst wird. Wenn Ihr Salt Master mit dem Hostnamen <literal>salt</literal> nicht erreichbar ist, bearbeiten Sie die Datei <filename>/etc/salt/minion</filename> oder erstellen Sie eine neue Datei <filename>/etc/salt/minion.d/master.conf</filename> mit folgendem Inhalt:
    </para>
<screen>master: <replaceable>host_name_of_salt_master</replaceable></screen>
    <tip>
     <para>
      Für die bestehenden Salt Minions ist die <option>master:</option>-Option bereits in <filename>/etc/salt/minion.d/calamari.conf</filename> festgelegt. Der Name der Konfigurationsdatei spielt keine Rolle. Wichtig ist nur das Verzeichnis <filename>/etc/salt/minion.d/</filename>.
     </para>
    </tip>
    <para>
     Wenn Sie an den oben genannten Konfigurationsdateien Änderungen vorgenommen haben, starten Sie den Salt Service auf allen Salt Minions neu:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Wenn Sie Ihr System bei SUSEConnect registriert haben und SCC/SMT verwenden, müssen Sie nichts weiter tun. 
      </para>
     </step>
     <step>
      <para>
       Wenn Sie SCC/SMT <emphasis role="bold">nicht</emphasis> verwenden, sondern eine Media-ISO oder eine andere Paketquelle, fügen Sie die folgenden Repositorys manuell hinzu: SLE12-SP3 Basis, SLE12-SP3 Update, SES5 Basis und SES5 Update. Verwenden Sie dazu das <command>zypper</command>-Kommando. Entfernen Sie zunächst alle vorhandenen Software-Repositorys. Fügen Sie dann die erforderlichen neuen Repositorys hinzu und aktualisieren Sie schließlich die Quellen der Repositorys:
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
     </step>
    </substeps>
   </step>
  </procedure>

  <procedure xml:id="upgrade4to5cephdeploy-admin">
   <title>Schritte, die auf den Salt Master Node angewendet werden sollen</title>
   <step>
    <para>
     Legen Sie die neue interne Objekt-Sortierreihenfolge fest und führen Sie folgendes Kommando aus:
    </para>
<screen><prompt>root@master # </prompt>ceph osd set sortbitwise</screen>
    <tip>
     <para>
      Wir empfehlen, das folgende Kommando auszuführen, um zu verifizieren, dass das vorige Kommando erfolgreich war:
     </para>
<screen><prompt>root@master # </prompt>ceph osd dump --format json-pretty | grep sortbitwise
 "flags": "sortbitwise,recovery_deletes,purged_snapdirs",</screen>
    </tip>
   </step>
   <step>
    <para>
     Führen Sie am Salt Master Node ein Upgrade auf SUSE Linux Enterprise Server 12 SP3 und SUSE Enterprise Storage 5 durch. Verwenden Sie <command>zypper migration</command> für SCC-registrierte Systeme. Verwenden Sie <command>zypper dup</command>, wenn Sie die erforderlichen Software-Repositorys manuell bereitstellen. Vergewissern Sie sich nach dem Upgrade, dass auf dem Salt Master Node nur Repositorys für SUSE Linux Enterprise Server 12 SP3 und SUSE Enterprise Storage 5 aktiv (und aktualisiert) sind, bevor Sie fortfahren.
    </para>
   </step>
   <step>
    <para>
     Falls nicht bereits vorhanden, installieren Sie das <systemitem>salt-master</systemitem>-Paket. Aktivieren und starten Sie dann den entsprechenden Service:
    </para>
<screen><prompt>root@master # </prompt>zypper install salt-master
<prompt>root@master # </prompt>systemctl enable salt-master
<prompt>root@master # </prompt>systemctl start salt-master</screen>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass alle Salt Minions vorhanden sind, indem Sie Ihre Schlüssel auflisten:
    </para>
<screen><prompt>root@master # </prompt>salt-key -L</screen>
   </step>
   <step>
    <para>
     Fügen Sie alle Salt Minions-Schlüssel zum Salt Master hinzu, einschließlich des Minion Masters:
    </para>
<screen><prompt>root@master # </prompt>salt-key -A -y</screen>
   </step>
   <step>
    <para>
     Stellen Sie sicher, dass die Schlüssel aller Salt Minions akzeptiert wurden:
    </para>
<screen><prompt>root@master # </prompt>salt-key -L</screen>
   </step>
   <step>
    <para>
     Vergewissern Sie sich, dass die Software auf Ihrem Salt Master Node aktuell ist:
    </para>
<screen><prompt>root@master # </prompt>zypper migration</screen>
   </step>
   <step>
    <para>
     Installieren Sie das Paket <systemitem>deepsea</systemitem>:
    </para>
<screen><prompt>root@master # </prompt>zypper install deepsea</screen>
   </step>
   <step>
    <para>
     Beziehen Sie die Salt Minions des Clusters mit ein. Weitere Informationen finden Sie in <xref linkend="ds-minion-targeting"/> zu <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Importieren Sie den bestehenden installierten Cluster <command>ceph-deploy</command>:
    </para>
<screen><prompt>root@master # </prompt>salt-run populate.engulf_existing_cluster</screen>
    <para>
     Das Kommando bewirkt Folgendes:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Verteilen der erforderlichen Salt- und DeepSea-Module an alle Salt Minions.
      </para>
     </listitem>
     <listitem>
      <para>
       Untersuchen des aktuell ausgeführten Ceph Clusters und Auffüllen von<filename>/srv/pillar/ceph/proposals</filename> mit einem Layout des Clusters.
      </para>
      <para>
       <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> wird erstellt mit Rollen, die allen erkannten aktuell ausgeführten Ceph Services entsprechen. Sehen Sie sich diese Datei an, um zu verifizieren, dass jeder der bestehenden MON, OSD, RGW und MDS Nodes über die entsprechenden Rollen verfügt. OSD-Nodes werden im Unterverzeichnis <filename>profile-import/</filename> importiert. Dadurch können Sie die Dateien in <filename>/srv/pillar/ceph/proposals/profile-import/cluster/</filename> und <filename>/srv/pillar/ceph/proposals/profile-import/stack/default/ceph/minions/</filename> untersuchen, um zu bestätigen, dass die OSDs korrekt übernommen wurden.
      </para>
      <note>
       <para>
        Die generierte Datei <filename>policy.cfg</filename> wendet nur Rollen für die erkannten Ceph Services "role-mon", "role-mgr", "role-mds", "role-rgw", "role-admin" und "role-master" für den Salt Master Node an. Alle anderen gewünschten Rollen müssen manuell zur Datei hinzugefügt werden (weitere Informationen finden Sie in <xref linkend="policy-role-assignment"/>).
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       Die bestehende <filename>ceph.conf</filename>-Datei des Clusters wird im Pfad <filename>/srv/salt/ceph/configuration/files/ceph.conf.import</filename> gespeichert.
      </para>
     </listitem>
     <listitem>
      <para>
       Die Datei <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename> enthält die fsid des Clusters, das Cluster-Netzwerk und das öffentliche Netzwerk. Sie gibt auch die Option <option>configuration_init: default-import</option> an, durch die DeepSea die oben genannte Konfigurationsdatei <filename>ceph.conf.import</filename> verwendet statt der standardmäßigen Vorlagen <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> von DeepSea.
      </para>
      <note>
       <title>Benutzerdefinierte <filename>ceph.conf</filename></title>
       <para>
        Wenn Sie benutzerdefinierte Änderungen in Datei <filename>ceph.conf</filename> vornehmen müssen, warten Sie bis der Import/Upgrade-Vorgang erfolgreich abgeschlossen ist. Bearbeiten Sie dann die Datei <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename> und kommentieren Sie die folgende Zeile:
       </para>
<screen>
configuration_init: default-import
</screen>
       <para>
        Speichern Sie die Datei und befolgen Sie die Anleitungen im <xref linkend="ds-custom-cephconf"/>.
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       Die verschiedenen Schlüsselbunde des Clusters werden in den folgenden Verzeichnissen gespeichert:
      </para>
<screen>/srv/salt/ceph/admin/cache/
/srv/salt/ceph/mon/cache/
/srv/salt/ceph/osd/cache/
/srv/salt/ceph/mds/cache/
/srv/salt/ceph/rgw/cache/</screen>
      <para>
       Verifizieren Sie, dass die Schlüsselbunddateien vorhanden sind und dass im folgenden Verzeichnis <emphasis>keine</emphasis> Schlüsselbunddatei enthalten ist (der Ceph Manager war vor SUSE Enterprise Storage 5 noch nicht vorhanden):
      </para>
<screen>
/srv/salt/ceph/mgr/cache/
</screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Das Kommando <command>salt-run populate.engulf_existing_cluster</command> verarbeitet nicht den Import der openATTIC-Konfiguration. Sie müssen die Datei <filename>policy.cfg</filename> manuell bearbeiten und eine Zeile <literal>role-openattic</literal> hinzufügen. Weitere Informationen finden Sie in <xref linkend="policy-configuration"/>.
    </para>
   </step>

   <step>
    <para>
     Das Kommando <command>salt-run populate.engulf_existing_cluster</command> verarbeitet nicht den Import der iSCSI Gateway-Konfigurationen. Wenn Ihr Cluster iSCSI Gateways enthält, importieren Sie deren Konfigurationen manuell:
    </para>
    <substeps>
     <step>
      <para>
       Exportieren Sie auf einem der iSCSI Gateway Nodes die aktuelle <filename>lrbd.conf</filename>-Datei und kopieren Sie sie in den Salt Master Node:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o &gt;/tmp/lrbd.conf
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf admin:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
     </step>
     <step>
      <para>
       Fügen Sie im Salt Master Node die standardmäßige iSCSI Gateway-Konfiguration zum DeepSea Setup hinzu:
      </para>
<screen>
<prompt>root@master # </prompt>mkdir -p /srv/pillar/ceph/stack/ceph/
<prompt>root@master # </prompt>echo 'igw_config: default-ui' &gt;&gt; /srv/pillar/ceph/stack/ceph/cluster.yml
<prompt>root@master # </prompt>chown salt:salt /srv/pillar/ceph/stack/ceph/cluster.yml
</screen>
     </step>
     <step>
      <para>
       Fügen Sie die iSCSI Gateway-Rollen zu <filename>policy.cfg</filename> hinzu und speichern Sie die Datei:
      </para>
<screen>
role-igw/stack/default/ceph/minions/ses-1.ses.suse.yml
role-igw/cluster/ses-1.ses.suse.sls
[...]
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Führen Sie Phase 1 aus, um alle möglichen Rollen zu erstellen:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Generieren Sie die erforderlichen Unterverzeichnisse unter <filename>/srv/pillar/ceph/stack</filename>:
    </para>
<screen><prompt>root@master # </prompt>salt-run push.proposal</screen>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass ein funktionierender von DeepSea verwalteter Cluster mit korrekt zugewiesenen Rollen vorhanden ist:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.get roles</screen>
    <para>
     Vergleichen Sie die Ausgabe mit dem tatsächlichen Layout des Clusters.
    </para>
   </step>
   <step>
    <para>
     Calamari führt einen geplanten Salt-Auftrag weiterhin aus, um den Cluster-Status zu prüfen. Löschen Sie den Auftrag:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>salt <replaceable>target</replaceable> schedule.delete ceph.heartbeat
</screen>
   </step>
   <step>
    <para>
     Fahren Sie ab hier gemäß <xref linkend="ceph-upgrade-4to5"/> fort.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-4to5crowbar">
  <title>Upgrade von SUSE Enterprise Storage 4 (Crowbar-Bereitstellung) auf Version 5</title>

  <important>
   <title>Softwareanforderungen</title>
   <para>
    Auf allen Ceph Nodes, auf denen das Upgrade durchgeführt werden soll, muss vor Beginn des Upgrade-Vorgangs die folgende Software installiert und auf die neueste Paketversion aktualisiert werden:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP2
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 4
     </para>
    </listitem>
   </itemizedlist>
  </important>

  <para>
   Führen Sie zum Upgrade von SUSE Enterprise Storage 4, das über Crowbar bereitgestellt wurde, auf Version 5 die folgenden Schritte aus:
  </para>

  <procedure>
   <step>
    <para>
     Stoppen und deaktivieren Sie alle auf Crowbar bezogenen Services für jeden Ceph Node (einschließlich Calamari Node):
    </para>
<screen>
<prompt>root@minion &gt; </prompt>sudo systemctl stop chef-client
<prompt>root@minion &gt; </prompt>sudo systemctl disable chef-client
<prompt>root@minion &gt; </prompt>sudo systemctl disable crowbar_join
<prompt>root@minion &gt; </prompt>sudo systemctl disable crowbar_notify_shutdown
</screen>
   </step>
   <step>
    <para>
     Verifizieren Sie für jeden Ceph Node (einschließlich Calamari Node), dass die Software-Repositorys auf die Produkte SUSE Enterprise Storage 5 und SUSE Linux Enterprise Server 12 SP3 verweisen. Wenn Repositorys, die auf ältere Produktversionen verweisen, noch vorhanden sind, müssen Sie sie deaktivieren.
    </para>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass für jeden Ceph Node (einschließlich Calamari Node) der
     <package>salt-minion</package> installiert ist. Falls nicht, installieren Sie ihn:
    </para>
<screen><prompt>root@minion &gt; </prompt>sudo zypper in salt salt-minion</screen>
   </step>
   <step>
    <para>
     Erstellen Sie für Ceph Nodes, auf denen das <package>salt-minion</package>
     -Paket nicht installiert war, die Datei <filename>/etc/salt/minion.d/master.conf</filename>, in der die Option <option>master</option> auf den vollständigen Calamari Node-Hostnamen verweist:
    </para>
<screen>master: <replaceable>full_calamari_hostname</replaceable></screen>
    <tip>
     <para>
      Für die bestehenden Salt Minions ist die <option>master:</option>-Option bereits in <filename>/etc/salt/minion.d/calamari.conf</filename> festgelegt. Der Name der Konfigurationsdatei spielt keine Rolle. Wichtig ist nur das Verzeichnis <filename>/etc/salt/minion.d/</filename>.
     </para>
    </tip>
    <para>
     Aktivieren und starten Sie den <systemitem class="daemon">salt-minion</systemitem> Service:
    </para>
<screen>
<prompt>root@minion &gt; </prompt>sudo systemctl enable salt-minion
<prompt>root@minion &gt; </prompt>sudo systemctl start salt-minion
</screen>
   </step>
   <step>
    <para>
     Akzeptieren Sie am Calamari Node alle verbleibenden Salt Minion-Schlüssel:
    </para>
<screen>
<prompt>root@master # </prompt>salt-key -L
[...]
Unaccepted Keys:
d52-54-00-16-45-0a.example.com
d52-54-00-70-ac-30.example.com
[...]

<prompt>root@master # </prompt>salt-key -A
The following keys are going to be accepted:
Unaccepted Keys:
d52-54-00-16-45-0a.example.com
d52-54-00-70-ac-30.example.com
Proceed? [n/Y] y
Key for minion d52-54-00-16-45-0a.example.com accepted.
Key for minion d52-54-00-70-ac-30.example.com accepted.
</screen>
   </step>
   <step>
    <para>
     Wenn Ceph im öffentlichen Netzwerk bereitgestellt wurde und keine VLAN-Schnittstelle vorhanden ist, fügen Sie eine VLAN-Schnittstelle im öffentlichen Netzwerk von Crowbar zum Calamari Node hinzu.
    </para>
   </step>
   <step>
    <para>
     Führen Sie im Calamari Node ein Upgrade auf SUSE Linux Enterprise Server 12 SP3 und SUSE Enterprise Storage 5 durch, entweder mithilfe von <command>zypper migration</command> oder Ihrer bevorzugten Methode. Ab hier wird der Calamari Node zum <emphasis>Salt Master</emphasis>. Neustarten Sie den Salt Master nach dem Upgrade.
    </para>
   </step>
   <step>
    <para>
     Installieren Sie DeepSea am Salt Master:
    </para>
<screen><prompt>root@master # </prompt>zypper in deepsea</screen>
   </step>
   <step>
    <para>
     Geben Sie die Option <option>deepsea_minions</option> an, um die korrekte Gruppe von Salt Minions in den Bereitstellungsstufen einzufügen. Weitere Informationen finden Sie in <xref linkend="ds-minion-targeting-dsminions"/>.
    </para>
   </step>
   <step>
    <para>
     DeepSea erwartet, dass die <filename>/etc/ceph/ceph.conf</filename> in allen Ceph Nodes identisch ist. Crowbar stellt in jedem Node eine leicht andere <filename>ceph.conf</filename> bereit, daher müssen Sie sie konsolidieren:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Entfernen Sie die Option <option>osd crush location hook</option>, da sie von Calamari hinzugefügt wurde.
      </para>
     </listitem>
     <listitem>
      <para>
       Entfernen Sie die Option <option>public addr</option> im Abschnitt <literal>[mon]</literal>.
      </para>
     </listitem>
     <listitem>
      <para>
       Entfernen Sie die Portnummern in der Option <option>mon host</option>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Wenn Sie das Object Gateway ausgeführt haben, hat Crowbar eine andere Datei <filename>/etc/ceph/ceph.conf.radosgw</filename> bereitgestellt, damit die Keystone-Geheimnisse von der regulären <filename>ceph.conf</filename>-Datei getrennt sind. Crowbar hat außerdem eine benutzerdefinierte Datei <filename>/etc/systemd/system/ceph-radosgw@.service</filename> hinzugefügt. Sie müssen diese entfernen, weil DeepSea sie nicht unterstützt:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Fügen Sie alle <literal>[client.rgw....]</literal>-Abschnitte der Datei <filename>ceph.conf.radosgw</filename> in allen Nodes an die Datei <filename>/etc/ceph/ceph.conf</filename> an.
      </para>
     </listitem>
     <listitem>
      <para>
       Führen Sie im Object Gateway Node Folgendes aus:
      </para>
<screen><prompt>root@minion &gt; </prompt>rm /etc/systemd/system/ceph-radosgw@.service
systemctl reenable ceph-radosgw@rgw.public.$<replaceable>hostname</replaceable></screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Vergewissern Sie sich, dass <command>ceph status</command> bei Ausführung vom Salt Master aus funktioniert:
    </para>
<screen><prompt>root@master # </prompt>ceph status
cluster a705580c-a7ae-4fae-815c-5cb9c1ded6c2
health HEALTH_OK
[...]
</screen>
   </step>
   <step>
    <para>
     Importieren Sie den bestehenden Cluster:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run populate.engulf_existing_cluster
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run push.proposal
</screen>
   </step>

   <step>
    <para>
     Das Kommando <command>salt-run populate.engulf_existing_cluster</command> verarbeitet nicht den Import der iSCSI Gateway-Konfigurationen. Wenn Ihr Cluster iSCSI Gateways enthält, importieren Sie deren Konfigurationen manuell:
    </para>
    <substeps>
     <step>
      <para>
       Exportieren Sie auf einem der iSCSI Gateway Nodes die aktuelle <filename>lrbd.conf</filename>-Datei und kopieren Sie sie in den Salt Master Node:
      </para>
<screen>
<prompt>root@minion &gt; </prompt>lrbd -o &gt; /tmp/lrbd.conf
<prompt>root@minion &gt; </prompt>scp /tmp/lrbd.conf admin:/srv/salt/ceph/igw/cache/lrbd.conf
</screen>
     </step>
     <step>
      <para>
       Fügen Sie im Salt Master Node die standardmäßige iSCSI Gateway-Konfiguration zum DeepSea Setup hinzu:
      </para>
<screen>
<prompt>root@master # </prompt>mkdir -p /srv/pillar/ceph/stack/ceph/
<prompt>root@master # </prompt>echo 'igw_config: default-ui' &gt;&gt; /srv/pillar/ceph/stack/ceph/cluster.yml
<prompt>root@master # </prompt>chown salt:salt /srv/pillar/ceph/stack/ceph/cluster.yml
</screen>
     </step>
     <step>
      <para>
       Fügen Sie die iSCSI Gateway-Rollen zu <filename>policy.cfg</filename> hinzu und speichern Sie die Datei:
      </para>
<screen>
role-igw/stack/default/ceph/minions/ses-1.ses.suse.yml
role-igw/cluster/ses-1.ses.suse.sls
[...]
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <substeps>
     <step>
      <para>
       Wenn Sie Ihr System bei SUSEConnect registriert haben und SCC/SMT verwenden, müssen Sie nichts weiter tun. 
      </para>
     </step>
     <step>
      <para>
       Wenn Sie SCC/SMT <emphasis role="bold">nicht</emphasis> verwenden, sondern eine Media-ISO oder eine andere Paketquelle, fügen Sie die folgenden Repositorys manuell hinzu: SLE12-SP3 Basis, SLE12-SP3 Update, SES5 Basis und SES5 Update. Verwenden Sie dazu das <command>zypper</command>-Kommando. Entfernen Sie zunächst alle vorhandenen Software-Repositorys. Fügen Sie dann die erforderlichen neuen Repositorys hinzu und aktualisieren Sie schließlich die Quellen der Repositorys:
      </para>
<screen>
<prompt>root # </prompt>zypper sd {0..99}
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/Storage/5/x86_64/product/ SES5-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/Storage/5/x86_64/update/ SES5-UPDATES
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Products/SLE-SERVER/12-SP3/x86_64/product/ SLES12-SP3-POOL
<prompt>root # </prompt>zypper ar \
 http://172.17.2.210:82/repo/SUSE/Updates/SLE-SERVER/12-SP3/x86_64/update/ SLES12-SP3-UPDATES
<prompt>root # </prompt>zypper ref
</screen>
      <para>
       Ändern Sie anschließend Ihre Pillar-Daten, um eine andere Strategie anzuwenden. Bearbeiten
      </para>
<screen>/srv/pillar/ceph/stack/<replaceable>name_of_cluster</replaceable>/cluster.yml</screen>
      <para>
       und fügen Sie die folgende Zeile hinzu:
      </para>
<screen>upgrade_init: zypper-dup</screen>
      <tip>
       <para>
        Für die <literal>zypper-dup</literal>-Strategie müssen Sie die neuesten Software-Repositorys hinzufügen. Die standardmäßige <literal>zypper-migration</literal>-Strategie dagegen verlässt sich auf die von SCC/SMT bereitgestellten Repositorys.
       </para>
      </tip>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Reparieren Sie Host Grains, damit DeepSea für die Ceph Daemon Instanz-IDs kurze Hostnamen im öffentlichen Netzwerk verwenden kann. Für jeden Node müssen Sie <command>grains.set</command> mit dem neuen (kurzen) Hostnamen ausführen. Verifizieren Sie vor dem Ausführen von <command>grains.set</command> die aktuellen Monitor-Instanzen, indem Sie <command>ceph status</command> ausführen. Nachfolgend sehen Sie ein Vorher-Nachher-Beispiel:
    </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.get host
d52-54-00-16-45-0a.example.com:
    d52-54-00-16-45-0a
d52-54-00-49-17-2a.example.com:
    d52-54-00-49-17-2a
d52-54-00-76-21-bc.example.com:
    d52-54-00-76-21-bc
d52-54-00-70-ac-30.example.com:
    d52-54-00-70-ac-30
</screen>
<screen>
<prompt>root@master # </prompt>salt d52-54-00-16-45-0a.example.com grains.set \
 host public.d52-54-00-16-45-0a
<prompt>root@master # </prompt>salt d52-54-00-49-17-2a.example.com grains.set \
 host public.d52-54-00-49-17-2a
<prompt>root@master # </prompt>salt d52-54-00-76-21-bc.example.com grains.set \
 host public.d52-54-00-76-21-bc
<prompt>root@master # </prompt>salt d52-54-00-70-ac-30.example.com grains.set \
 host public.d52-54-00-70-ac-30
</screen>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> grains.get host
d52-54-00-76-21-bc.example.com:
    public.d52-54-00-76-21-bc
d52-54-00-16-45-0a.example.com:
    public.d52-54-00-16-45-0a
d52-54-00-49-17-2a.example.com:
    public.d52-54-00-49-17-2a
d52-54-00-70-ac-30.example.com:
    public.d52-54-00-70-ac-30
</screen>
   </step>
   <step>
    <para>
     Führen Sie das Upgrade durch:
    </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> state.apply ceph.updates
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> test.version
<prompt>root@master # </prompt>salt-run state.orch ceph.maintenance.upgrade
</screen>
    <para>
     Jeder Node startet neu. Der Cluster startet und moniert, dass keine aktive Ceph Manager-Instanz vorhanden ist. Das ist normal. Calamari sollte zu diesem Zeitpunkt nicht mehr installiert sein bzw. ausgeführt werden.
    </para>
   </step>
   <step>
    <para>
     Führen Sie die erforderlichen Bereitstellungsschritte aus, um den Cluster in einen ordnungsgemäßen Zustand zu versetzen:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
</screen>
   </step>
   <step>
    <para>
     Fügen Sie zum Bereitstellen von openATTIC (weitere Informationen hierzu finden Sie im <xref linkend="ceph-oa"/>) eine entsprechende <literal>role-openattic</literal>-Zeile (weitere Informationen hierzu finden Sie in <xref linkend="policy-role-assignment"/>) zu<filename>/srv/pillar/ceph/proposals/policy.cfg</filename> hinzu und führen Sie dann Folgendes aus:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
   </step>
   <step>
    <para>
     Während des Upgrades wird die Fehlermeldung "Error EINVAL: entity [...] exists but caps do not match" angezeigt. Informationen zur Fehlerbehebung finden Sie in <xref linkend="ceph-upgrade-4to5"/>.
    </para>
   </step>
   <step>
    <para>
     Führen Sie die noch verbleibende Bereinigung durch:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Crowbar erstellt für jeden OSD Einträge in <filename>/etc/fstab</filename>. Löschen Sie diese, da sie nicht notwendig sind.
      </para>
     </listitem>
     <listitem>
      <para>
       Calamari führt einen geplanten Salt-Auftrag weiterhin aus, um den Cluster-Status zu prüfen. Löschen Sie den Auftrag:
      </para>
<screen>
<prompt>root@master # </prompt>salt <replaceable>target</replaceable> schedule.delete ceph.heartbeat
</screen>
     </listitem>
     <listitem>
      <para>
       Es sind immer noch einige unnötige Pakete installiert, meistens RubyGems und solche, die sich auf Chef beziehen. Sie müssen nicht unbedingt entfernt werden, doch Sie können sie löschen, indem Sie <command>zypper rm <replaceable>pkg_name</replaceable></command> ausführen.
      </para>
     </listitem>
    </itemizedlist>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph-upgrade-3to5">
  <title>Upgrade von SUSE Enterprise Storage 3 auf 5</title>

  <important>
   <title>Softwareanforderungen</title>
   <para>
    Auf allen Ceph Nodes, auf denen das Upgrade durchgeführt werden soll, muss vor Beginn des Upgrade-Vorgangs die folgende Software installiert und auf die neueste Paketversion aktualisiert werden:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SUSE Linux Enterprise Server 12 SP1
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE Enterprise Storage 3
     </para>
    </listitem>
   </itemizedlist>
  </important>

  <para>
   Führen Sie für ein Upgrade des SUSE Enterprise Storage 3-Clusters auf Version 5 die in <xref linkend="upgrade4to5cephdeploy-all"/> und dann <xref linkend="upgrade4to5cephdeploy-admin"/> beschriebenen Schritte aus.
  </para>
 </sect1>
</chapter>
