<?xml version="1.0" encoding="UTF-8"?>
<appendix xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_manual-install.xml" version="5.0" xml:id="app-storage-manual-inst">
 <title>Beispielverfahren einer manuellen Ceph Installation</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>Ja</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Im folgenden Verfahren sehen sie die Kommandos, die Sie zur manuellen Installation des Ceph Storage Clusters benötigen.
 </para>
 <procedure>
  <step>
   <para>
    Generieren Sie die Schlüsselgeheimnisse für die Ceph Services, die Sie ausführen möchten. Sie generieren sie mit folgendem Kommando:
   </para>
<screen>python -c "import os ; import struct ; import time; import base64 ; \
 key = os.urandom(16) ; header = struct.pack('&lt;hiih',1,int(time.time()),0,len(key)) ; \
 print base64.b64encode(header + key)"</screen>
  </step>
  <step>
   <para>
    Fügen Sie die Schlüssel zu den entsprechenden Schlüsselbunden hinzu. Zuerst für <systemitem class="username">client.admin</systemitem>, dann für die Monitors und danach für die anderen entsprechenden Services wie OSD, Object Gateway oder MDS:
   </para>
<screen>ceph-authtool -n client.admin \
 --create-keyring /etc/ceph/ceph.client.admin.keyring \
 --cap mds 'allow *' --cap mon 'allow *' --cap osd 'allow *'
ceph-authtool -n mon. \
 --create-keyring /var/lib/ceph/bootstrap-mon/ceph-osceph-03.keyring \
 --set-uid=0 --cap mon 'allow *'
ceph-authtool -n client.bootstrap-osd \
 --create-keyring /var/lib/ceph/bootstrap-osd/ceph.keyring \
 --cap mon 'allow profile bootstrap-osd'
ceph-authtool -n client.bootstrap-rgw \
 --create-keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring \
 --cap mon 'allow profile bootstrap-rgw'
ceph-authtool -n client.bootstrap-mds \
 --create-keyring /var/lib/ceph/bootstrap-mds/ceph.keyring \
 --cap mon 'allow profile bootstrap-mds'</screen>
  </step>
  <step>
   <para>
    Erstellen Sie eine "monmap", eine Datenbank aller Monitore in einem Cluster:
   </para>
<screen>monmaptool --create --fsid eaac9695-4265-4ca8-ac2a-f3a479c559b1 \
 /tmp/tmpuuhxm3/monmap
monmaptool --add osceph-02 192.168.43.60 /tmp/tmpuuhxm3/monmap
monmaptool --add osceph-03 192.168.43.96 /tmp/tmpuuhxm3/monmap
monmaptool --add osceph-04 192.168.43.80 /tmp/tmpuuhxm3/monmap</screen>
  </step>
  <step>
   <para>
    Erstellen Sie einen neuen Schlüsselbund und importieren Sie dort die Schlüssel aus dem Admin-Schlüsselbund und dem Schlüsselbund der Monitors. Starten Sie dann damit die Monitors:
   </para>
<screen>ceph-authtool --create-keyring /tmp/tmpuuhxm3/keyring \
 --import-keyring /var/lib/ceph/bootstrap-mon/ceph-osceph-03.keyring
ceph-authtool /tmp/tmpuuhxm3/keyring \
 --import-keyring /etc/ceph/ceph.client.admin.keyring
sudo -u ceph ceph-mon --mkfs -i osceph-03 \
 --monmap /tmp/tmpuuhxm3/monmap --keyring /tmp/tmpuuhxm3/keyring
systemctl restart ceph-mon@osceph-03</screen>
  </step>
  <step>
   <para>
    Überprüfen Sie den Zustand der Monitors in <systemitem class="daemon">systemd</systemitem>:
   </para>
<screen>systemctl show --property ActiveState ceph-mon@osceph-03</screen>
  </step>
  <step>
   <para>
    Prüfen Sie, ob Ceph ausgeführt wird und den Monitorstatus meldet:
   </para>
<screen>ceph --cluster=ceph \
 --admin-daemon /var/run/ceph/ceph-mon.osceph-03.asok mon_status</screen>
  </step>
  <step>
   <para>
    Prüfen Sie den Status des spezifischen Service anhand der vorhandenen Schlüssel:
   </para>
<screen>ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin -f json-pretty status
[...]
ceph --connect-timeout 5 \
 --keyring /var/lib/ceph/bootstrap-mon/ceph-osceph-03.keyring \
 --name mon. -f json-pretty status</screen>
  </step>
  <step>
   <para>
    Importieren Sie den Schlüsselbund von den bestehenden Ceph Services und überprüfen Sie den Status:
   </para>
<screen>ceph auth import -i /var/lib/ceph/bootstrap-osd/ceph.keyring
ceph auth import -i /var/lib/ceph/bootstrap-rgw/ceph.keyring
ceph auth import -i /var/lib/ceph/bootstrap-mds/ceph.keyring
ceph --cluster=ceph \
 --admin-daemon /var/run/ceph/ceph-mon.osceph-03.asok mon_status
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin -f json-pretty status</screen>
  </step>
  <step>
   <para>
    Bereiten Sie anhand des XFS-Dateisystems die Datenträger/Partitionen für OSDs vor:
   </para>
<screen>ceph-disk -v prepare --fs-type xfs --data-dev --cluster ceph \
 --cluster-uuid eaac9695-4265-4ca8-ac2a-f3a479c559b1 /dev/vdb
ceph-disk -v prepare --fs-type xfs --data-dev --cluster ceph \
 --cluster-uuid eaac9695-4265-4ca8-ac2a-f3a479c559b1 /dev/vdc
[...]</screen>
  </step>
  <step>
   <para>
    Aktivieren Sie die Partitionen:
   </para>
<screen>ceph-disk -v activate --mark-init systemd --mount /dev/vdb1
ceph-disk -v activate --mark-init systemd --mount /dev/vdc1</screen>
  </step>
  <step>
   <para>
    Erstellen Sie für SUSE Enterprise Storage Version 2.1 und ältere Versionen die Standardpools:
   </para>
<screen>ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .users.swift 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .intent-log 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .rgw.gc 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .users.uid 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .rgw.control 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .users 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .usage 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .log 16 16
ceph --connect-timeout 5 --keyring /etc/ceph/ceph.client.admin.keyring \
 --name client.admin osd pool create .rgw 16 16</screen>
  </step>
  <step>
   <para>
    Erstellen Sie den Schlüssel der Object Gateway-Instanz aus dem Bootstrap-Schlüssel:
   </para>
<screen>ceph --connect-timeout 5 --cluster ceph --name client.bootstrap-rgw \
 --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create \
 client.rgw.0dc1e13033d2467eace46270f0048b39 osd 'allow rwx' mon 'allow rw' \
 -o /var/lib/ceph/radosgw/ceph-rgw.<replaceable>rgw_name</replaceable>/keyring
  </screen>
  </step>
  <step>
   <para>
    Aktiveren und starten Sie Object Gateway:
   </para>
<screen>systemctl enable ceph-radosgw@rgw.<replaceable>rgw_name</replaceable>
systemctl start ceph-radosgw@rgw.<replaceable>rgw_name</replaceable></screen>
  </step>
  <step>
   <para>
    Erstellen Sie optional den Schlüssel der MDS-Instanz aus dem Bootstrap-Schlüssel. Aktivieren und starten Sie MDS:
   </para>
<screen>ceph --connect-timeout 5 --cluster ceph --name client.bootstrap-mds \
 --keyring /var/lib/ceph/bootstrap-mds/ceph.keyring auth get-or-create \
 mds.mds.<replaceable>rgw_name</replaceable> osd 'allow rwx' mds allow mon \
 'allow profile mds' \
 -o /var/lib/ceph/mds/ceph-mds.<replaceable>rgw_name</replaceable>/keyring
systemctl enable ceph-mds@mds.<replaceable>rgw_name</replaceable>
systemctl start ceph-mds@mds.<replaceable>rgw_name</replaceable></screen>
  </step>
 </procedure>
</appendix>
