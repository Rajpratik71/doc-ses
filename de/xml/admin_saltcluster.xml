<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_saltcluster.xml" version="5.0" xml:id="storage-salt-cluster">
 <title>Cluster-Verwaltung mit Salt</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>Ja</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Nach der Bereitstellung des Ceph Clusters müssen Sie wahrscheinlich gelegentlich einige Änderungen daran vornehmen. Dazu gehört das Hinzufügen oder Entfernen neuer Nodes, Festplatten oder Services. In diesem Kapitel wird erläutert, wie Sie diese Verwaltungsaufgaben erledigen.
 </para>
 <sect1 xml:id="salt-adding-nodes">
  <title>Hinzufügen neuer Cluster Nodes</title>

  <para>
   Das Verfahren zum Hinzufügen neuer Nodes zum Cluster ist in etwa identisch mit der ersten Bereitstellung eines Cluster Nodes, die im <xref linkend="ceph-install-saltstack"/> erläutert wird:
  </para>

  <procedure>
   <step>
    <para>
     Installieren Sie SUSE Linux Enterprise Server 12 SP3 im neuen Node, konfigurieren Sie dessen Netzwerkeinstellung, sodass der Hostname des Salt Masters korrekt aufgelöst wird, und installieren Sie das Paket <systemitem>salt-minion</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper in salt-minion</screen>
    <para>
     Wenn der Hostname des Salt Masters nicht <literal>salt</literal> lautet, bearbeiten Sie <filename>/etc/salt/minion</filename> und fügen Sie Folgendes hinzu:
    </para>
<screen>master: <replaceable>DNS_name_of_your_salt_master</replaceable></screen>
    <para>
     Wenn Sie an den oben genannten Konfigurationsdateien Änderungen vorgenommen haben, starten Sie den Service <systemitem>salt.minion</systemitem> neu:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <para>
     Akzeptieren Sie alle Salt-Schlüssel am Salt Master:
    </para>
<screen><prompt>root@master # </prompt>salt-key --accept-all</screen>
   </step>
   <step>
    <para>
     Verifizieren Sie, dass <filename>/srv/pillar/ceph/deepsea_minions.sls</filename> auch den neuen Salt Minion adressiert. Weitere Informationen finden Sie im <xref linkend="ds-minion-targeting-name"/> und im <xref linkend="ds-depl-stages"/>.
    </para>
   </step>
   <step>
    <para>
     Führen Sie die Vorbereitungsphase durch. In dieser Phase werden die Module und Grains synchronisiert, sodass der neue Minion alle Informationen zur Verfügung stellen kann, die von DeepSea erwartet werden:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
   </step>
   <step>
    <para>
     Führen Sie die Ermittlungsphase durch. In dieser Phase werden neue Dateieinträge im Verzeichnis <filename>/srv/pillar/ceph/proposals</filename> geschrieben, wo Sie relevante YML-Dateien bearbeiten können:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Ändern Sie optional <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>, falls der neu hinzugefügte Host nicht dem bestehenden Benennungsschema entspricht. Detaillierte Informationen finden Sie im <xref linkend="policy-configuration"/>.
    </para>
   </step>
   <step>
    <para>
     Führen Sie die Konfigurationsphase durch. In dieser Phase wird alles unter <filename>/srv/pillar/ceph</filename> gelesen und der Pillar wird entsprechend aktualisiert:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
    <para>
     Im Pillar sind Daten gespeichert, auf die Sie mit dem folgenden Kommando zugreifen:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.items</screen>
   </step>
   <step>
    <para>
     Die Konfigurations- und Bereitstellungsphasen umfassen neu hinzugefügte Nodes:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-adding-services">
  <title>Hinzufügen neuer Rollen zu Nodes</title>

  <para>
   Mit DeepSea stellen Sie alle Typen von unterstützten Rollen bereit. Weitere Informationen zu unterstützten Rollentypen und Beispiele zu deren Abgleich finden Sie im <xref linkend="policy-role-assignment"/>.
  </para>

  <tip>
   <title>Erforderliche und optionale Rollen und Phasen</title>
   <para>
    Grundsätzlich empfehlen wir, alle Bereitstellungsphasen 0 bis 5 auszuführen, wenn Sie eine neue Rolle zu einem Cluster Node hinzufügen. Um Zeit zu sparen, können Sie die Phase 3 oder 4 überspringen, je nach dem Typ der Rolle, die Sie bereitstellen möchten. Die OSD- und MON-Rollen enthalten grundlegende Services und sind für Ceph erforderlich. Andere Rollen wie das Object Gateway sind optional. DeepSea-Bereitstellungsphasen sind hierarchisch: Phase 3 stellt grundlegende Services bereit, Phase 4 optionale.
   </para>
   <para>
    Daher müssen Sie Phase 3 ausführen, wenn Sie grundlegende Rollen wie MON in einem bestehenden OSD-Node ausführen und können Phase 4 überspringen.
   </para>
   <para>
    Entsprechend können Sie Phase 3 überspringen, wenn Sie optionale Services wie Object Gateway bereitstellen, müssen in diesem Fall jedoch Phase 4 ausführen.
   </para>
  </tip>

  <para>
   Führen Sie die folgenden Schritte aus, um einen neuen Service zu einem bestehenden Node hinzuzufügen:
  </para>

  <procedure>
   <step>
    <para>
     Passen Sie <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> so an, dass der bestehende Host mit einer neuen Rolle abgeglichen wird. Weitere Informationen finden Sie im <xref linkend="policy-configuration"/>. Wenn Sie beispielsweise ein Object Gateway in einem MON Node ausführen müssen, sieht die Zeile in etwas so aus:
    </para>
<screen>role-rgw/xx/x/example.mon-1.sls</screen>
   </step>
   <step>
    <para>
     Führen Sie Phase 2 für das Update des Pillar aus:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Führen Sie Phase 3 zum Bereitstellen von grundlegenden Services aus bzw. Phase 4 zum Bereitstellen optionaler Services. Es kann jedoch nicht schaden, beide Phasen auszuführen.
    </para>
   </step>
  </procedure>

  <tip>
   <para>
    Denken Sie beim Hinzufügen eines OSD zum bestehenden Cluster daran, dass der Cluster danach einige Zeit zum Ausgleich benötigt. Wir empfehlen, alle gewünschten OSDs zur selben Zeit hinzuzufügen, um den Zeitraum für den Ausgleich so kurz wie möglich zu halten.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="salt-node-removing">
  <title>Entfernen und erneute Installation von Cluster Nodes</title>

  <para>
   Bearbeiten Sie zum Entfernen einer Rolle aus dem Cluster die Datei <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> und entfernen Sie die entsprechenden Zeilen. Führen Sie Phase 2 und 5 aus wie im <xref linkend="ceph-install-stack"/> erläutert.
  </para>

  <note>
   <title>Entfernen von OSDs aus Ihrem Cluster</title>
   <para>
    Falls Sie einen bestimmten OSD-Node aus Ihrem Cluster entfernen müssen, stellen Sie sicher, dass Ihr Cluster mehr freien Speicherplatz hat als die Festplatte, die Sie entfernen möchten. Bedenken Sie, dass durch Entfernen eines OSD ein Ausgleich des gesamten Clusters durchgeführt wird.
   </para>
  </note>

  <para>
   Wenn eine Rolle von einem Minion entfernt wird, sollen damit alle Änderungen in Bezug auf diese Rolle rückgängig gemacht werden. Bei den meisten Rollen ist diese Aufgabe problemlos zu bewältigen, doch es gibt möglicherweise Probleme bei Paketabhängigkeiten. Wenn ein Paket deinstalliert wird, bleiben die Abhängigkeiten bestehen.
  </para>

  <para>
   Entfernte OSDs werden als leere Laufwerke angezeigt. Die entsprechenden Aufgaben überschreiben den Anfang des Dateisystems, entfernen Sicherungspartitionen und löschen die Partitionstabellen endgültig.
  </para>

  <note>
   <title>Beibehalten von Partitionen, die anhand anderer Methoden erstellt wurden</title>
   <para>
    Festplattenlaufwerke, die früher anhand anderer Methoden wie <command>ceph-deploy</command> konfiguriert wurden, enthalten möglicherweise immer noch Partitionen. Diese werden von DeepSea nicht automatisch zerstört. Der Administrator muss alle auf diesen Laufwerken noch enthaltenen Partitionen entfernen.
   </para>
  </note>

  <example xml:id="ex-ds-rmnode">
   <title>Entfernen eines Salt Minion vom Cluster</title>
   <para>
    Wenn Ihre Speicher-Minions benannt wurden, wie zum Beispiel "data1.ceph", "data2.ceph" ... "data6.ceph", und wenn die entsprechenden Zeilen in Ihrer Datei <filename>policy.cfg</filename> so ähnlich aussehen wie die folgende:
   </para>
<screen>[...]
# Hardware Profile
profile-default/cluster/data*.sls
profile-default/stack/default/ceph/minions/data*.yml
[...]</screen>
   <para>
    Dann müssen Sie zum Entfernen des Salt Minion "data2.ceph" die Zeile folgendermaßen ändern:
   </para>
<screen>
[...]
# Hardware Profile
profile-default/cluster/data[1,3-6]*.sls
profile-default/stack/default/ceph/minions/data[1,3-6]*.yml
[...]</screen>
   <para>
    Führen Sie dann die Phasen 2 und 5 aus:
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5</screen>
  </example>

  <example xml:id="ex-ds-mignode">
   <title>Migrieren von Nodes</title>
   <para>
    Stellen Sie sich folgende Situation vor: Während der ersten Cluster-Installation haben Sie (als Administrator) einen der Speicher-Nodes als eigenständiges Object Gateway zugeordnet und warten noch auf die Lieferung der Gateway-Hardware. Die permanente Hardware für das Gateway wird schließlich geliefert und Sie können die vorgesehene Rolle zum Sicherungsspeicher-Node zuweisen und die Gateway-Rolle entfernen.
   </para>
   <para>
    Nach Ausführung der Phasen 0 und 1 (Informationen hierzu finden Sie im<xref linkend="ds-depl-stages"/>) für die neue Hardware, haben Sie das neue Gateway <literal>rgw1</literal> genannt. Wenn für Node <literal>data8</literal> die Object Gateway-Rolle entfernt und die Speicher-Rolle hinzugefügt werden muss und die aktuelle Datei <filename>policy.cfg</filename> folgendermaßen aussieht:
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-7]*.sls
profile-default/stack/default/ceph/minions/data[1-7]*.sls

# Roles
role-rgw/cluster/data8*.sls</screen>
   <para>
    Dann ändern Sie die Datei zu:
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-8]*.sls
profile-default/stack/default/ceph/minions/data[1-8]*.sls

# Roles
role-rgw/cluster/rgw1*.sls</screen>
   <para>
    Führen Sie die Phasen 2 und 5 aus. Phase 3 fügt <literal>data8</literal> als Speicher-Node hinzu. Einen Moment lang verfügt <literal>data8</literal> über beide Rollen. In Phase 4 wird die Object Gateway-Rolle zu <literal>rgw1</literal> hinzugefügt und in Phase 5 wird die Object Gateway-Rolle von <literal>data8</literal> entfernt.
   </para>
  </example>
 </sect1>
 <sect1 xml:id="ds-mon">
  <title>Erneute Bereitstellung von Monitor Nodes</title>

  <para>
   Wenn bei einem oder mehreren Monitor Nodes Fehler auftreten und sie nicht mehr antworten, müssen Sie die fehlerhaften Monitors aus dem Cluster entfernen und sie möglicherweise im Cluster wieder neu hinzufügen.
  </para>

  <important>
   <title>Das Minimum ist drei Monitor Nodes</title>
   <para>
    Es müssen mindestens drei Monitor Nodes vorhanden sein. Wenn bei einem Monitor Node ein Fehler auftritt und Ihr Cluster deshalb nur noch einen oder zwei Monitor Nodes enthält, müssen Sie die Monitor-Rolle vorübergehend anderen Cluster Nodes hinzufügen, bevor Sie die fehlerhaften Monitor Nodes neu bereitstellen. Sie können die temporären Monitor-Rollen deinstallieren, nachdem Sie die fehlerhaften Monitor Nodes neu bereitgestellt haben.
   </para>
   <para>
    Weitere Informationen zum Hinzufügen neuer Nodes/Rollen zum Ceph Cluster finden Sie in <xref linkend="salt-adding-nodes"/> und <xref linkend="salt-adding-services"/>.
   </para>
   <para>
    Weitere Informationen zum Entfernen von Cluster Nodes finden Sie in <xref linkend="salt-node-removing"/>.
   </para>
  </important>

  <para>
   Es gibt zwei grundlegende Grade von Ceph Node-Fehlern:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Der Salt Minion ist entweder physisch defekt oder auf Betriebssystemebene beschädigt und antwortet nicht bei Aufruf von <command>salt '<replaceable>minion_name</replaceable>' test.ping</command>. In diesem Fall müssen Sie den Server vollständig neu bereitstellen. Befolgen Sie dazu die entsprechenden Anweisungen im <xref linkend="ceph-install-stack"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Bei den auf den Monitor bezogenen Services sind Fehler aufgetreten und sie lassen sich nicht wiederherstellen, doch der Host antwortet bei Aufruf von <command>salt '<replaceable>minion_name</replaceable>' test.ping</command>. Führen Sie in diesem Fall die folgenden Schritte aus:
    </para>
   </listitem>
  </itemizedlist>

  <procedure>
   <step>
    <para>
     Bearbeiten Sie <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> am Salt Master und entfernen oder aktualisieren Sie die Zeilen, die sich auf die fehlerhaften Monitor Nodes beziehen, sodass diese nun auf die funktionierenden Monitor Nodes zeigen.
    </para>
   </step>
   <step>
    <para>
     Führen Sie die DeepSea-Phasen 2 bis 5 aus, um die Änderungen anzuwenden:
    </para>
<screen>
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.4
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.5
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-node-add-disk">
  <title>Hinzufügen eines OSD zu einem Node</title>

  <para>
   Verifizieren Sie zum Hinzufügen einer Festplatte zu einem bestehenden OSD-Node, dass alle Partitionen auf der Festplatte entfernt und diese vollständig gelöscht wurde. Weitere detaillierte Informationen finden Sie in <xref linkend="deploy-wiping-disk"/> im <xref linkend="ceph-install-stack"/>. Wenn die Festplatte leer ist, fügen Sie diese zur YAML-Datei des Nodes hinzu. Der Pfad zur Datei lautet <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/<replaceable>node_name</replaceable>.yml</filename>. Führen Sie nach dem Speichern der Datei die DeepSea-Phasen 2 und 3 aus:
  </para>

<screen><prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>

  <tip>
   <title>Profile automatisch aktualisiert</title>
   <para>
    Statt die YAML-Datei manuell zu bearbeiten, können Sie DeepSea neue Profile erstellen lassen. Die bestehenden Profile müssen entfernt werden, damit DeepSea neue Profile erstellen kann:
   </para>
<screen><prompt>root@master # </prompt><command>old</command> /srv/pillar/ceph/proposals/profile-default/
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.1
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>
  </tip>
 </sect1>
 <sect1 xml:id="salt-removing-osd">
  <title>Entfernen eines OSD</title>

  <para>
   Durch Ausführen des folgenden Kommandos entfernen Sie einen Ceph OSD aus dem Cluster:
  </para>

<screen><prompt>root@master # </prompt><command>salt-run</command> disengage.safety
<prompt>root@master # </prompt><command>salt-run</command> remove.osd <replaceable>OSD_ID</replaceable></screen>

  <para>
   <replaceable>OSD_ID</replaceable> muss die Nummer des OSD ohne <literal>osd</literal> sein. Beispiel: Von <literal>osd.3</literal> verwenden Sie nur die Zahl <literal>3</literal>.
  </para>

  <tip>
   <title>Entfernen mehrerer OSDs</title>
   <para>
    Es ist nicht möglich, mit dem Kommando <command>salt-run remove.osd</command> mehrere OSDs gleichzeitig zu entfernen. Um den Vorgang zum Entfernen mehrerer OSDs zu automatisieren, verwenden Sie folgende Schleife (5, 21, 33, 19 sind ID-Nummern der zu entfernenden OSDs):
   </para>
<screen>
for i in 5 21 33 19
do
 echo $i
 salt-run disengage.safety
 salt-run remove.osd $i
done
</screen>
  </tip>

  <sect2 xml:id="osd-forced-removal">
   <title>Entfernen fehlerhafter OSDs erzwingen</title>
   <para>
    In manchen Fällen ist es nicht möglich, einen OSD ordnungsgemäß zu entfernen (weitere Informationen hierzu finden Sie in <xref linkend="salt-removing-osd"/>). Dies ist beispielsweise der Fall, wenn der OSD oder dessen Cache beschädigt ist, wenn E/A-Operationen hängen geblieben sind oder wenn sich die OSD-Festplatte nicht aushängen lässt. In einem derartigen Fall müssen Sie den Vorgang zum Entfernen des OSD erzwingen:
   </para>
<screen><prompt>root@master # </prompt><replaceable>target</replaceable> osd.remove <replaceable>OSD_ID</replaceable> force=True</screen>
   <para>
    Durch dieses Kommando wird sowohl die Datenpartition entfernt als auch das Journal oder die WAL/DB-Partitionen.
   </para>
   <para>
    Führen Sie die folgenden Schritte aus, um mögliche bezuglose Journal/WAL/DB-Geräte zu erkennen:
   </para>
   <procedure>
    <step>
     <para>
      Wählen Sie das Gerät, auf dem sich möglicherweise bezuglose Partitionen befinden, und speichern Sie die Liste dieser Partitionen in eine Datei:
     </para>
<screen>
<prompt>root@minion &gt; </prompt>ls /dev/sdd?* &gt; /tmp/partitions
</screen>
    </step>
    <step>
     <para>
      Führen Sie <command>readlink</command> gegen alle "block.wal"-, "block.db"- und "journal"-Geräte aus und vergleichen Sie die Ausgabe mit der vorher gespeicherten Liste der Partitionen:
     </para>
<screen>
<prompt>root@minion &gt; </prompt>readlink -f /var/lib/ceph/osd/ceph-*/{block.wal,block.db,journal} \
 | sort | comm -23 /tmp/partitions -
</screen>
     <para>
      Die Ausgabe stellt die Liste der Partitionen dar, die <emphasis>nicht</emphasis> von Ceph genutzt werden.
     </para>
    </step>
    <step>
     <para>
      Entfernen Sie die bezuglosen Partitionen, die nicht zu Ceph gehören, mit Ihrem bevorzugten Kommando (beispielsweise <command>fdisk</command>, <command>parted</command> oder <command>sgdisk</command>).
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ds-osd-recover">
  <title>Wiederherstellen eines erneut installierten OSD-Nodes</title>

  <para>
   Wenn das Betriebssystem in einem Ihrer OSD-Nodes abstürzt und sich nicht wiederherstellen lässt, führen Sie die folgenden Schritte aus, um es wiederherzustellen und seine OSD-Rolle mit den unveränderten Cluster-Daten neu bereitzustellen:
  </para>

  <procedure>
   <step>
    <para>
     Führen Sie eine erneute Installation des Betriebssystems im Node durch.
    </para>
   </step>
   <step>
    <para>
     Installieren Sie die <package>salt-minion</package>-Pakete im OSD-Node, löschen Sie den alten Salt Minion-Schlüssel am Salt Master und registrieren Sie den neuen Schlüssel des Salt Minions beim Salt Master. Weitere Informationen zur Salt Minion-Bereitstellung finden Sie im <xref linkend="ceph-install-stack"/>.
    </para>
   </step>
   <step>
    <para>
     Führen Sie statt der gesamten Phase 0 nur die folgenden Teile aus:
    </para>
<screen>
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.sync
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.packages.common
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.mines
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.updates
</screen>
   </step>
   <step>
    <para>
     Führen Sie die DeepSea-Phasen 1 bis 5 aus:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5
</screen>
   </step>
   <step>
    <para>
     Führen Sie DeepSea-Phase 0 aus:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
</screen>
   </step>
   <step>
    <para>
     Neustarten Sie den relevanten OSD-Node. Alle OSD-Festplatten werden neu ermittelt und wiederverwendet.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt-automated-installation">
  <title>Automatische Installation mit Salt</title>

  <para>
   Die Installation kann mithilfe des Salt-Reaktors automatisiert werden. In virtuellen Umgebungen oder konsistenten Hardwareumgebungen ermöglicht diese Konfiguration die Erstellung eines Ceph Clusters mit dem angegebenen Verhalten.
  </para>

  <warning>
   <para>
    Salt kann keine Abhängigkeitsprüfungen auf Basis von Reaktorereignissen durchführen. Das Risiko ist groß, dass Ihr Salt Master dadurch überlastet wird und nicht mehr antwortet.
   </para>
  </warning>

  <para>
   Für die automatische Installation ist Folgendes erforderlich:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Eine ordnungsgemäß erstellte Datei <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     Eine vorbereitete benutzerdefinierte Konfiguration, die in das Verzeichnis  <filename>/srv/pillar/ceph/stack</filename> gestellt wurde.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Die standardmäßige Reaktorkonfiguration führt nur die Phasen 0 und 1 aus. Dadurch kann der Reaktor gestestet werden, ohne auf die Ausführung der nachfolgenden Phasen warten zu müssen.
  </para>

  <para>
   Wenn der erste "salt-minion" startet, beginnt Phase 0. Eine Sperre verhindert mehrere Instanzen. Phase 1 beginnt, wenn alle Minions Phase 0 abgeschlossen haben.
  </para>

  <para>
   Wenn der Vorgang ordnungsgemäß durchgeführt wird, ändern Sie die letzte Zeile in Datei <filename>/etc/salt/master.d/reactor.conf</filename>:
  </para>

<screen>- /srv/salt/ceph/reactor/discovery.sls</screen>

  <para>
   zu
  </para>

<screen>- /srv/salt/ceph/reactor/all_stages.sls</screen>
 </sect1>
 <sect1 xml:id="deepsea-rolling-updates">
  <title>Aktualisieren der Cluster Nodes</title>

  <para>
   Es empfiehlt sich, regelmäßig die verfügbaren Rolling Releases auf die Nodes Ihres Clusters anzuwenden. Führen Sie Phase 0 aus, um die Updates anzuwenden:
  </para>

<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>

  <para>
   Wenn DeepSea einen aktiven Ceph Cluster erkennt, wendet es Updates an und startet die Nodes der Reihe nach neu. DeepSea hält sich an die offizielle Empfehlung von Ceph, zunächst die Monitors zu aktualisieren, dann die OSDs und zuletzt zusätzliche Services wie MDS, Object Gateway, iSCSI Gateway oder NFS Ganesha. DeepSea stoppt den Update-Vorgang, wenn es ein Problem im Cluster erkennt. Dies wird möglicherweise ausgelöst durch Folgendes:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Ceph zeigt die Meldung "HEALTH_ERR" länger als 300 Sekunden an.
    </para>
   </listitem>
   <listitem>
    <para>
     Auf den Salt Minions wird abgefragt, ob ihre zugewiesenen Services nach dem Update noch aktiv sind und ausgeführt werden. Das Update wird nicht ausgeführt, wenn die Services länger als 900 Sekunden inaktiv sind.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Durch diese Maßnahmen wird sichergestellt, dass der Ceph Cluster funktionsfähig bleibt, auch wenn Updates beschädigt sind oder nicht durchgeführt werden können.
  </para>

  <para>
   DeepSea Phase 0 aktualisiert das System mittels <command>zypper update</command> und neustartet das System, wenn der Kernel aktualisiert ist. Stellen Sie sicher, dass der neueste Kernel installiert ist und ausgeführt wird, bevor Sie DeepSea Phase 0 initiieren, wenn Sie die Möglichkeit eines erzwungenen Neustarts potenziell aller Nodes ausschließen möchten.
  </para>

  <tip>
   <title><command>zypper patch</command></title>
   <para>
    Wenn Sie das System lieber mit dem Kommando <command>zypper patch</command> aktualisieren möchten, bearbeiten Sie <filename>/srv/pillar/ceph/stack/global.yml</filename> und fügen Sie folgende Zeile hinzu:
   </para>
<screen>update_method_init: zypper-patch</screen>
  </tip>

  <para>
   Das standardmäßige Neustartverhalten von DeepSea Phase 0 lässt sich durch Hinzufügen der folgenden Zeilen zu Datei <filename>/srv/pillar/ceph/stack/global.yml</filename> ändern:
  </para>

<screen>stage_prep_master: default-update-no-reboot
stage_prep_minion: default-update-no-reboot</screen>

  <para>
   Mit <literal>stage_prep_master</literal> wird das Verhalten des Salt Masters in Phase 0 festgelegt, mit <literal>stage_prep_minion</literal> das Verhalten aller Minions. Die folgenden Parameter sind verfügbar:
  </para>

  <variablelist>
   <varlistentry>
    <term>default</term>
    <listitem>
     <para>
      Installiert die Updates und neustartet nach dem Update-Vorgang.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-update-no-reboot</term>
    <listitem>
     <para>
      Installiert die Updates ohne Neustart.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-reboot</term>
    <listitem>
     <para>
      Neustart ohne Installation der Updates.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-no-reboot</term>
    <listitem>
     <para>
      Updates werden nicht installiert und es wird kein Neustart durchgeführt.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-salt-cluster-reboot">
  <title>Anhalten oder Neustarten des Clusters</title>

  <para>
   In einigen Fällen muss möglicherweise der gesamte Cluster angehalten oder neugestartet werden. Wir empfehlen, sorgfältig nach Abhängigkeiten von aktiven Services zu suchen. Die folgenden Schritte beschreiben den Vorgang zum Stoppen und Starten des Clusters:
  </para>

  <procedure>
   <step>
    <para>
     Weisen Sie den Ceph Cluster an, für OSDs die Flagge "noout" zu setzen:
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd set noout</screen>
   </step>
   <step>
    <para>
     Stoppen Sie die Daemons und Nodes in der folgenden Reihenfolge:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Speicher-Clients
      </para>
     </listitem>
     <listitem>
      <para>
       Gateways wie NFS Ganesha oder Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Metadata Server
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Führen Sie Wartungsaufgaben aus, falls erforderlich.
    </para>
   </step>
   <step>
    <para>
     Starten Sie die Nodes und Server in umgekehrter Reihenfolge des Herunterfahrens:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Metadata Server
      </para>
     </listitem>
     <listitem>
      <para>
       Gateways wie NFS Ganesha oder Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Speicher-Clients
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Entfernen Sie die Flagge "noout":
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd unset noout</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ds-custom-cephconf">
  <title>Benutzerdefinierte Datei <filename>ceph.conf</filename></title>

  <para>
   Wenn Sie benutzerdefinierte Einstellungen zu Datei <filename>ceph.conf</filename> hinzufügen müssen, können Sie dazu die Konfigurationsdateien im Verzeichnis <filename>/srv/salt/ceph/configuration/files/ceph.conf.d</filename> entsprechend ändern:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     global.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mon.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mgr.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mds.conf
    </para>
   </listitem>
   <listitem>
    <para>
     osd.conf
    </para>
   </listitem>
   <listitem>
    <para>
     client.conf
    </para>
   </listitem>
   <listitem>
    <para>
     rgw.conf
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>Eindeutige <filename>rgw.conf</filename></title>
   <para>
    Das Object Gateway bietet ein hohes Maß an Flexibilität und ist einzigartig verglichen mit anderen Abschnitten von <filename>ceph.conf</filename>. Alle anderen Ceph-Komponenten weisen statische Header auf wie <literal>[mon]</literal> oder <literal>[osd]</literal>. Das Object Gateway weist eindeutige Header auf wie <literal>[client.rgw.rgw1]</literal>. Dies bedeutet, dass für Datei <filename>rgw.conf</filename> ein Header-Eintrag erforderlich ist. Ein Beispiel hierzu finden Sie in Datei <filename>/srv/salt/ceph/configuration/files/rgw.conf</filename>.
   </para>
  </note>

  <important>
   <title>Phase 3 ausführen</title>
   <para>
    Führen Sie Phase 3 aus, nachdem Sie benutzerdefinierte Änderungen an den oben genannten Konfigurationsdateien vorgenommen haben. Die Änderungen werden dadurch auf die Cluster Nodes angewendet:
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
  </important>

  <para>
   Diese Dateien werden aus der Vorlagendatei <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> übernommen. Sie entsprechen den verschiedenen Abschnitten, die von der Ceph-Konfigurationsdatei akzeptiert werden. Wenn Sie einen Konfigurationsausschnitt in die richtige Datei einfügen, kann DeepSea diesen Ausschnitt in den richtigen Abschnitt platzieren. Sie brauchen keine der Abschnitts-Header hinzuzufügen.
  </para>

  <tip>
   <para>
    Fügen Sie einen Header wie <literal>[osd.1]</literal> hinzu, wenn Sie Konfigurationsoptionen nur auf bestimmte Instanzen eines Daemon anwenden möchten. Die folgenden Konfigurationsoptionen werden nur auf den OSD Daemon mit ID 1 angewendet.
   </para>
  </tip>

  <sect2>
   <title>Außerkraftsetzen der Standardeinstellungen</title>
   <para>
    Ältere Anweisungen in einem Abschnitt werden durch neuere überschrieben. Somit ist es möglich, die in der Vorlage <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> angegebene Standardkonfiguration außer Kraft zu setzen. Beispiel: Fügen Sie die folgenden drei Zeilen zu Datei <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename> hinzu, um die cephx-Authentifizierung auszuschalten:
   </para>
<screen>auth cluster required = none
auth service required = none
auth client required = none</screen>
  </sect2>

  <sect2>
   <title>Einbeziehen von Konfigurationsdateien</title>
   <para>
    Wenn Sie viele benutzerdefinierte Konfigurationen anwenden müssen, erleichtern Sie die Dateiverwaltung anhand der folgenden "include"-Anweisungen in den benutzerdefinierten Konfigurationsdateien. Nachfolgend sehen Sie ein Beispiel der Datei <filename>osd.conf</filename>:
   </para>
<screen>[osd.1]
{% include "ceph/configuration/files/ceph.conf.d/osd1.conf" ignore missing %}
[osd.2]
{% include "ceph/configuration/files/ceph.conf.d/osd2.conf" ignore missing %}
[osd.3]
{% include "ceph/configuration/files/ceph.conf.d/osd3.conf" ignore missing %}
[osd.4]
{% include "ceph/configuration/files/ceph.conf.d/osd4.conf" ignore missing %}</screen>
   <para>
    Im vorigen Beispiel enthalten die Dateien <filename>osd1.conf</filename>, <filename>osd2.conf</filename>, <filename>osd3.conf</filename> und <filename>osd4.conf</filename> die für den entsprechenden OSD spezifischen Konfigurationsoptionen.
   </para>
   <tip>
    <title>Konfiguration zur Laufzeit</title>
    <para>
     Änderungen an den Ceph-Konfigurationsdateien werden wirksam nach dem Neustart der entsprechenden Ceph Daemons. Weitere Informationen zum Ändern der Ceph-Konfiguration zur Laufzeit finden Sie im folgenden <xref linkend="ceph-config-runtime"/>.
    </para>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-config-runtime">
  <title>Ceph-Konfiguration zur Laufzeit</title>

  <para>
   In <xref linkend="ds-custom-cephconf"/> wird erläutert, wie Änderungen an der Ceph-Konfigurationsdatei <filename>ceph.conf</filename> vorgenommen werden. Das tatsächliche Cluster-Verhalten wird jedoch nicht durch den aktuellen Zustand der Datei <filename>ceph.conf</filename> bestimmt, sondern durch die Konfiguration der aktiven Ceph Daemons, die im Arbeitsspeicher gespeichert ist.
  </para>

  <para>
   Mit dem <emphasis>admin socket</emphasis> im Node, in dem der Daemon ausgeführt wird, fragen Sie einen einzelnen Ceph Daemon nach einer bestimmten Konfigurationseinstellung ab. Beispiel: Mit dem folgenden Kommando wird der Wert des Konfigurationsparameters <option>osd_max_write_size</option> vom Daemon namens <literal>osd.0</literal> abgerufen:
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/ceph-osd.0.asok \
config get osd_max_write_size
{
  "osd_max_write_size": "90"
}</screen>

  <para>
   Die Einstellungen des Daemons können auch zur Laufzeit <emphasis>geändert</emphasis> werden. Berücksichtigen Sie, dass diese Änderung vorübergehend ist und beim nächsten Neustart des Daemons verloren geht. Beispiel: Mit dem folgenden Kommando wird der Parameter <option>osd_max_write_size</option> für alle OSDs im Cluster auf "50" geändert:
  </para>

<screen><prompt>root # </prompt>ceph tell osd.* injectargs --osd_max_write_size 50</screen>

  <warning>
   <title><command>injectargs</command> ist nicht zuverlässig</title>
   <para>
    Leider können Sie sich nicht hundertprozentig darauf verlassen, dass mit <command>injectargs</command> die Cluster-Einstellungen geändert werden. Wenn Sie sicherstellen müssen, dass der geänderte Parameter aktiv ist, ändern Sie ihn in der Konfigurationsdatei und starten Sie alle Daemons im Cluster neu.
   </para>
  </warning>
 </sect1>
</chapter>
