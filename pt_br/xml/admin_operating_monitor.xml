<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph-monitor">
 <title>Determinando o estado do cluster</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>sim</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Quando você tem um cluster em execução, pode usar a ferramenta <command>ceph</command> para monitorá-lo. Normalmente, a determinação do estado do cluster envolve verificar o status do OSD, monitor, grupo de posicionamento e servidor de metadados. <remark role="fixme">Maybe revert to old version of sentence: Determining the cluster state typically involves
  checking OSD status, monitor status, placement group status and metadata
  server status.</remark>
 </para>
 <tip>
  <title>Modo interativo</title>
  <para>
   Para executar a ferramenta <command>ceph</command> no modo interativo, digite <command>ceph</command> na linha de comando sem argumentos. O modo interativo é o mais prático quando você pretende digitar mais comandos <command>ceph</command> em uma linha. Por exemplo:
  </para>
<screen><prompt>cephadm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon_status</screen>
 </tip>
 <sect1 xml:id="monitor-health">
  <title>Verificando a saúde do cluster</title>

  <para>
   Após iniciar o cluster e antes de começar a leitura e/ou gravação de dados, verifique a saúde dele:
  </para>

<screen><prompt>root # </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <para>
   O cluster do Ceph retorna um dos seguintes códigos de saúde:
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      Um ou mais OSDs estão marcados como inativos. O daemon OSD pode ter sido parado ou os OSDs peers talvez não conseguem acessar o OSD pela rede. As causas comuns incluem um daemon parado ou com falha, um host inativo ou uma interrupção da rede.
     </para>
     <para>
      Verifique se o host está saudável, se o daemon foi iniciado e se a rede está funcionando. Se o daemon falhou, o arquivo de registro do daemon (<filename>/var/log/ceph/ceph-osd.*</filename>) pode incluir informações de depuração.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>tipo de crush</replaceable>_DOWN. Por exemplo, OSD_HOST_DOWN</term>
    <listitem>
     <para>
      Todos os OSDs em uma subárvore específica do CRUSH estão marcados como inativos. Por exemplo, todos os OSDs em um host.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      Um OSD é referenciado na hierarquia do mapa CRUSH, mas não existe. O OSD pode ser removido da hierarquia do CRUSH com:
     </para>
<screen><prompt>root # </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      Os limites de uso para <emphasis>backfillfull</emphasis>, <emphasis>nearfull</emphasis>, <emphasis>full</emphasis> e/ou <emphasis>failsafe_full</emphasis> não estão em ordem crescente. Especificamente, esperamos <emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>, <emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis> e <emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis>. É possível ajustar os limites com:
     </para>
<screen><prompt>root # </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      Um ou mais OSDs excederam o limite de <emphasis>full</emphasis> e impedem o cluster de executar gravações. É possível verificar o uso por pool com:
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
     <para>
      É possível ver a cota <emphasis>full</emphasis> definida no momento com:
     </para>
<screen><prompt>root # </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      Uma solução alternativa de curto prazo para resolver a disponibilidade de gravação é aumentar um pouco o valor do limite de full:
     </para>
<screen><prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      Adicione o novo armazenamento ao cluster implantando mais OSDs ou apague os dados existentes para liberar espaço.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      Um ou mais OSDs excederam o limite de <emphasis>backfillfull</emphasis>, o que impede a redistribuição dos dados no dispositivo. Trata-se de um aviso antecipado de que a redistribuição talvez não possa ser concluída e de que o cluster está quase cheio. É possível verificar o uso por pool com:
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      Um ou mais OSDs excederam o limite de <emphasis>nearfull</emphasis>. Trata-se de um aviso antecipado de que o cluster está quase cheio. É possível verificar o uso por pool com:
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      Um ou mais flags de interesse do cluster foram definidos. Com exceção de <emphasis>full</emphasis>, é possível definir ou limpar esses flags com:
     </para>
<screen><prompt>root # </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>root # </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      Esses flags incluem:
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         O cluster foi sinalizado como cheio e não pode realizar gravações.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd, pausewr </term>
       <listitem>
        <para>
         Leituras ou gravações pausadas.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         Os OSDs não têm permissão para serem iniciados.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         Os relatórios de falha do OSD estão sendo ignorados, portanto, os monitores não marcarão os OSDs como <emphasis>inativos</emphasis>.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Os OSDs já marcados como <emphasis>out</emphasis> não serão remarcados como <emphasis>in</emphasis> quando forem iniciados.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Os OSDs <emphasis>inativos</emphasis> não serão automaticamente marcados como <emphasis>out</emphasis> após o intervalo configurado.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill, norecover, norebalance</term>
       <listitem>
        <para>
         A recuperação ou a redistribuição de dados está suspensa.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub, nodeep_scrub</term>
       <listitem>
        <para>
         A depuração (consulte a <xref linkend="scrubbing"/>) está desabilitada.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         A atividade de camadas de cache foi suspensa.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      Um ou mais OSDs têm um flag de interesse definido por OSD. Esses flags incluem:
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         O OSD não tem permissão para ser iniciado.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         Os relatórios de falha para este OSD serão ignorados.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Se este OSD já foi marcado como <emphasis>out</emphasis> automaticamente após uma falha, ele não será marcado como <emphasis>in</emphasis> quando for iniciado.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Se este OSD estiver inativo, ele não será automaticamente marcado como <emphasis>out</emphasis> após o intervalo configurado.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      É possível definir e limpar os flags por OSD com:
     </para>
<screen><prompt>root # </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>root # </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      O Mapa CRUSH usa configurações muito antigas e deve ser atualizado. Os tunables mais antigos que podem ser usados (ou seja, a versão de cliente mais antiga que pode se conectar ao cluster) sem acionar este aviso de saúde são determinados pela opção de configuração <option>mon_crush_min_required_version</option>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      O Mapa CRUSH usa um método mais antigo que não é o ideal para calcular os valores de peso intermediários para compartimentos de memória straw. O Mapa CRUSH deve ser atualizado para usar o método mais recente (<option>straw_calc_version</option>=1).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      Um ou mais pools de cache não estão configurados com um conjunto de acertos para monitorar o uso, o que impede o agente de camadas de identificar objetos frios para descarregar e eliminar do cache. É possível configurar conjuntos de acertos no pool de cache com:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      Não há OSDs anterior ao Luminous v12 em execução, mas o flag <option>sortbitwise</option> não foi definido. Você precisa definir o flag <option>sortbitwise</option> antes que os OSDs Luminous v12 ou mais recentes possam ser iniciados:
     </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Um ou mais pools atingiram a cota e não permitem mais gravações. Você pode definir cotas e uso de pool com:
     </para>
<screen><prompt>root # </prompt>ceph df detail</screen>
     <para>
      Você pode aumentar a cota do pool com
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      ou apagar alguns dados existentes para reduzir o uso.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      A disponibilidade de dados está reduzida, o que significa que o cluster não pode atender a possíveis solicitações de leitura ou gravação para alguns dados no cluster. Especificamente, o estado de um ou mais PGs não permite que as solicitações de E/S sejam atendidas. Os estados dos PGs problemáticos incluem <emphasis>emparelhamento</emphasis>, <emphasis>obsoleto</emphasis>, <emphasis>incompleto</emphasis> e a ausência de <emphasis>ativo</emphasis> (se essas condições não forem resolvidas rapidamente). As informações detalhadas sobre quais PGs são afetados estão disponíveis em:
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      Na maioria dos casos, a causa raiz é que um ou mais OSDs estão inativos no momento. É possível consultar o estado dos PGs problemáticos específicos com:
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      A redundância de dados está reduzida para alguns dados, o que significa que o cluster não tem o número de réplicas desejado para todos os dados (em pools replicados) ou para fragmentos de código de eliminação (em pools com codificação de eliminação). Especificamente, um ou mais PGs têm o flag <emphasis>degraded</emphasis> ou <emphasis>undersized</emphasis> definido (não há instâncias suficientes desse grupo de posicionamento no cluster) ou não tinham o flag <emphasis>clean</emphasis> definido durante determinado período. As informações detalhadas sobre quais PGs são afetados estão disponíveis em:
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      Na maioria dos casos, a causa raiz é que um ou mais OSDs estão inativos no momento. É possível consultar o estado dos PGs problemáticos específicos com:
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      A redundância de dados pode estar reduzida ou em risco para alguns dados devido à ausência de espaço livre no cluster. Especificamente, um ou mais PGs têm o flag <emphasis>backfill_toofull</emphasis> ou <emphasis>recovery_toofull</emphasis> definido, o que significa que o cluster não pode migrar ou recuperar dados porque um ou mais OSDs estão acima do limite de <emphasis>backfillfull</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      A depuração de dados (consulte a <xref linkend="scrubbing"/>) descobriu alguns problemas com a consistência de dados no cluster. Especificamente, um ou mais PGs têm o flag <emphasis>inconsistent</emphasis> ou <emphasis>snaptrim_error</emphasis> definido, indicando que uma operação de depuração anterior detectou um problema, ou o flag <emphasis>repair</emphasis> definido, o que significa que um reparo para esse tipo de inconsistência está agora em andamento.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      Depurações recentes de OSD revelaram inconsistências.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Um pool de camada de cache está quase cheio. Neste contexto, “full” é determinado pelas propriedades <emphasis>target_max_bytes</emphasis> e <emphasis>target_max_objects</emphasis> no pool de cache. Quando o pool atinge o limite de destino, as solicitações de gravação para o pool podem ser bloqueadas enquanto os dados são descarregados e eliminados do cache, um estado que normalmente gera latências muito altas e baixo desempenho. É possível ajustar o tamanho do destino do pool de cache com:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      As atividades normais de descarregamento e eliminação de cache também podem ficar restritas por redução na disponibilidade ou no desempenho da camada de base ou do carregamento geral do cluster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      O número de PGs em uso está abaixo do limite configurável de <option>mon_pg_warn_min_per_osd</option> PGs por OSD. Isso pode levar à distribuição e ao equilíbrio de dados abaixo do ideal em todos os OSDs no cluster, reduzindo o desempenho geral.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      O número de PGs em uso está acima do limite configurável de <option>mon_pg_warn_max_per_osd</option> PGs por OSD. Isso pode levar a um aumento do uso de memória dos daemons OSD, a uma redução do emparelhamento após mudanças no estado do cluster (por exemplo, reinicializações, adições ou remoções de OSD) e a um aumento da carga nos Ceph Managers e Ceph Monitors.
     </para>
     <para>
      O valor <option>pg_num</option> de pools existentes não pode ser reduzido. Porém, o valor <option>pgp_num</option> pode. Isso efetivamente combina alguns PGs nos mesmos conjuntos de OSDs, atenuando alguns dos impactos negativos descritos acima. É possível ajustar o valor <option>pgp_num</option> com:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      Um ou mais pools têm um valor <option>pgp_num</option> menor do que <option>pg_num</option>. Normalmente, isso indica que a contagem de PGs foi aumentada sem aumentar também o comportamento de posicionamento. Isso costuma ser resolvido definindo <option>pgp_num</option> para corresponder a <option>pg_num</option>, o que aciona a migração de dados, com:
     </para>
<screen>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      Um ou mais pools têm um número médio de objetos por PG que é significativamente maior do que a média geral do cluster. O limite específico é controlado pelo valor da configuração <option>mon_pg_warn_max_object_skew</option>. Isso costuma ser uma indicação de que o(s) pool(s) com a maioria dos dados no cluster está(ão) com um número muito baixo de PGs, e/ou que outros pools sem tantos dados têm PGs em excesso. É possível aumentar o limite para silenciar o aviso de saúde ajustando a opção de configuração <option>mon_pg_warn_max_object_skew</option> nos monitores.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED</term>
    <listitem>
     <para>
      Existe um pool que contém um ou mais objetos, mas que não foi marcados para uso por determinado aplicativo. Resolva esse aviso identificando o pool para uso por um aplicativo. Por exemplo, se o pool é usado pelo RBD:
     </para>
<screen><prompt>root # </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      Se o pool é usado por um aplicativo personalizado “foo”, você também pode identificá-lo usando o comando de nível inferior:
     </para>
<screen><prompt>root # </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Um ou mais pools atingiram (ou estão muito próximos de atingir) a cota. O limite para acionar essa condição de erro é controlado pela opção de configuração <option>mon_pool_quota_crit_threshold</option>. É possível aumentar ou reduzir (ou remover) as cotas de pool com:
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      A definição do valor como 0 desabilitará a cota.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Um ou mais pools estão quase atingindo a cota. O limite para acionar essa condição de aviso é controlado pela opção de configuração <option>mon_pool_quota_warn_threshold</option>. É possível aumentar ou reduzir (ou remover) as cotas de pool com:
     </para>
<screen><prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      A definição do valor como 0 desabilitará a cota.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      Um ou mais objetos no cluster não estão armazenados no nó em que o cluster deseja que eles sejam armazenados. Isso é uma indicação de que a migração de dados decorrente de alguma mudança recente no cluster ainda não foi concluída. Os dados incorretamente armazenados não representam uma condição de risco por si só. A consistência de dados nunca está em risco, e as cópias antigas de objetos serão removidas apenas quando houver o número desejado de novas cópias (nos locais esperados).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      Um ou mais objetos no cluster não foram encontrados. Especificamente, os OSDs sabem que uma cópia nova ou atualizada de um objeto deve existir, mas uma cópia dessa versão do objeto não foi encontrada nos OSDs que estão online no momento. As solicitações de leitura ou gravação para os objetos “não encontrados” serão bloqueadas. O ideal é que um OSD inativo com a cópia mais recente do objeto não encontrado possa voltar a ficar online. É possível identificar os OSDs candidatos com base no estado do emparelhamento referente ao(s) PG(s) responsável(is) pelo objeto não encontrado:
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      O processamento de uma ou mais solicitações OSD está levando muito tempo. Isso pode ser uma indicação de carga extrema, um dispositivo de armazenamento lento ou um bug de software. É possível consultar a fila de solicitações no(s) OSD(s) em questão com o seguinte comando executado do host OSD:
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      Você pode ver um resumo das solicitações recentes mais lentas:
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      Você pode encontrar o local de um OSD com:
     </para>
<screen><prompt>root # </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      Uma ou mais solicitações OSD ficaram bloqueadas por um tempo extremamente longo. Isso é uma indicação de que o cluster não esteve saudável por um longo período (por exemplo, não há OSDs suficientes em execução) ou de que existe algum problema interno com o OSD.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      Um ou mais PGs não foram depurados (consulte a <xref linkend="scrubbing"/>) recentemente. Normalmente, os PGs são depurados a cada <option>mon_scrub_interval</option> segundos, e esse aviso será acionado após decorrer <option>mon_warn_not_scrubbed</option> segundos sem uma depuração. Os PGs não serão depurados se não forem sinalizados como limpos, o que poderá ocorrer se forem armazenados incorretamente ou estiverem degradados (consulte PG_AVAILABILITY e PG_DEGRADED acima). Você pode iniciar manualmente uma depuração de um PG limpo com:
     </para>
<screen><prompt>root # </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      Um ou mais PGs não foram depurados em detalhes (consulte a <xref linkend="scrubbing"/>) recentemente. Normalmente, os PGs são depurados a cada <option>osd_deep_mon_scrub_interval</option> segundos, e esse aviso é acionado quando esses intervalos de <option>mon_warn_not_deep_scrubbed</option> decorreram sem uma depuração. Os PGs não serão depurados (em detalhes) se não forem sinalizados como limpos, o que poderá ocorrer se forem armazenados incorretamente ou estiverem degradados (consulte PG_AVAILABILITY e PG_DEGRADED acima). Você pode iniciar manualmente uma depuração de um PG limpo com:
     </para>
<screen><prompt>root # </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    Se você especificou locais diferentes do padrão em sua configuração ou no chaveiro, deve especificar estes locais:
   </para>
<screen><prompt>root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-watch">
  <title>Observando um cluster</title>

  <para>
   Você pode detectar o estado imediato do cluster usando o comando <command>ceph -s</command>. Por exemplo, um cluster do Ceph bem pequeno composto por um monitor e dois OSDs pode imprimir o seguinte quando há uma carga de trabalho em execução:
  </para>

<screen>cluster:
  id:     6586341d-4565-3755-a4fd-b50f51bee248
  health: HEALTH_OK

services:
  mon: 3 daemons, quorum blueshark1,blueshark2,blueshark3
  mgr: blueshark3(active), standbys: blueshark2, blueshark1
  osd: 15 osds: 15 up, 15 in

data:
  pools:   8 pools, 340 pgs
  objects: 537 objects, 1985 MB
  usage:   23881 MB used, 5571 GB / 5595 GB avail
  pgs:     340 active+clean

io:
  client:   100 MB/s rd, 26256 op/s rd, 0 op/s wr</screen>

  <para>
   A saída apresenta as seguintes informações:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     ID do cluster
    </para>
   </listitem>
   <listitem>
    <para>
     Status de saúde do cluster
    </para>
   </listitem>
   <listitem>
    <para>
     A época do mapa do monitor e o status do quorum do monitor
    </para>
   </listitem>
   <listitem>
    <para>
     A época do mapa OSD e o status dos OSDs
    </para>
   </listitem>
   <listitem>
    <para>
     A versão do mapa do grupo de posicionamento
    </para>
   </listitem>
   <listitem>
    <para>
     O número de grupos de posicionamento e pools
    </para>
   </listitem>
   <listitem>
    <para>
     A quantidade <emphasis>estimada</emphasis> de dados armazenados e o número de objetos armazenados; e
    </para>
   </listitem>
   <listitem>
    <para>
     A quantidade total de dados armazenados.
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Como o Ceph calcula o uso de dados</title>
   <para>
    O valor <literal>usado</literal> reflete o valor real do armazenamento bruto utilizado. O valor <literal>xxx GB/xxx GB</literal> indica o valor disponível (o menor número) da capacidade de armazenamento geral do cluster. O número estimado reflete o tamanho dos dados armazenados antes de serem replicados, clonados ou capturados como instantâneos. Portanto, a quantidade de dados realmente armazenados costuma exceder o valor estimado armazenado, pois o Ceph cria réplicas dos dados e também pode usar a capacidade de armazenamento para fazer clonagem e criar instantâneos.
   </para>
  </tip>

  <para>
   Outros comandos que exibem informações de status imediatas são:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Para obter as informações atualizadas em tempo real, insira qualquer um destes comandos (incluindo <command>ceph -s</command>) em um loop de espera. Por exemplo:
  </para>

<screen><systemitem class="username">root</systemitem>while true ; do ceph -s ; sleep 10 ; done</screen>

  <para>
   Pressione <keycombo><keycap function="control"/><keycap>C</keycap></keycombo> quando estiver cansado de observar.
  </para>
 </sect1>
 <sect1 xml:id="monitor-stats">
  <title>Verificando as estatísticas de uso do cluster</title>

  <para>
   Para verificar o uso de dados de um cluster e a distribuição de dados entre os pools, você pode usar a opção <command>df</command>. Esse procedimento é similar ao <command>df</command> do Linux. Execute o seguinte:
  </para>

<screen><prompt>root # </prompt>ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    55886G     55826G       61731M          0.11
POOLS:
    NAME         ID     USED      %USED     MAX AVAIL     OBJECTS
    testpool     1          0         0        17676G           0
    ecpool       2      4077M      0.01        35352G        2102
    test1        3          0         0        17676G           0
    rbd          4         16         0        17676G           3
    rbd1         5         16         0        17676G           3
    ecpool1      6      5708M      0.02        35352G        2871</screen>

  <para>
   A seção <literal>GLOBAL</literal> da saída apresenta uma visão geral da quantidade de armazenamento que seu cluster usa para os dados.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>SIZE</literal>: A capacidade de armazenamento geral do cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal>: A quantidade de espaço livre disponível no cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal>: A quantidade usada de armazenamento bruto.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal>: A porcentagem usada de armazenamento bruto. Use esse número em conjunto com <literal>full ratio</literal> e <literal>near full ratio</literal> para garantir que você não atinja a capacidade do cluster. Consulte <link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/mon-config-ref#storage-capacit">Capacidade de armazenamento</link> para obter mais detalhes.
    </para>
    <note>
     <title>Nível de preenchimento do cluster</title>
     <para>
      Um nível de preenchimento de armazenamento bruto de 70% a 80% indica que um novo armazenamento precisa ser adicionado ao cluster. O uso mais alto pode resultar em OSDs únicos cheios e problemas de saúde do cluster.
     </para>
     <para>
      Use o comando <command>ceph osd df tree</command> para listar o nível de preenchimento de todos os OSDs.
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   A seção <literal>POOLS</literal> da saída apresenta uma lista dos pools e o uso estimado de cada pool. A saída dessa seção <emphasis>não</emphasis> reflete réplicas, clones ou instantâneos. Por exemplo, se você armazenar um objeto com 1 MB de dados, o uso estimado será de 1 MB, mas o uso real poderá ser de 2 MB ou mais, dependendo do número de réplicas, clones e instantâneos.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>NAME</literal>: O nome do pool.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal>: O ID do pool.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: A quantidade estimada de dados armazenados em quilobytes, exceto quando o número tem M anexado para megabytes ou G para gigabytes.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>%USED</literal>: A porcentagem estimada de armazenamento usado por pool.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal>: O espaço máximo disponível no pool especificado.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal>: O número de objetos armazenados por pool.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    Os números na seção POOLS são estimativas. Eles não incluem o número de réplicas, instantâneos ou clones. Sendo assim, a soma dos valores USED e %USED não incluirá os valores RAW USED e %RAW USED na seção %GLOBAL da saída.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor-status">
  <title>Verificando o status do cluster</title>

  <para>
   Para verificar o status de um cluster, execute o seguinte:
  </para>

<screen><prompt>root # </prompt>ceph status</screen>

  <para>
   ou
  </para>

<screen><prompt>root # </prompt>ceph -s</screen>

  <para>
   No modo interativo, digite <command>status</command> e pressione <keycap function="enter"/>.
  </para>

<screen>ceph&gt; status</screen>

  <para>
   O Ceph imprimirá o status do cluster. Por exemplo, um cluster do Ceph bem pequeno composto por um monitor e dois OSDs pode imprimir o seguinte:
  </para>

<screen>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</screen>
 </sect1>
 <sect1 xml:id="monitor-osdstatus">
  <title>Verificando o status do OSD</title>

  <para>
   Você pode verificar os OSDs para garantir que estejam ativos e em execução:
  </para>

<screen><prompt>root # </prompt>ceph osd stat</screen>

  <para>
   ou
  </para>

<screen><prompt>root # </prompt>ceph osd dump</screen>

  <para>
   Você também pode ver os OSDs de acordo com a posição deles no mapa CRUSH.
  </para>

<screen><prompt>root # </prompt>ceph osd tree</screen>

  <para>
   O Ceph imprimirá uma árvore CRUSH com um host, os OSDs, se eles estão ativos e o peso.
  </para>

<screen># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</screen>
 </sect1>
 <sect1 xml:id="storage-bp-monitoring-fullosd">
  <title>Verificando se há OSDs cheios</title>

  <para>
   O Ceph impede você de gravar em um OSD cheio para evitar a perda de dados. Em um cluster operacional, você deve receber um aviso quando o cluster está próximo cota máxima. O padrão do valor <command>mon osd full ratio</command> é de 0,95, ou 95% da capacidade antes de impedir que os clientes gravem dados. O padrão do valor <command>mon osd nearfull ratio</command> é de 0,85, ou 85% da capacidade, quando ele gera um aviso de saúde.
  </para>

  <para>
   O <command>ceph health</command> relata os nós OSD cheios:
  </para>

<screen>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   ou
  </para>

<screen>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   A melhor maneira de resolver um cluster cheio é adicionar novos nós OSD, o que permite ao cluster redistribuir os dados para o armazenamento recém-disponibilizado.
  </para>

  <para>
   Se você não pode iniciar um OSD porque ele está cheio, é possível apagar alguns dados excluindo diretórios do grupo de posicionamento no OSD cheio.
  </para>

  <tip>
   <title>Evitando OSDs cheios</title>
   <para>
    Depois que um OSD fica cheio (usa 100% do espaço em disco), ele costuma falhar rapidamente sem aviso. Veja a seguir algumas dicas para se lembrar na hora de administrar nós OSD.
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      O espaço em disco de cada OSD (normalmente montado em <filename>/var/lib/ceph/osd/osd-{1,2..}</filename>) precisa ser colocado em um disco ou partição subjacente dedicado.
     </para>
    </listitem>
    <listitem>
     <para>
      Verifique os arquivos de configuração do Ceph e certifique-se de que o Ceph não armazene o arquivo de registro em discos/partições dedicados para uso por OSDs.
     </para>
    </listitem>
    <listitem>
     <para>
      Confirme se nenhum outro processo faz gravações nos discos/partições dedicados para uso por OSDs.
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-monstatus">
  <title>Verificando o status do monitor</title>

  <para>
   Se o seu cluster tem vários monitores (mais provável), você deve verificar o status do quorum do monitor depois de iniciar o cluster, antes de ler e/ou gravar dados. Um quorum deve estar presente quando vários monitores estão em execução. Você também deve verificar o status do monitor periodicamente para garantir que ele esteja em execução.
  </para>

  <para>
   Para exibir o mapa do monitor, execute o seguinte:
  </para>

<screen><prompt>root # </prompt>ceph mon stat</screen>

  <para>
   ou
  </para>

<screen><prompt>root # </prompt>ceph mon dump</screen>

  <para>
   Para verificar o status do quorum para o cluster do monitor, execute o seguinte:
  </para>

<screen><prompt>root # </prompt>ceph quorum_status</screen>

  <para>
   O Ceph retornará o status do quorum. Por exemplo, um cluster do Ceph com três monitores pode retornar o seguinte:
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "127.0.0.1:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "127.0.0.1:6790\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "127.0.0.1:6791\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor-pgroupstatus">
  <title>Verificando estados de grupo de posicionamento</title>

  <para>
   Os grupos de posicionamento mapeiam objetos para OSDs. Ao monitorar seus grupos de posicionamento, você deseja que eles estejam <literal>ativos</literal> e <literal>limpos</literal>. Para ver uma discussão detalhada, consulte <link xlink:href="http://docs.ceph.com/docs/master/rados/operations/monitoring-osd-pg">Monitorando OSDs e grupos de posicionamento</link>.
  </para>
 </sect1>
 <sect1 xml:id="monitor-adminsocket">
  <title>Usando o soquete de admin</title>

  <para>
   <remark role="fixme">Maybe give an example use case? No obvious difference to normal ceph command?!</remark> O soquete de admin do Ceph permite consultar um daemon pela interface do soquete. Por padrão, os soquetes do Ceph residem em <filename>/var/run/ceph</filename>. Para acessar um daemon pelo soquete de admin, efetue login no host que executa o daemon e use o seguinte comando:
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable></screen>

  <para>
   Para ver os comandos de soquete de admin disponíveis, execute o seguinte comando:
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable> help</screen>

  <para>
   O comando de soquete de admin permite mostrar e definir sua configuração em tempo de execução. Consulte <link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf#ceph-runtime-config">Vendo uma configuração em tempo de execução</link> para obter detalhes.
  </para>

  <para>
   Você também pode definir diretamente os valores de configuração em tempo de execução (o soquete de admin ignora o monitor, ao contrário de <command>ceph tell</command> <replaceable>daemon-type</replaceable>.<replaceable>id</replaceable> injectargs, que usa o monitor, mas não exige login diretamente no host em questão).
  </para>
 </sect1>
</chapter>
