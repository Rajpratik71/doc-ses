<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_nfsganesha.xml" version="5.0" xml:id="cha-ceph-nfsganesha">

 <title>NFS Ganesha: Exportar dados do Ceph pelo NFS</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>editando</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>yes (sim)</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    
 <para>
  NFS Ganesha é um servidor NFS (consulte <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_nfs.html">Sharing File Systems with NFS</link> (Compartilhando sistemas de arquivos com o NFS)) executado em um espaço de endereço de usuário, e não como parte do kernel do sistema operacional. Com o NFS Ganesha, você pode conectar seu próprio mecanismo de armazenamento, como Ceph, e acessá-lo de qualquer cliente NFS.
 </para>
 <para>
  Os compartimentos de memória do S3 são exportados para o NFS por usuário. Por exemplo, usando o caminho <filename><replaceable>NÓ_DO_GANESHA:</replaceable>/<replaceable>NOMEDEUSUÁRIO</replaceable>/<replaceable>NOMEDOCOMPARTIMENTODEMEMÓRIA</replaceable></filename>.
 </para>
 <para>
  Por padrão, um CephFS é exportado por meio do caminho <filename><replaceable>NÓ_DO_GANESHA:</replaceable>/cephfs</filename>.
 </para>
 <sect1 xml:id="ceph-nfsganesha-install">
  <title>Instalação</title>

  <para>
   Para obter instruções, consulte o <xref linkend="cha-as-ganesha"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-config">
  <title>Configuração</title>

  <para>
   Para obter uma lista de todos os parâmetros disponíveis no arquivo de configuração, consulte:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>man ganesha-config</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-ceph-config</command> para obter as opções da FSAL (File System Abstraction Layer – Camada de Abstração do Sistema de Arquivos) do CephFS.
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-rgw-config</command> para obter as opções da FSAL do Object Gateway.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Esta seção inclui informações para ajudar você a configurar o servidor NFS Ganesha para exportar os dados de cluster acessíveis por meio do Object Gateway e do CephFS.
  </para>

  <para>
   A configuração do NFS Ganesha é controlada por <filename>/etc/ganesha/ganesha.conf</filename>. Observe que as mudanças nesse arquivo serão sobregravadas quando a Fase 4 do DeepSea for executada. Para mudar as configurações permanentemente, edite o arquivo <filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename> localizado no master Salt.
  </para>

  <sect2 xml:id="ceph-nfsganesha-config-general">
   <title>Seção de exportação</title>
   <para>
    Esta seção descreve como configurar as seções <literal>EXPORT</literal> no <filename>ganesha.conf</filename>.
   </para>
<screen>EXPORT
{
  Export_Id = 1;
  Path = "/";
  Pseudo = "/";
  Access_Type = RW;
  Squash = No_Root_Squash;
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
   <sect3 xml:id="ceph-nfsganesha-config-general-export">
    <title>Seção de exportação principal</title>
    <variablelist>
     <varlistentry>
      <term>Export_Id</term>
      <listitem>
       <para>
        Cada exportação precisa ter um “Export_Id” exclusivo (obrigatório).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Caminho</term>
      <listitem>
       <para>
        Caminho de exportação no pool do CephFS relacionado (obrigatório). Isso permite que os subdiretórios sejam exportados do CephFS.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Pseudo</term>
      <listitem>
       <para>
        Caminho de exportação de destino do NFS (obrigatório para NFSv4). Ele define em qual caminho de exportação do NFS os dados exportados estarão disponíveis.
       </para>
       <para>
        Exemplo: com o valor <literal>/cephfs/</literal> e após a execução de
       </para>
<screen>
<prompt>root # </prompt>mount <replaceable>GANESHA_IP</replaceable>:/cephfs/ /mnt/
</screen>
       <para>
        Os dados do CephFS estão disponíveis no diretório <filename>/mnt/cephfs/</filename> no cliente.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Access_Type</term>
      <listitem>
       <para>
        “RO” para acesso apenas leitura. O padrão é “None”.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Squash</term>
      <listitem>
       <para>
        Opção “squash” do NFS.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>FSAL</term>
      <listitem>
       <para>
        “Camada de Abstração do Sistema de Arquivos” de exportação. Consulte a <xref linkend="ceph-nfsganesha-config-general-fsal"/>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-nfsganesha-config-general-fsal">
    <title>Subseção FSAL</title>
<screen>EXPORT
{
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
    <variablelist>
     <varlistentry>
      <term>Nome</term>
      <listitem>
       <para>
        Define o back end que o NFS Ganesha usa. Os valores permitidos são <literal>CEPH</literal> para CephFS ou <literal>RGW</literal> para Object Gateway. Dependendo da opção, uma <literal>role-mds</literal> ou <literal>role-rgw</literal> deve ser definida em <filename>policy.cfg</filename>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-config-rgw">
   <title>Seção RGW</title>
<screen>RGW {
  ceph_conf = "/etc/ceph/ceph.conf";
  name = "name";
  cluster = "ceph";
}</screen>
   <variablelist>
    <varlistentry>
     <term>ceph_conf</term>
     <listitem>
      <para>
       Aponta para o arquivo <filename>ceph.conf</filename>. Durante a implantação com o DeepSea, não é necessário mudar esse valor.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>name</term>
     <listitem>
      <para>
       O nome do usuário do cliente Ceph que o NFS Ganesha utiliza.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cluster</term>
     <listitem>
      <para>
       Nome do cluster do Ceph. Atualmente, o SUSE Enterprise Storage 5 suporta apenas um nome de cluster, que é <literal>ceph</literal> por padrão.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ganesha-nfsport">
   <title>Mudando as portas padrão do NFS Ganesha</title>
   <para>
    Por padrão, o NFS Ganesha usa a porta 2049 para NFS e 875 para suporte a rquota. Para mudar os números de porta padrão, use as opções <option>NFS_Port</option> e <option>RQUOTA_Port</option> na seção <literal>NFS_CORE_PARAM</literal>. Por exemplo:
   </para>
<screen>
NFS_CORE_PARAM
{
 NFS_Port = 2060;
 RQUOTA_Port = 876;
}
</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-customrole">
  <title>Funções personalizadas do NFS Ganesha</title>

  <para>
   É possível definir funções personalizadas do NFS Ganesha para nós de cluster. Na sequência, essas funções são atribuídas aos nós em <filename>policy.cfg</filename>. As funções permitem o seguinte:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Nós separados do NFS Ganesha para acessar o Object Gateway e o CephFS.
    </para>
   </listitem>
   <listitem>
    <para>
     Atribuição de usuários diferentes do Object Gateway a nós do NFS Ganesha.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   A existência de usuários diferentes do Object Gateway permite que os nós do NFS Ganesha acessem compartimentos de memória diferentes do S3. É possível usar os compartimentos de memória do S3 para controle de acesso. Nota: Os compartimentos de memória do S3 não devem ser confundidos com os do Ceph usados no Mapa CRUSH.
  </para>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-multiusers">
   <title>Usuários diferentes do Object Gateway para NFS Ganesha</title>
   <para>
    O seguinte procedimento de exemplo para o master Salt mostra como criar duas funções do NFS Ganesha com usuários diferentes do Object Gateway. Neste exemplo, as funções <literal>gold</literal> e <literal>silver</literal> são usadas, e o DeepSea já fornece arquivos de configuração de exemplo para elas.
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-rgw-multiusers">
    <step>
     <para>
      Abra o arquivo <filename>/srv/pillar/ceph/stack/global.yml</filename> com o editor de sua preferência. Crie o arquivo se ele não existir.
     </para>
    </step>
    <step>
     <para>
      O arquivo precisa incluir as seguintes linhas:
     </para>
<screen>rgw_configurations:
  - rgw
  - silver
  - gold
ganesha_configurations:
  - silver
  - gold</screen>
     <para>
      Mais tarde, essas funções poderão ser atribuídas em <filename>policy.cfg</filename>.
     </para>
    </step>
    <step>
     <para>
      Crie um arquivo <filename>/srv/salt/ceph/rgw/users/users.d/gold.yml</filename> e adicione o seguinte conteúdo:
     </para>
<screen>- { uid: "gold1", name: "gold1", email: "gold1@demo.nil" }</screen>
     <para>
      Crie um arquivo <filename>/srv/salt/ceph/rgw/users/users.d/silver.yml</filename> e adicione o seguinte conteúdo:
     </para>
<screen>- { uid: "silver1", name: "silver1", email: "silver1@demo.nil" }</screen>
    </step>
    <step>
     <para>
      Agora, os gabaritos para o <filename>ganesha.conf</filename> precisam ser criados para cada função. O gabarito original do DeepSea é um bom ponto de partida. Crie duas cópias:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 silver.conf.j2
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 gold.conf.j2</screen>
    </step>
    <step>
     <para>
      As novas funções exigem chaveiros para acessar o cluster. Para conceder acesso, copie o <filename>ganesha.j2</filename>:
     </para>
<screen><prompt>root # </prompt><command>cp</command> ganesha.j2 silver.j2
<prompt>root # </prompt><command>cp</command> ganesha.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Copie o chaveiro para o Object Gateway:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/rgw/files/
<prompt>root # </prompt><command>cp</command> rgw.j2 silver.j2
<prompt>root # </prompt><command>cp</command> rgw.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      O Object Gateway também precisa da configuração para as diferentes funções:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/configuration/files/
<prompt>root # </prompt><command>cp</command> ceph.conf.rgw silver.conf
<prompt>root # </prompt><command>cp</command> ceph.conf.rgw gold.conf</screen>
    </step>
    <step>
     <para>
      Atribua as funções recém-criadas aos nós de cluster em <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>:
     </para>
<screen>role-silver/cluster/<replaceable>NODE1</replaceable>.sls
role-gold/cluster/<replaceable>NODE2</replaceable>.sls
 </screen>
     <para>
      Substitua <replaceable>NODE1</replaceable> e <replaceable>NODE2</replaceable> pelos nomes dos nós aos quais você deseja atribuir as funções.
     </para>
    </step>
    <step>
     <para>
      Execute as Fases de 0 a 4 do DeepSea.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-cephfs">
   <title>Separando a FSAL do CephFS e do Object Gateway</title>
   <para>
    O seguinte procedimento de exemplo para o master Salt mostra como criar duas novas funções diferentes que usam o CephFS e o Object Gateway:
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-customrole">
    <step>
     <para>
      Abra o arquivo <filename>/srv/pillar/ceph/rgw.sls</filename> com o editor de sua preferência. Crie o arquivo se ele não existir.
     </para>
    </step>
    <step>
     <para>
      O arquivo precisa incluir as seguintes linhas:
     </para>
<screen>rgw_configurations:
  ganesha_cfs:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }
  ganesha_rgw:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }

ganesha_configurations:
  - ganesha_cfs
  - ganesha_rgw</screen>
     <para>
      Mais tarde, essas funções poderão ser atribuídas em <filename>policy.cfg</filename>.
     </para>
    </step>
    <step>
     <para>
      Agora, os gabaritos para o <filename>ganesha.conf</filename> precisam ser criados para cada função. O gabarito original do DeepSea é um bom ponto de partida. Crie duas cópias:
     </para>
<screen><prompt>root # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 ganesha_rgw.conf.j2
<prompt>root # </prompt><command>cp</command> ganesha.conf.j2 ganesha_cfs.conf.j2</screen>
    </step>
    <step>
     <para>
      Edite o <filename>ganesha_rgw.conf.j2</filename> e remova a seção:
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles='mds') != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      Edite o <filename>ganesha_cfs.conf.j2</filename> e remova a seção:
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles=role) != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      As novas funções exigem chaveiros para acessar o cluster. Para conceder acesso, copie o <filename>ganesha.j2</filename>:
     </para>
<screen><prompt>root # </prompt><command>cp</command> ganesha.j2 ganesha_rgw.j2
<prompt>root # </prompt><command>cp</command> ganesha.j2 ganesha_cfs.j2</screen>
     <para>
      A linha <literal>caps mds = "allow *"</literal> pode ser removida do <filename>ganesha_rgw.j2</filename>.
     </para>
    </step>
    <step>
     <para>
      Copie o chaveiro para o Object Gateway:
     </para>
<screen><prompt>root # </prompt><command>cp</command> /srv/salt/ceph/rgw/files/rgw.j2 \
/srv/salt/ceph/rgw/files/ganesha_rgw.j2</screen>
    </step>
    <step>
     <para>
      O Object Gateway precisa da configuração para a nova função:
     </para>
<screen><prompt>root # </prompt><command>cp</command> /srv/salt/ceph/configuration/files/ceph.conf.rgw \
/srv/salt/ceph/configuration/files/ceph.conf.ganesha_rgw</screen>
    </step>
    <step>
     <para>
      Atribua as funções recém-criadas aos nós de cluster em <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>:
     </para>
<screen>role-ganesha_rgw/cluster/<replaceable>NODE1</replaceable>.sls
role-ganesha_cfs/cluster/<replaceable>NODE1</replaceable>.sls
 </screen>
     <para>
      Substitua <replaceable>NODE1</replaceable> e <replaceable>NODE2</replaceable> pelos nomes dos nós aos quais você deseja atribuir as funções.
     </para>
    </step>
    <step>
     <para>
      Execute as Fases de 0 a 4 do DeepSea.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-services">
  <title>Iniciando ou reiniciando o NFS Ganesha</title>

  <para>
   Para habilitar e iniciar o serviço NFS Ganesha, execute:
  </para>

<screen><prompt>root # </prompt><command>systemctl</command> enable nfs-ganesha
<prompt>root # </prompt><command>systemctl</command> start nfs-ganesha</screen>

  <para>
   Reinicie o NFS Ganesha com:
  </para>

<screen><prompt>root # </prompt><command>systemctl</command> restart nfs-ganesha</screen>

  <para>
   Quando o NFS Ganesha é iniciado ou reiniciado, ele tem um tempo de espera extra de 90 segundos para o NFS v4. Durante o período extra, as novas solicitações dos clientes são ativamente rejeitadas. Portanto, os clientes podem enfrentar lentidão nas solicitações durante o período extra do NFS.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-loglevel">
  <title>Definindo o nível de registro</title>

  <para>
   Mude o nível de depuração padrão <literal>NIV_EVENT</literal> editando o arquivo <filename>/etc/sysconfig/nfs-ganesha</filename>. Substitua <literal>NIV_EVENT</literal> por <literal>NIV_DEBUG</literal> ou <literal>NIV_FULL_DEBUG</literal>. O aumento do nível de detalhes do registro pode gerar grandes quantidades de dados nos arquivos de registro.
  </para>

<screen>OPTIONS="-L /var/log/ganesha/ganesha.log -f /etc/ganesha/ganesha.conf -N NIV_EVENT"</screen>

  <para>
   É necessário reiniciar o serviço ao mudar o nível de registro.
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-verify">
  <title>Verificando o compartilhamento NFS exportado</title>

  <para>
   Ao usar o NFS v3, você pode verificar se os compartilhamentos NFS foram exportados no nó do servidor NFS Ganesha:
  </para>

<screen><prompt>root # </prompt><command>showmount</command> -e
/ (everything)</screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-mount">
  <title>Montando o compartilhamento NFS exportado</title>

  <para>
   Para montar o compartilhamento NFS exportado (conforme configurado na <xref linkend="ceph-nfsganesha-config"/>) em um host de cliente, execute:
  </para>

<screen><prompt>root # </prompt><command>mount</command> -t nfs -o rw,noatime,sync \
 <replaceable>nfs_ganesha_server_hostname:/ /path/to/local/mountpoint</replaceable></screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-more">
  <title>Recursos adicionais</title>

  <para>
   A documentação original do NFS Ganesha pode ser encontrada em <link xlink:href="https://github.com/nfs-ganesha/nfs-ganesha/wiki/Docs"/>.
  </para>
 </sect1>
</chapter>
